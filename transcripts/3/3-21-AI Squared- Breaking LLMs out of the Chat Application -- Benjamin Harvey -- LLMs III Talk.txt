[Music] how are you man hello hello how are you doing very good very good okay so uh the floor is yours right we go ahead and share my screen and it we jump in and keep going uh my name is Benjamin Harvey I am the founder and CEO of AI squared um but I'm also a professor at George Washington University um where I am the director of Designing trustworthy AI systems um today we're going to talk more in depth and in detail about you know how we're helping organizations create generative AI augmented experiences that uh organizations and customers um are are are loving in this space so a little bit about my background so um again my name is Benjamin Harvey um I started off um uh you know with a a degree in computer science specifically um looking at um you know how we can help organizations apply Ai and machine learning algorithms they large scale cancer genomics data sets um and that's what I got my PhD in and after I finished my PhD I did my post-graduate research at Harvard and MIT a joint program for the science technology um I went from the the Harvard MIT area uh out in Boston to the National Security Agency and at the National Security Agency um my last two positions I was the um head of data science for the Edward Snowden leaks and I was also the chief of operations data science for the operations directorate so uh in those particular positions um you know I first started off helping the National Security Agency understand you know what were the equities and the millions of files that were taken out of the building by Edward Snowden and I was the lead data scientists for running machine learning and artificial intelligence algorithms across uh the forensics data sets uh that we discovered to really posture the organization to mitigate some of the vulnerabilities that were exposed to some of the adversaries uh but I also um in the position of chief of operations data science at the National Security Agency was directly responsible for uh helping the organization understand uh not only how they create the technology to support Ai and M at scale but also from a a process and people perspective how do we create the uh internal processes you know whether it's governance uh to compliance really to ensure that um you know we can operate in a manner that allows us to uh increase the overall adoption of these AI Technologies um across organizations right where you know we're we're more than just deploying models but we're actually integrating those models into the workflows of our Workforce so um in that particular position in that role I saw tons of gaps one of the biggest was you know the inability of the federal government to really integrate Ai and machine learning Technologies inside of currently existing tools and applications um and that's where you know the foundation of this particular company in AI squared um that's where we were build based upon um I went and did a couple of years at um you know the Silicon Valley startup called Data bricks uh where um my last couple of positions focused on you know being a subject matter expert on the AI ml side but also you know really supporting you know uh growing business uh particularly for AI ML on the federal side of the house at data breaks um you know what you see here is really you know some information that's associated with um um you know the impact that we feel integrating generative AI Technologies inside of the federal government space but also in Industry can actually have where um ultimately in the federal government it's more about supporting the an in the military war fighter so the goal for us is how do we from a commercial perspective Empower organizations to integrate J Ai and predictive AI into current existing tools and applications uh so that we can uh really support uh more empowered data driven decision making and really from an AI Square perspective here are some of our investors including new Enterprise Associates uh but we're also um you know um recognized globally uh for some of the achievements that we've had as well all right so so thinking about um some of our our use cases um you know so our our product right is really a platform that empowers uh product owners analysts data teams and it really helps them you know securely accelerate their AI projects so both generative and predictive as well as measuring their benefits and what we're doing and what I'll be able to show you all um with this technology is we're embedding the AI in the generative AI inside of these applications without coding okay and we'll look at you know how the generative AI is helping us kind of build some of what we call these components based upon templates um but most importantly is providing you know the trust by iterating um with the human in the loop and then improving the AI and machine learning um capabilities according to the accuracy and the performance by leveraging that feedback and other analytics to um you know tune those models to help them become more accurate so we've we've um you know started working with you know a ton of customers in the space you know although away from Financial Services the cyber security uh to health and Life Sciences um but you know most importantly what we've been able to do is we've really been able to help organizations um take Ai and ML and start to um embed those Technologies inside currently existing tools and applications okay all right so so what I'm going to start with is really um a little background on you know the the traditional open AI GPT training process right and the reason I'm I want to draw parallels here is because um a lot of organizations uh as we talk to them in the early stages don't understand how important it is not to just um you know build a database of vector edings and train a or or tune a a model based upon those embeddings inside of a vectorized database right um but they don't understand understanding the value and the impact and the importance of having the human in the loop to provide feedback for the J of AI capabilities so that you can increase the accuracy and performance of that model over time okay so we're talk a little bit about the training process and specifically spend a little bit of time on uh how these Technologies are actually being tuned with the human in Loop where they're providing feedback and that's really what's powering the ability for a lot of these models to build additional question answer pairs that are really supporting the increased accuracy and performance of these models on these internally in internally uh developed organized and used proprietary uh data sources so that you can actually start to really prove some value for these JM AI Technologies inside of an organization so um you know we all understand um you know kind of the traditional training process that's associated with with these uh large language models and this jur of AI space where you we're starting with the you know the pre-training um where you know for an example there could be um a model that has you know 175 billion parameters that's being trained on a vectorized database with you know 300 billion tokens with a you know 50k vocabulary size uh and we're using right that to be able to empower us right to create our first itation of the model right so it's purely you know training based upon you know a large um you know vectorized source of information we have this huge model in this particular example 175 billion parameters as well as a vocabulary size of 50k and we've been able to to leverage that database across uh 300 billion tokens as well okay um and then the second step right is really what I want to dig into a little bit right so it's the the fine-tuning right where you're you know collecting data and you're fine-tuning where there's this reward right that's associated with um you know the information that you're gaining and then using or or optimizing right based upon the reinforcement learning um using things like a you know po algorithm for an example okay so so there's really two stages here so it's the traditional kind of training process but it's also the fine-tuning and what I really want to focus on is how AI squar is supporting some of the fine-tuning and really demystifying right some of the areas associated with how do you go into an organization with an open source model and come out with the model that is trained and could help you um you know really start to answer some questions for a specific domain based upon Le inside of an organization so so when you think about this fine-tuning step um uh what a lot of of organizations that we that we work with don't really understand initially is it it's really how important it is to not just use that initial vectorized database that has a vocabulary and just use that directly for a model that you're going to push out into an organization but the fine-tuning Step is really what provided um organizations uh like open AI but also organizations that are using large language models up to date the ability to start getting some really solid answers um to provide their organization so you know when we think about the fine tuning there's there's a couple of different steps right so so one of the steps um that organizations use and and we Empower organizations to do something very similar is really based upon a prompt the labeler then demonstrates the designed output and then there is this data set for the supervised learning and then you know finally you have this stf model right um so essentially what you're doing here is essentially a okay um uh based upon the response I'm going to tell you if it was good or bad right thumbs up thumbs down and if it was thumbs down I'm gonna provide you with a more of a an answer for me as a SME that I feel was accurate right or or correct given that particular response if me as the SME determined that it was incorrect okay and then there's another step right for a lot of organizations they say hey not only are we going to provide you with the right answer right we're also going to provide you a context additional context for why the answer was was wrong okay U and organizations using both of those types of information to retrain the model or tune the model but also in in and in the Second Step here you can see that you know you're using this stf model to provide additional answers right and and those answers uh instead of just providing one you're providing multiple and those multiple answers are being ranked and you're using that ranking as you're using the reinforcement learning to tune the model as well okay so so the the big thing that you have to understand and we're seeing this with a lot of customers is that the initial um you know creation of the vectorized database and just tuning on the vectorized database is one thing or just tuning on um you know just the embeddings that are from the underlying data across the organizational repositories is one thing but building a really solid you know not just a question answer pair um so that you can tune the model question answer pairs that you can tune the model with but also adding additional context from the users uh or the subject matter experts that are providing the labels so that you can increase the accuracy and performance over time as well and not just doing this at one point in time but doing this over the the life cycle of the model that's being deployed inside of the organizations and that's what we saw in financial services from a perspective of these organizations run observational studies and these observational studies are continuously being ran throughout the lifetime of the model okay so the fine-tuning is what we're seeing as the most important piece of the puzzle over time to provide these organizations with the ability to get a high fidelity of qu quality and the answers that they're getting from these large language models and a lot of organizations going in don't understand the power and the value of this but AI squared what we do is we come in and we say okay not only are we going to integrate this large language model into your currently existing Tools application but we we have to run observational studies to instrument it the the model gather feedback and watch the accuracy and performance improve our time so what does this look like um you know in an actual use case so so so here's an example um of a use case that we we worked with uh with a particular customer and and what we're doing here is uh we've done a couple of different things right and this is particularly in the cyber cyber security domain but what we're doing here is um we're starting to gather information right that's associated with not just you know uh vectorized data right that we are are gathering you know from the repositories in the organization we're also pulling in information from across the entire organization right so you know from a cyber security perspective this could be you know IP information hash information domain information it could be information about help documents uh it could be other llms uh it could be um you know vulnerability intelligence or threat intelligence right so these this could be a number of different types of information that's being pulled from across uh you know a cyber security organization for for for an example right now not only do you need to understand the sources of information that you can feed to the large language model but you also need to understand more about how are you going to gather that feedback right that we talked about to empower that fine-tuning you can increase the accuracy and the performance of that model over time right so really we've got two ends of the spectrum we've got sources of information other models these could be predicted models or these could be other generative AI models right that you want to add into the the sources right where you're powering the large language model and you're using it as an agent to be able to reach out to these sources depending on if the model feels that it has the information necessary to provide a very solid response okay so first is how do you um empower the llm to make connections to the sources of information that could really help it provide a solid response okay so that's one part of the problem but there's another part of problem specifically associated with defin tuning so what we did is we said okay all right so from the final answer of the llm the generative AI capability we're going to empower you to give it a thumbs up thumbs down if it is a thumbs down we want you to provide additional context for why it was wrong as well as the correct answer we also want to help the large language model understand if it's actually grabbing the necessary information that could help it provide the best response so as the subject matter experts provide information back to um the data team as well as the llm what we're doing is is we're trying to gather diff uh different information that's associated with okay from purely from a accuracy and performance perspective right how's the model doing okay um but also help us understand are there any other sources of information that could have been used with this large language model that could have helped it provide a better response okay so now we're getting into the guts of are there any undocumented or unknown data sources that we can add to the llm that can help it increase the accuracy and performance as well corre um but also relevancy right so we talk about you know what's the model timely was it relevant right um want to make sure that the results from the model are actionable right so we think about timeline is relevancy actionability but also the context right um being able to add additional context that could help that that could help the llm uh Second Time Around um provide a better response as well right so we're we're Gathering all this feedback and we're using that feedback with the model as part of that um that the tuning process to help increase the accuracy and performance over time okay so what does this all kind of kind of lead to right so if you think about many organizations and how they use large language models to date they use them inside of the chat application okay but what we're seeing as well is we're seeing a lot of organizations with the interest in okay how do I break this llm outside of the chat application okay so many of our use cases right now are associated with helping organizations take the insights that are associated with a traditional large language model and push them directly inside of currently existing tools and applications across the organization to support those um you know think about those analysts those business users those individuals on the front line that need those insights but don't want to jump out of their workflows to be able to use a chat bot or chat application and have that conversational experience they literally want the insights from a a actionable perspective a timeliness perspective uh from a integration directly in their workflows perspective they want it where they they want it exactly where when and how they need them when they want them directly inside their workl so um on the AI squared side another thing that we've worked really hard on is really you know empowering organizations to um think about the last mile of AI a little differently right so um you know think about how llms make a prediction and how that can be integrated into a currently existing tool or application but also right how could you use the human in a loop right similarly to how you use the human in a loop to actually gather additional insights directly within a chat application where it's thumbs up thumbs down if it's thumbs down provide me with context but also provide me with the right answer but give me additional um insights according to whether if the results were actable relevant timely contextualize uh if they had the right sources of information within them Etc so we're still Gathering additional feedback right in those currently existing tools and applications but what makes it really unique when you think about how you can start to provide joura of AI insights inside of a currently existing tool or application right what you need that a lot of applications don't currently provide is really that con content in the context right so the content associated with what are all the different sources of information that I could gain access to and then from a context perspective where are you at in your workflow right what web page are you on what web application are you within so getting that content as to what other sources of information exist that I don't currently know know about or not currently aware of that could help me better answer this this question as well as that context as to all right application am I in if I'm a business user um what lead am I looking at um if I am a business user um help me understand um where I am in my particular workflow uh in regards to turning a lead into an actual client so that context is extremely important to empower the llm to to deliver insight that are act more relevant timely and contextualized that can ultimately support datadriven decision-making all right so when we think about this um from how AI squar is working with generative Ai and doing augmentation and integration right so it's really about how can you augment the cognitive decision-making process of someone in a currently existing tool or application using the results from a large language model and really where AI squar comes in at is um uh We've created a technology called llm link right and what it provides us with is the ability to discover those um documented and undocumented data sources that could really empower the llm to increase the accuracy in which is providing responses whether it's inside of a chat application or whether it's back into a um currently existing tool or application inside of the organiz ation okay so um what we use is essentially a couple of different things right um we use llm Link to connect us to those documented and undocumented data sources but we also use llm Link to empower Empower us to be able to um make the connection to other models to other data sources that really helps us fine-tune that model with regards to the Fidelity of information that we are providing it to drive those responses but at the same time we use generative AI to help us create different experiences inside of the uh enduser applications right so we're not only powering the llm to discover new data sources but we're also allowing the llm to create code based upon our templates that we're using to create these very novel personalized experiences for different users inside these currently existing applications as well okay so it's more than just using you know documents that you vectorize theide of a database from the embeddings to be able to power the llm it is the context and the content so we're also grabbing and harvesting from the Dom an understanding of where the user where the user is what the user is doing that implicit and explicit Behavior as well as the content from where they are in their workflow right so implicitly you know um what page they're on how long they've been on that page um explicitly you know what they may be liking what they may be sharing um at all of that information really empowers AI Square to deliver these insights directly back inside of these currently existing tools and applications okay so we use llm Link to help us um understand where those documented undocumented data sources are but also these could be as we mentioned before these could be um predictive AI capabilities or generative AI capabilities that we're pulling together and then we use the um J of AI capability within AI Square to then create code that can create these really custom and personalized experiences in these currently existing tools and applications that we're embedding as well and then finally what we're doing is is we're then pushing um uh the content and the context right from the enduser application back into the llm to really help us personaliz what type of responses we're providing all right so so one one really cool example um this comes from one of our financial services customers so one one really cool example is um you know we've got a use case where in financial services we're working with sales account managers or sales Executives and they have a list of uh potential clients uh or leads and one of the challenges was really you know how do we start to get a high fidelity of information that's associated with um that particular lead that could help us ultimately make a decision or drive a decision on how we can communicate with this lead to ultimately turn them in he or she into a customer okay uh so starting off this organization didn't have a lot of you know um didn't it didn't have a lot of insights that were complex enough to really Drive making a decision for that lead to help turn them into a customer so what AI Square did is we used those key components of what I showed you as far as that augmentation and integration so Gathering the context and the content right from the actual field of view harvesting that from the the the application that that particular user is working within uh using llm link to drive the discovery of Doc dou umented undocumented as well as other AI generative Ai and predictive AI capabilities uh using our generative AI uh technology inside the platform to create custom experiences that's associated with the insights from the sources of data the insights from the models that are actually being used we're creating custom experiences and visualizations inside in the application that can support really helping that sales account manager or sales exective have a great experience learning about how to turn Alice Allison into a customer but also the final aspect of that was grabbing feedback right so you're only as good as from an llm perspective is the feedback that you can give over time to power the tuning of the model as well so what you see here are really two different aspects one aspect is we're Gathering U using llm link to reach out to those different sources of information right so one source of information here we have a propensity score where it's high medium and low uh score from probability from 0o to one we also have a couple of models that do core and non-core product recommendations that we use the llm to reach out to we also have a database data warehouse is associated with web and event signals that the llm reached out to and we use generative AI to create um some code that we embedded directly inside the application and that helps you have a really awesome experience of how the results from the different models that are being generated through the large language model are being integrated inside of this application okay but remember we talked about the tuning piece so how do you increase the accuracy and performance of the large language model over time then AI squar Works directly within um uh the compounds of feedback that we overlay inside of the application and we provide you with the ability to start providing feedback on the experience that was generated by the Jer of AI so what you're seeing is a totally new experience that the llm is powering so how do you customize that you have to continuously tune it so we're providing that user inside of this ecosystem with the ability to say okay for Alice Allison that was great that the actual um integration for Alice Allison was on this page and we had this score but I'd like the llm to provide something a little a little different so we can associate a certain template with how the llm would create a circle chart or a byy chart or a bar chart or a pie chart and we can empower the llm to create different experiences based upon these templates okay so what we're doing here is we're using all those different aspects with the ultimate goal of augmenting the current currently existing experience inside the application leveraging llm link to drive the discovery of documented and undocumented AI capability and data sources we're also Gathering that feedback to empower the tuning we're also sourcing information directly from the field of view so that we're harvesting insights so that we can get context and additional content and we're using all that together to really support data driven decision making for examp for an example um sales account managers or sales Executives Financial Services or consumer or package Goods with some of the companies that we work all right so kind of pulled it all together and wrapping it up uh so when you think about kind of what are the different pieces of the puzzle to empower this so what we have is essentially a um a way to empower our llm Link Technology to reach out to the different sources right so these sources could be you know model files uh the sources could be model API endpoints or they could be data sources across an organization and we've seen we've seen our llm and it has the ability inside of our gener AI technology assign of the platform to reach out to any one of those different sources to find those documented and undocumented data sources be able to add them as part of the uh results that we're embedding inside of these applications um but at the same time as we talked about we have the the um uh the autot tuning the feedback that provides you with the capability to start Gathering some of the data for autot tuning where you can set a threshold of feedback and say hey after we hit this threshold I want you to kick off a um a retrain so that we can tune this model based upon all the feedback that we gathered up to this point and then it's really the the engine right so the engine that we talked about which is powering the discovery of those different capabilities for AI and generative AI where it could be a predictive model like we talked about in the use case before where we showed um the llm restyle tour predictive AI model that did a smart a sales opportunity score for a lead and also reached out to a predictive model that did product recommendations uh but we're also using generative AI to customize those really cool experiences so that code that was generated uh in regards to those dashboards came directly from a generative AI capability where we are using a template to create new code that empowers you to um create like a bar chart or a pie chart or a circle chart um whatever it may be and we're using that and that's what's being embedded directly inside the applications uh we have a workspace face where um low code no code depending on if you're data Sciences or um depending on if you were a you know for an example um a product owner you can build out these experiences inside a new applications in minutes and then finally right uh we've seen a lot of success from organizations that want to test different experiences across the organization with different sets of users so um they do AB testing where they create an experience for for one group of users using AI square and in cre a separate experience for another group of users you're usually asir as well so um I I'll stop there and um I'll open the floor up um for questions but really appreciate the opportunity to tell you a little bit about uh what we're seeing in the space and how things are shaping up and uh looking forward to engaging with those who are interested in more information thank you thank you very much Benjamin this has been absolutely incredible I think I have about a thousand questions for you and I'm gonna I'm G to try to keep it to the top 500 or so so but let me start with a couple of questions from I mean like my mind has been racing ever since you were saying things about the NSA and then so I have questions stemming from then to all the way into like the details of AI squ and what you guys are building now there's just like so much that you touched on I'm going to start with a couple of questions uh that folks from the chat posted so the first one I see here is from Rex he says what's the process for then using the feedback to refine tune uh when do you decide it's the right time to go through that process and eat the cost again and I believe that you addressed a little bit of that sort of like towards the end but can you perhaps give a more complete answer to this yeah great great question um by by the way so so if if you think about um you know when when a lot of organizations um grab an open source model for the first time and then doing some tuning based upon the original original open source model that they brought into the organization they use two different types of data set they they traditionally use so if you think about um datab bricks Dolly right data bricks Dolly op Source not only the model but they open source this you know data set of question answer payers that they use to actually train the model as well so when we when we pull the data uh inside of an organization um we're creating it in two different ways one way is just just straightforward like a you know um a vector database based upon word eddings of the internal organizational repositories that's one but what we do is we structure the feedback as question answer pairs right and those question answer pairs we use with the vectorized database and together the feedback with with that we construct this question answer pairs with the vectorized database we use those both to actually retrain them but that that's a very great the next one is we have from Lucas here do you have concerns about data quality for the feedback loop so simplest example being that an optional thumbs up thumbs down usually has more thumbs down since users are more likely to complain when their workflow breaks than to complement you when it works well uh since they just proceed with the workflow instead anyway how do you handle this sort of um imbalance yeah great great question again um so what we do is we do um have a hierarchy of of people that are providing feedback so so we we we have a we run a stud right and in this study that we run it's called an observational study and we run that with organizations the organizations inside the observational study have subject manner experts that have the expertise to provide the feedback right but it's a very controlled study so when we retrain we're retraining on the data from the study from the subject matter experts that we have trust in that are going to be able to help us get a very high level of quality and in the feedback but we don't limit the feedback just to those individuals so so we also use more of like a crowd sourcing mechanism for other individuals any organization that are providing feedback as well where we can flag certain items because 10 users said the same thing about that one specific thing right and that Flags certain things for us so that we can understand that we need to make improvements but specifically for the study right that you have to continuously run over time right you can't just deploy this llm and think it's going to just automatically just be great for six years right have to tune it over time so what we do is we run a controlled study a certain number of subject matter experts that we validated and verified and then um we kind of use those two different aspects of crowdsourcing and an observational study together you sort of like okay it seems like you're taking a very like you're deeply integrating into their workflow and into their company this is not just like okay use this product play around with our sandbox you're done you feel like this is you simply cannot roll out uh a in the way that it seems like you're imagining you should with this approach exactly and and and and the the the the reality in what organizations are seeing is that they're trying they they're literally trying right now and um the first organization on the cyber security side that we worked with they've tried and they were they got to a point where they were like okay we we're training this model on you know tons and tons of data in the organization um you know we went from open source to fine tune on our data in our organization and the model still sucks how can we get it better and you know the the the reality that come that come to Jesus moment was really you know hey look like you guys have to embed some processes that you can start to get a more fine grained Fidelity and the amount of feedback that you can get because what organizations don't see is open AI spent a lot of time resources Gathering that feedback right and doing that fine-tuning and organizations now think hey I can bring this open source model in and I don't have to do the level of fine-tuning that open AI did to be able to train chat GPT I'm just going to be able to use a vector database and get a a hugely accurate model so it's really two things we saw you have to do the fine tuning you have to run these you have to continuously do the fine-tuning and the other thing is you can't try to the ocean in the first iteration of the model Right Use the llm to bring in other models other llms that you might need to use but kind of stay more focused initially and then bring in other sources of information other predictive models other llms over time to kind of expand the breath of the questions that you can answer with your capability yeah I'm I'm very curious about who internally has the motivation to sort of like weather that kind of project because because it's I mean it's one thing if you say you know what fine let's just bring this Chan GPT is kind of cool we'll plug it in I got some I know how to you know call some Rust apis and then as soon as you have some moment of disillusionment now there is much more staying power that seems to be necessary right so somebody in the organization has to say well no this is actually worth doubling down on who are those people great qu oh my goodness great question so um so here's the thing it's a lot of times it's motivated by the cost of some of these studies in in in the llm world right so here's what we see we see organizations they spend millions of dollars testing evaluating llms and they never get anything in the production that anyone is ever willing to actually use on a you know day-to-day basis right so so we we've had CEOs that say Hey like my organization just spent $10 million and we don't have anything to show for but a bunch of models that have been fine-tuned you know and and and and and they're sitting on the shelf right so so we come in and we say hey if you want to get to that next level and you actually want to want to push out a production level product or you actually want to use something at a production level inside the organization here's what you have to do um but at the same time there has to be an understanding from because you've got this you got the people that are seeing the money being spent but you also have to have someone who is very critically you know understanding the importance of getting these capabilities into the hands of the business users right so on the from the data science side traditionally data scientists don't care much about you know after I throw it over the fence who uses it and how they use it so there's a connectivity from like these product owners right yeah Pro who own the AI Technologies as they exist inside of some of these currently existing products and tools yeah combination of the people seeing the money spent and the people that own the fact that the Technologies need to be embedded into the workflows of the business users as well yeah yeah so you you get these like so the product owners that's on one hand and it feels to me like probably more and more product owners are feeling the Allure of pulling in llms into their or just AI in general perhaps just like as they see it through like the lens of of Chach PT and whatever into their products but that seems to have been a relatively recent Trend you're also talking about you know work that you guys did in the Snowden case and this is what like early 2010s that we're talking about what how do you compare sort of like the motivations back then to say well let's pull in Ai and machine learning a relatively recent sort of um uh like uh addition to the zist at the time uh what you're seeing now like what I imagine like an enormous amount has changed in the mindset said but is there any way you can describe that difference yeah great great question great question um you know I I think great that's this is such a great question so so so you know some years back right the the motivation was the thesis was you know how can I get predictive AI um integrated inside of currently existing tools and applications but over the past year it's the thesis has completely changed to generative AI right because organizations want to they want to scrap the chat applications and they they're like hey I want to completely start to integrate these J of AI Technologies inside of the workflows of the people that need them the most now during the Snowden case from a predictive AI perspective the feedback was really important as well right because the feedback helps you understand for an example um you know there are I'll tell you this there are um very um cool ways that you can use feedback from a predictive AI perspective to understand what individuals are doing from an AI perspective right that they may not supposed to be doing right so you know what what models are you using um you know what information are you you curious about as you're leveraging these different AI capabilities right so there's there's a lot of important and um useful information that you can gain as you're Gathering feedback right from users in their workflows directly from a um uh Insider threat perspective right so I'll say that so back in the day I I'll say this our technology was really dual hated from a Insider threat perspective but also right from a traditional you know how can I integrate AI into predictive AI into the workflows but that feedback gives you a lot of insights into how your organization is using Ai and machine learning Insider threat can you say more what does that mean yeah so so The Insider threat right I want you guys to think about um this is really you know how individuals in the or so so understanding the behavior so so user entity and behavioral analytics right is where a lot of organizations are trying to use to be able to determine if someone is doing things that are of Nefarious activities inside of the organization right so early days AI squared was really you know looking at how individuals were using Ai and machine learning so the feedback was being used for us to be able to determine all right if you're using predictive Ai and you're looking at a certain model inside of an organization that you shouldn't be looking at then how can I understand that feedback to really be able to determine if you have the correct access authorizations and authentications if your behavior doesn't match right exactly what you're doing at a certain point in time as well so we kind of use it in a dual haded manner also for Insider threat but also from a predictive AI capability as well guys hey what's I just wanted to jump on here I'm about to go on to stage one but I wanted to say that Benjamin Harvey is a Legend I love this guy I'll see you later he messaged that in the group chat I think somewhere earlier too so you know he's sincere and this is the moments before he gets on the stage this is what he feels about Benjamin I'm sure you've made quite an impression uh on him and look at me I want to just keep you here for as long as I can I'm just I'm continuing to grill you on question the other thing is I have no filter I'm just gonna keep asking you questions until we tell see asking some of these questions anymore I prepared let's see I do have like dozens of questions here that I I might find you on the slack later on but let's see if there is something that that you know what I I okay I know we we got to wrap up but I do want to ask you so something like this um you seem to have been talking about both like working in the federal government agency's financial services too like it seems like you're sort of like spanning the space here of like the different companies that you could be working with uh you don't seem to have been limiting yourself that being said you're also it feels mean like while you have a product and a technology that you're building you're also very Hands-On uh working with those clients right so they may or may not I don't know if internally you call them a client or a customer or a user right it seems to me like like when you cater to let's say like the federal government yep do you feel like having an only product approach is the best way to go do you need to do like a mix of products and services how should companies that are sort of like product first companies think about Services when catering to uh buyers like the federal government that's such a great question so so what I what I'll show you I I had one I had a picture of um of one of the awards that I won it was in it was in a presentation but this is it right here right so this is this is the 2017 right so this was for some of the work that we did um for the Edward Snowden leaks um this is the 2017 top award for a Counter Intelligence professional in the United States in 2017 right so to answer your question you you almost need some it's pedigree number one right because the federal government is so hard to break into right as far as how do you start to do services or even bring a product inside of the organization so see almost for us you know we were very fortunate because I had the background and the experience of working in the federal government for over 10 years I had done you know so much work at the highest levels in the federal government so that really helped right so you have to have someone that understands acquisition processes but also has tons of connections that can help you kind of get into the federal government because I wish I could say um that you can kind of you know kind of you know knock on the door and find the right organization that understands the value of your technology to be able to get in but it's really about uh relationships um but it's also about connecting the dots and understanding like the underlying mission objectives and connecting your technology to those mission objectives but the only way that you have an understanding of those mission objectives is you have to have um intimate knowledge of the organization and you have to have intimate um knowledge of the strategy from some of the leaders in the organization as well to kind of map your Technologies too so going in you do want to have a combination of both because the federal government doesn't pay for for products right like they pay for butts and seats so the opportunity is to go in and say hey look I've got a technology that can augment the workforce but as I put butts and seats I'm G to add this technology with it so that they can become more um you know more efficient and effective and how they're actually building things or providing you know insights for a military war fighter any the analyst but at the same time I'm not saying that this technology is going to replace you know adding butts and seats like it's going to literally still Empower us to bring more um workers into the organization but we're just using our product to augment so we we we have got kind of like a dual approach in the federal government we're g to bring in you know additional contractors to help support Mission we're going to augment them with our product as well for which companies does it make sense then to try to break into the federal government is it yeah do you have like is it you need to just be like Mission driven is it also a lucrative business to get into like are is the market size sufficient like how do you kind of uh reconcile all these different sometimes conflicting incentives when you make that great question so so I I I'll give you an example I know a company that does 500 million ARR just with the National Security Agency Jesus just with the National Security Agency that's one company right so um and they provideed technology that's just one company so the point is is that the the opportunity is lucrative um but at the same time it is a huge commitment from a startup perspective to trying to go into the federal government without having a ton of connections understand the acquisition process and being able to um to very succinctly go into an organization and connect to a program of record when I say program of record it's like an organization that has dollars that have been allocated for you know three four five years out and you can connect to that budget so you have to have that otherwise you can be spinning your wheels for a couple of years wasting you know the money that you could be going after industry industry dollars and bringing into the organization to try to win just your First Federal opportunity so there are programs like the sbir small business Innovation research grants that you can go after U from the federal government perspective to get you some non-diluted fund so I would say go after those first while you trying to figure out how to find customers in the federal government and use both of those Avenues together in conjunction with going after commercial dollars to be able to see if you can you know do work in the federal Benjamin it was a massive pleasure to have you here thank you very much for your time and wisdom yeah hey you got it whenever you you guys need me uh I'll be back and you know it's it's an honor to be here cuz I love talking to you guys and anytime you need me let me know and I I'll I'll be the first person to support whatever you guys are doing in the future will doe thank you very much Benjamin and good luck with the i squared okay all right talk to you later man thank you [Music] right