maybe uh before I uh I I kick off the panel just to say a couple of things about why we thought uh we we want to spend a little bit of time with uh with you all on um Ai and education uh at proses as you might have heard us say now a couple of times we invest in different sectors one of the uh big ones is attech uh basically education technology companies there's about 12 of them um and this is a space that we been very excited about for some time uh because we believe uh here technology can play an important role into improving the way people learn all around the world and so in that work we have had the privilege of working with uh leaders in in in some of the companies and uh and others uh that are trying to basically change how we learn using technology and we thought to invite three uh people on to basically have that discussion with us today um and I want to quickly um maybe just introduce them or at least at least say who they are and then I'll let them introduce them and and say how they're using ey in their company so first we have yea husan who's the founder and CEO of solo learn welcome yea U we also have Bill salak the CTO of brainley and Clinton from dualingo who heads up the AI uh work at dualingo and I think between the three of you uh we're close to representing about a billion Learners that you each serve uh through uh your company so that's quite an interesting uh I think number and each of you have thought about how you bring AI into your products in different ways uh so I'd love maybe for you to maybe quickly introduce yourself um uh what you and the company have been looking at and maybe what you're most excited about in terms of the one or two AI use cases you've been spending time on uh recently so maybe yea can I ask you to start yes sure uh so thanks for having me really exciting so we solo learn uh we are the most engaging platform to learn to code for mobile first bite-sized practice heavy with a strong community that kind of supports you whenever you get stuck uh a top up on Google Play and App Store over 30 million registered users around the globe mostly organic growth so that's what solo learning is and in the last year and a half we have been experimenting with AI kind of you know just trying to understand how AI improves learning experience in in in general because as a company we're very much focused on experience you know how you teach learning science at the core of everything we do and we have like we have production IED you know an AI assistant we have tested couple of things that haven't worked and we discontinued them and a very exciting project we're working on now and I think that's like very much wor the ettech like the disruption in ettech will happen like if you look at what has happened in edtech in the last 10 years uh the biggest Focus was on has been on content generation so we have generated you know tons of video lessons on any topic out there where at Tech hasn't been super efficient like other than like couple of companies you know just investing in the space is basically you know just replicating a great classroom exper experience online and when you think about you know just all the promise of AI out there which is you know an AI tutor for all of us you know like personalized learning you know Accord like playground where you can test any skill you know on the go or you know AI books that can teach us to be more you know socially and emotionally intelligent those are all components of like the great components of great teaching and great classrooms and I feel that for kind of you know just teaching AI how to teach is a very like under you know like overlooked area in a way and by just you know kind of you know just investing in it and that's a project I'll talk more about but that's like a very exciting project we recently started basically training the models not only to produce content but also to produce it in a format that actually teaches so super excited about that it's not live yet but we're seeing very good early results and I'm going to stop here so fantastic yeah we definitely going to spend a little bit of time going a little bit deeper on that in a second you but thanks for for the introduction and thanks for joining us today uh maybe I can quickly hand it over to you bill um and say a little bit about you know what you do at brain Ley uh what the product is and what are some of the use cases that you've been uh working on recently sure absolutely so brandley is a Community Learning platform you can think of us as the world large study group we have hundreds of millions of Learners that come to us every month to get help uh we have an extensive extensive knowledge base that covers all School subjects and grades all of this is very sophisticated technology um it's a platform that helps Learners get unstuck when they need help we integrate AI into that experience we also integrate Community um so it's Learners helping Learners AI is there to assist when needed um and our goal is to give learners high quality explanations to the questions that they're struggling with so this is school work but we're helping Learners outside of school um our our goal or the thing that's driving us right now and where we see integration in in Ai and sort of where our biggest technology Investments are going right now is all all around this concept of giving the explanations that your teacher would have given so we we don't just think about giving an explanation or giving an answer but we think about what are the qualities of an explanation or an answer that is most suitable for this particular learner like what is the vocabulary being used in their classroom what are the concepts that they've been exposed to so that when we give them an explanation it actually serves their needs it's not that we're introducing new words they've never heard before or concepts that they haven't learned yet but we're really trying to get as close to the classroom as we can um to provide that that level of personalization that you get from your teacher who's giving you a one-on-one you know sort of tutoring session so to speak um there's a lot going on in our platform uh to be able to make this happen but but all of the features all the things that we work on are really around this particular goal yeah thanks for sharing that and you know you and the team were you know some of the earliest adopters uh you know in the group and sort of trying to embrace how AI could I think help you in that North Star and I think uh we'll talk about this hopefully in a bit as well but uh you've certainly helped us understand what the uh the high quality aspirations are that you also put yourself and the AI and the community too when it comes to providing the right answer and when you know how you think about evaluating answers whether they come from your subject matter experts or Ai and it isn't just a correct answer but it needs to basically be as good as you described as the teacher needs to be so uh uh uh we we'll go deeper into that in a second um Clinton so uh thank you for joining us uh uh from du maybe the same question to you and um um also maybe you can share a little bit you know how you spend your days at dual lingo what are the key use cases that you're you and the team have been you know spending time on when it comes uh to using Ai and and and giving a better user experience for the dualingo Learners yeah absolutely um excited to be here thanks for thanks for the invitation um so yes I'm Clinton bnell dualingo head of AI um dualingo uh you know primarily we have a language learning product uh to make sure everyone's aware of that uh we are also recently expanding to some other subjects like math and music um but uh yeah primarily most of our AI is happening in the language learning space um we we've been we've been using AI since close to the beginning of dual lingo like a decade ago uh largely for personalization uh related uh issues right trying to figure out what are the right exercises for this given learner at this given time um I think uh maybe most relevant to today um we you know most recently some of the cool new things that we've started doing with uh large language models the lest generation of them uh include uh one big area is a lot of interactive uh kinds of features right so being able to like have a conversation in a language that you're learning um is something that the technology just wasn't there to support before uh now we we are building various features where you can have different types of conversations uh there's a lot of interesting um a lot of interesting problems that come up there uh in terms of how to make that actually a compelling feature for Learners who are wanting uh sort of a fun bite-sized experience um who are maybe a bit less like self-directed uh we are also doing some work in the explanation space so interesting to he'll hear uh what bill was talking about there uh definitely definitely some connections uh because you know now we can actually give people explanations of if they get something wrong uh you know why why was that wrong uh they are you know uh mostly right um but there's a lot of optimization where still doing there um and then we are also you know using large language models uh quite a bit uh echoing back to something that um yeva was talking about uh in terms of thinking about how to automatically you know generate parts of the curriculum or figure out you know how to teach a particular concept um to a given learner uh and and I certainly would Echo what what uh she was saying there that you know generating content uh as content is easy generating content that teaches well um is a very different problem that larg language models don't know how to do out of the box uh except in kind of obvious Common Sense ways so uh yeah a lot of a lot of other interesting AI work happening but I think maybe I'll focus on those for today great well thank thanks for sharing that and when I I remember you know in my days when I was doing my PhD at caring melon I think that's that was when dingo was born and uh at that time there's you know some of the early ml work was taking place there so it's not really surprising to hear you have that in your DNA it sounds like um now you might have seen that the the theme of the of the event today is um llms in production and um uh you know there's a lot of Builders out here joining today listening to to the panel and various speakers have shared very sort of you know things that have brought a little bit of realism back into the discussion you know agents suck for example or how hard it is to do eals and so on and uh for all of the promise and so on that we of course uh think about when it comes to AI and and being applied in education I'd love to also ask you you know what are the what are some of the things that you've learned uh Lessons Learned maybe where you had expectations on AI moving some important you know metrics that you've been looking at when it comes to Learners and and the way they use your product that weren't exactly met or other sort of I guess you know because many of you are early movers in the space other you know wisdom you've you've gained in the last 18 months as you sort of thought about or maybe even before but thought about brick building this next generation of ml models in into learning um maybe Bill uh you have some thoughts on that one yeah absolutely so I mean the the audience should know Paul that you and I you pulled me into this pretty early like you I think you were the one who brought um open ai's new gbt models to me and said hey you got to look at this and I I can say until you showed me what you guys were working on you know we had we had dabbled in the space and I was quite skeptical so so when we when you ask the question like what disappointed us or what didn't quite live up to our expectations like we I came from a place of very low expectations and I think I was you were consistently like pushing my boundaries and showing me like oh no this can actually work um but I think what we learned I think like the wisdom here that that's most important to take away and certainly has wor has served us well is that if you're relying on the llm as a fact generation engine or you're looking at it as a body of knowledge like that's where you're going to find disappointment where we find the biggest successes is in using to synthesize or produce a an explanation or text or an output that is informed by something we're able to give it so we put it on very rails right we put it on on we put it down a path by using um augmented prompts or we feed it information and we basically ask it to synthesize this information into a more productive or humanlike response and I think it does really well at that um where you give it space to go off the rails where you give it space to kind of figure things out I think that's where you're going to find disappointment it's also the least competitive so think about your data think about what you know about the problem that you're trying to solve as your competitive advantage in the market space anytime you rely upon the llm to sort of do what everybody else can do with it without augmenting it with your special CL I think you're you're sort of competing at the lowest common denominator and you're not going to have much success with that that can Surface in a number of ways right not just facts but just in producing responses that are sort of generic and um not necessarily helpful in a personalized use case h thanks for sharing that maybe a follow-up question just to uh before we we go to uh to Clinton and you have a how do you address this right because you talked about hundreds of millions of Learners you do have this in your product you do have you know these basically it's called false positives or mistakes misleading answers and so on that wouldn't live up to your standard how do you deal with that ated brainley so you know with the with a healthy dose of skepticism that we entered this in we really started by putting the features that we created in in serious constraints so we didn't ask it to generate responses to questions or explanations to questions we started with something simple like here we have an answer to a question question but it's not serving our learner and the learner will let give the learner the ability to have this explanation reframed so we added a simple feature like simplify this explanation or explain this in more detail right so now we have the context we have the facts we're comfortable with that but we're able to modify the use case the users able to modify the use case to serve their need only later did we get into retrieval augmented generation use cases only after we felt comfortable able um with sort of those simpler things that were more constrained um but the rack stuff really expanded a new area um and then when getting directly to your question you know the more you know about your learners the more you know about their behavior patterns and their curriculum and their content and it should be I should be clear we don't teach we don't own the curriculum at Brinley we are not the ones who have generated the curriculum we are literally a tool for any school system any curriculum so when when Learners are asking us questions we are trying to learn what they're learning we're trying to figure out which cohort of Learners looks like them um what's the content they're most likely to visit what are the patterns in our knowledge base that that we can apply to them to then be able to augment the llm generated output um so it is about understanding your audience it's it's about understanding their behavioral patterns and the content that they're going to be traversing now and in the future and then augmenting those prompts that's a very very difficult thing to do um but I like to simplify it for my stakeholders by saying oh yeah no this is the same thing you see on Netflix and YouTube this is just um you know commonplace stuff it's it's actually quite difficult I would definitely agree it's Brave to simplify it at the risk of then being told to just do it fast and everywhere but that's a thanks for sharing that um yea maybe the same question to you so you know I think we worked together there for some some time and I think we're excited you brought us into the space too so yeah so but at the same time we learned some things along the way um but I'm also curious how you see that now as you're shaping the direction of the company or if you look back the last 18 months what are some of those lessons where you said hey these are expectations I had that maybe didn't sort of turn out to be exactly as matched um and and and how you use that information as you decide what you do next yeah I like to Echo whatever Bill said because I think like we started with you know let's just do something you know everyone is talking about AI let let's get into this space H and what we've learned is like exactly the same you know because you're not going to be differentiated if you build just another assistant you know it will be somewhat helpful probably it will solve some problems but it's not going to be you know a core like basically a core part of your product and what we we with think we do best and like with a lot of room for improvement is we teach and we started the company you know with like can you make hard things easy to understand so that was the big premise and the content work we're doing right now is exactly focused on that and the exciting part of it is that we have actual teachers who kind of you know just provide feedback and we train the system based on the teacher feedback because we have learned that that the part that is missing because yeah AI is great you know to produce like a lot of information you know just just in like the factual information as Bill puted but then it's not great in kind of putting it in a way that that students actually understand so we started with very small pieces of our bite-sized content you know just the theory part first then we moved to like simple practice exercises and the deeper we go like the like so like basically I think that's where like we can make some difference in in automating what we know about how people learn cool yeah I think that some of those lessons were hard learned I remember also when we were actually excited about some of the feedback we did the small cohort we did the math on the cost and we said wait a second we can't really scale this up and so I discussed with the team how we could train our own model and eventually we did to kind of make sure it was also cost effective I think that comes back to one of the themes we started with you know at our scale at you know your scale um this becomes a serious consideration so totally but that feature that we build together is is is a is kind of loved one like it's not a core feature but it's it's very much used so it explains the coding gers in the human language so makes it easier for students to understand so in production it kind of yeah yeah it definitely gets to the point of making complex things easier to to learn EAS to understand totally yeah um so CL Clinton you know given that du lingo also you know in your DNA how how do you how do you look back at some of the lessons you learned in you know jumping into some of these ml applications and and things that maybe didn't turn out quite as you expected either on the metrics or on other ways to kind of bring this into users at at your skill yeah yeah uh great great question so yeah I I think I would I would Echo uh some of the stuff first that that bill and youa were talking about um one thing though uh maybe turning this into slightly more of a discussion uh I I took some of what bill and yeva was saying to kind of be opposites actually if I under if I was following correctly I think Bill was one of the points he was making was that generating the getting AI models to generate the underlying facts can be very hard to get them to do it right instead like you generate those based on your own internal data and then use AI to kind of package that in a nice you know way to to present to Learners and if I and I think Eva was actually kind of saying the opposite right that um use the AI models to generate the facts and then uh and then the hard part is actually figuring out how to like present this in the most useful way to a learner um did I did I follow those things correctly yeah but I didn't mean that generating facts is always going to be correct and great and you know so you have some work to do I think on both ends yeah no okay that that that's interesting so definitely we've also found that yeah the fact part is the is the hardest part to get to get right most of the time um I mean sorry it's hard to make it such that that's almost always right um we definitely uh run into some run into some hurdles there uh several of the solutions Bill mentioned are things we've explored um I was also going to mention in terms of uh what another thing that we've realized in this modern LM world uh doesn't work as well is is just naively running these things at scale because of cost um and I guess Paul you you just brought that up right before um but but yeah that that seems uh that seems very true at at you a very large scale uh that that we upgrade at um even you know even some of the cheaper models uh are are still you know cost prohibitive to run you know to run on you know every user response or something like that um we've actually been doing a lot of work uh in figuring out ways of using large language models uh in in ways that don't scale with uh with usage so for example uh you know using them to pre-generate a lot of possible options for example that then you're just picking from uh in certain cases or um or even in some interesting uh cases we are doing things like using uh using large language models to generate cheap Like rules that we can apply in real time uh to to like detect certain things uh like if a person made a particular kind of grammatical error or something like that um and so that that's actually been very interesting too where we're figing ways of using these models to generate cheap detectors that we then run without those models um across across everyone that's a very cool one I think that's something we we end up talking about as well a lot because you know generations to do good Generations is expensive right you need these really high quality large models but you know selecting between the best answer basically ranking is a much lower effort task right so you can uh either train your own models uh or find other ways to have these models generate the rules so that's nice to hear hear that you guys are working on that now we've you know I I purposely sort of wanted to dive a little bit on the on the on the learnings and the skepticism that you might have developed over time on where this might and might not work at the same time I think there's ALS this is one of the areas where the potential for transforming the way we learn is maybe more evident than in other IND Industries so I would like to you know maybe draw on your uh on your ideas for if you were to sort of plot the next couple of years what are the things that you are excited about right so having tried and and and and learned and and and and maybe stumbled on on some use cases like what are the things that now given all that those things you feel will really shape the industry um you know you are building together so um I don't know who wants to go first um I see Clinton nodding so maybe you want to start sure yeah yeah big question so it is it is a big question um and I I think there's a lot of different exciting possibilities I mean definitely one is just uh for for language in particular is just enabling people to practice and learn in a much much more interactive way um uh in a much more kind of real-time adaptive way uh so you know being able to you know practice ordering a coffee at a restaurant or something right is like a a skill that you can now practice a lot of times where you you just couldn't before so there's a lot of of kind of Step change functions like that um I I think that uh one one problem you run into in these cases though uh which which I think the community is kind of starting to Grapple with now um is that it's pretty easy to just like make a chat bot uh but making an actual like compelling interactive product that is based on chat is a very different goal um you know something that people want to come back to every day and keep keep doing things with um is that an AI problem in your view or is that something that you say we've got the AI tools for but it requires rethinking the product experience and the the way we've we're presenting these models into our current Journey yeah it's a really good question I mean I I think definitely there's a lot of product work to do there for sure I'm trying to figure out like what what should these experiences look like uh you know what what do we want to build but I think then once you nail that down uh for for a given use case there are still a lot of interesting AI problems that that come up there so for example um you know one thing that we're running into uh dualingo now we we have you know one our the main like interactive chat feature that we're making is about um is basically like you know a goal directed chat like you know ordering a drink at a at a cafe or you know or helping uh helping a tourist find their passport you know something like um particular like goal directed conversations um what even once we have that uh and we want to generate things uh we have several different constraints you know we're trying to generate these conversations to be like with our dualingo world characters have their own personalities um obviously trying to you know focus on particular kinds of of topics that we're teaching um but also one of the really hard constraints is just keeping the language like at a level that a learner of this ability can understand right and that that turns out to be like one of the hardest problems you can you can very you can do a rough pass and say like you know ask basically like in your prompt you can say something like oh try to have this at the level of a you know at the level of a third grader you something whatever you say there but um that that only gets you so far um and there's a lot of other interesting AI work to get it to actually be at the right level um yeah that's a great point so I think uh that's a you know you know I think in in in the language space you talk about C1 C2 these pred levels that's definitely something you can tell a language model to do or adhere to very well today but maybe with fine tuning and so on that becomes uh uh easier in the next couple of that's right that's right fine tuning is pretty helpful there um but but yeah so I I think one thing that's going to happen is just figuring out like what what kinds of really Interactive Learning experiences resonate with people and are things that people are going to be coming back to and how do you build those um ver versus just here is an open into chat bot that in theory can teach you a lot of things although it may make stuff up sometimes yeah that's a that that's a definitely an exciting language learning future so hopefully we get to see that bill how do you think about based on everything you've seen so far and and and the the the the feedback you're getting from your learners uh what excites you um in terms of the next coming years um you know my excitement is not so much driven by what I see happening with new products or or new techn Technologies it's more about the acceptance of these Technologies in new places in our lives that we we haven't been readily accepting them so when we you know when we first started working with llms um one of the literally like every interview that I did since open aai released chat gbt the question was and how do people feel about having AI in the classroom or how do people feel about AI interacting with their children as if you know this was um some version of The Terminator that was coming for their kids um and so you know I think that Society in general culture in general is is like more open and accepting and starting to get comfortable with this so I'm really excited about the problems we can solve because there are huge problems in education informal education in the entrenched sort of um systems of Education that are run by governments National governments there are huge problems there there's underfunding there's under Staffing there's lack of being able to have one-on-one attention with kids we can solve those problems with these Technologies and that to me is the most exciting opportunity in front of us yeah that um that is hard to disagree with so uh um I hope uh you guys can be part of that solution um yea same question for you yeah I think like there is a lot of exciting stuff like when when you imagine where you can go you know as a result of kind of whatever was made available to us you know the prospects are like great and awesome uh I think it will take some time to get there you know whatever we work on and and we talked about it it's not perfect and and it will need a lot of tuning fine tuning you know just a lot of kind of trial and error and and learning on the go but yeah like we have no other choice because we need to be learning on the goal we need to be upskilling you know all the time just to stay competitive and to be relevant and and so that's that's the path like the question is how fast we get there and and yeah and how fast we figure things out yeah that's I mean uh um uh hearing it from from the three of you I mean you've gone through I think a healthy amount of skepticism to some excitement to you know back and I I still hear some uh optimism in what you're describing in the future so I guess as a as a father of two young children I hope uh by the time they have to learn many languages code or any other homework help uh you guys have built everything they need to do this better and more effectively so thank you for joining us today really appreciate the time I know it's late for some of you early in other parts of the world so thanks for for for joining and sharing your uh your wisd yeah [Music]