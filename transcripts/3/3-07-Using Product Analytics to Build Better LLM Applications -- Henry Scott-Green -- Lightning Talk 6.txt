uh none other than the CEO uh and co-founder of context AI Henry Scott green and I will mention that this is one of the talks that came through the request for presentations that we put out and it was so good the abstract had me and so Henry I had to bring you on here man how you doing hi thank you yeah great to be here BR bring great how are you great man well you've got 10 minutes on the clock I'll be back in just a gif I'll let you get after it fantastic thanks so much so yeah today I'm going to talk about how you can build even better llm products by using analytics asking the question of so you've built your first llm product what comes next and that's when you're hopefully going to build an even better one by using real user feedback and this talk is going to be geared towards product people and product problems and I'll explain why I think that's the most important layer to be focused on so who am I and why am I talking about product analytics I'm Henry and I spent seven years as a product manager at Google where I built and I patented billion user AI based anti-abuse systems uh now however I'm the co-founder and CEO of context Ai and we build product analytics tools for llm applications so that's why that's why we're here so why do I think the biggest problem to solve in this stack is a product problem it's because we're in a period of very rapid change similar to you know the dawn of mobile or the internet I think huge Industries are being disrupted and new winners are unquestionably going to emerge I think if you're on this Zoom call you probably don't need me to tell you this but I think it's worth calling out regardless so during a period of such intense change what's the most important thing to focus on it's that you're building something that adds real value for real people and that's a very hard problem which is ultimately a product one not a technical one it's answering questions such as you know what should you build and what do your users want it's not enough to build a product that works or hopefully works well now obviously that's hard but it's not enough to have a successful product and a successful business you need to add real value to real users and then the real question is how do you do that so obviously you start you build something you launch it now what you're going to start iterating towards product Market fit you're going to learn as much as you can from your users then you're going to build and ship the next version but how are you supposed to know what your users want and how do you know if the thing that you've built your new baby product how do you know if that's any good and how do you measure the impact of the changes that you're making as you iterate through the product development process there's two challenges that I see for llm product builders in the ecosystem today the first is that understanding of your users which is so crucial to product development the these are questions like why are these people using your product and what is it that they want the second half is understanding your product does it actually meet real user needs and how can you improve it so obviously the real question is how are you going to solve these problems now one solution being demonstrated by Spongebob here is that you could read all the chat transcripts that works really well when you've got a demo project or a hackathon or a small Alpha but it's not going to scale Beyond a few dozen engag users Builders I speak with every day are relying on this method and they say their products feel like they exist in a black box that's the phrase I hear all the time so a better and scalable solution is product analytics product analytics is the name for a group of tools that basically shine a light on user behavior and product performance to solve this blackbox problem and what specifically is it that you should be evaluating using your product analytics well first first you want to understand your users there's many things to look at here and most important is probably why are people using your product a couple of techniques you can use to understand this are by clustering con conversations bottom up for topic detection and this can this can Encompass conversations that you didn't even know were going to occur the alternative is a top down classification against a predefined taxonomy because obviously you do understand what some fraction of your users are going to be talking about timately though you're going to want tools at two layers you want to understand the themes of user Behavior but then you're going to want to go deep and read specific transcripts to understand exactly what's happening in your product so you can build that crucial user empathy second half is understanding product performance some of the metrics that give a good signal here are the like to dislike ratio of your users in response to your responses the user input sentiment are they happy versus frustrated user feedback surveys message regeneration rates and conversion rates for goals that you define you're going to want to track this performance at many levels and this is a key Gap that I see in the ecosystem today obviously you want to look at Global product wide success how many people are converting how many people are clicking thumbs up thumbs down but your product isn't you know doesn't exist in isolation there's a whole diverse you know landscape of use cases and this is why you need to slice by topic you need to say okay the queries about X queries about Y which which ones are being handled well and which ones are being handled poorly so you've got to slice these success metrics across your whole product for each of the topics that users discuss for each conversation that occurs and obviously for each message and these really help you understand how you should direct your product investment efforts and those valuable engineering resources that you have how are you going to make your product better with them so that's what we're trying to solve uh at context we're product analytics platform for llm applications trying to give people understanding of how people are actually using their product and how their products performing and what specifically you should you be tracking As you move from a small beta over into production I'm going to show you how we've approached it that hopefully gives some inspiration to other builders on this call so a couple of the ways that and a couple of the key questions that I think you're going to want to understand firstly how are people using your product this is where I mentioned you want to have detection of the conversation topics being discussed most frequently by classifying top down against the taxonomy clustering bottoms up for topics that you didn't know are being discussed and keyword detection to get things like those embarrassing competitor mentions then it's how your product's performing and being able to slice the performance of your product the sentiment of the user inputs the ratio of thumbs UPS to thumbs down of the responses across each of those conversation topics as I just mentioned then you want to dive deep into user Behavior are users churning or are they sticking around what topics do the engaged users talk about what topics users talk about right before they churn it's so important that you're slicing your product Behavior to these individual use cases that people have within the universe of possibilities that is your product and then you're going to want to be able to answer any question by putting together custom graphs and charts uh because everyone's definition of success is wildly different so that's something that you have to support if you're trying to build an analytics platform different ways that you might want to slice your data are looking at different user coh s different AB test arms different models or different development environments that you've got in production and then finally Trends are only so important and it's important that you have that analytics and insights layer but then you need to go deep to build user empathy and to debug specific problems we probably going to want some tooling that lets you manage all of the transcripts and filter them based on date ranges and the topics that are being discussed and success versus failure signals and obviously privacy and security incredibly important uh you know I I think no one can build a platform these days to provide analytics or observability without these kinds of features talk to compliance stripping pii not trading models and I think some other things that we're building out soon but I think that are interesting uh if for this conversation are building out pre-launch evaluations in addition to postlaunch everything I've showed here is really once you've got something in production how a real user interacting with it how can you build data sets for rhf and then some additional things that we've got coming uh down the line but hopefully you didn't just want analytics for the sake of it or because your boss told you to uh what do you actually do with these metrics and so you basically you want to identify these eras of poor performance or of strong performance and then understand what's driving them and ultimately use that understanding to improve your product so you can do prompt engineering you can do rag or improve your data set that's used for for fine tuning you can change the ux Run AB tests and double down on your strengths and perhaps do marketing to address those key use cases so so that's an overview of how we solve the blackbox problem that I see that exists today for llm developers ultimately solving that blackbox problem allows you to build an even better product we'd love to help for for folks love to continue the conversation please get in touch thanks so much awesome Henry I appreciate it man and I appreciate you did not let me down with that one uh so that is awesome