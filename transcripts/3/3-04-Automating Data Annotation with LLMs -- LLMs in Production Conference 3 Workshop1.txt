yeah i' i' I've kind of been part of the mlops community um just as like a member for you know since Demetrios founded it back in like 2020 or so it was it was right around the time the the pandemic started I think and it's just it's been amazing to see like how much it's grown and um how useful of a resource it's become for everyone um and uh you know so yeah it's been it's been exciting to and it's exciting to be part of this so I think we have around uh yeah 24 people and it's growing uh let's kick it off and you know uh as uh one of you said uh all these sessions are recorded like people are across time zones and everything so I'm sure a lot of people kind of wait wanting to watch this session uh later uh so let's let's kick it off uh so hope you're enjoying the conference welcome to the workshop uh I'm your moderator for this session uh so few words about me uh I'm I'm Nishi I'm director of machine learning at process uh uh we based in Amsterdam and today I'm helping with the conference uh so that's why you see me here and so for this session we have brilliant folks from Human signal uh talking about using llms for data annotation so as you probably know high quality label data it's crucial for machine learning right and even for llm you still need label data for rlf but in this session we don't talk about we will not talk about data feeding to llm but the opposite we'll talk about how llm can assist in the process of uh data annotation uh so so that's kind of the context uh for this and uh uh a simple housekeeping rule so as you see it's a nice and cozy setting and you know you you are kind of as a participant you're on stage now you can also speak uh so the way we want to run this is let's keep it interactive if you have any questions uh put that in chat and the speaker will take it as they go uh they have prepared a presentation for let's say around 45 minutes so in last 15 minutes we really want to kind of also have a discussion where you can unmute yourself and feel free to just ask it but meanwhile as the presentation goes please put your questions on the chat and speaker will kind of look at it and they will ask so Michael Nikolai Chris with that the floor is now yours all right thanks um yeah I will share my screen to kick off the presentation then me and yeah and uh I'll pass the presentation to Michael uh just let me know if you're yeah I'll I guess I'll just kick it off right now um uh we wanna I want to welcome everybody to the to thee to this to this Workshop um uh my name is Chris Hodge and I am the head of of community at human signal and human signal is um like we're the creators of an open source project called label studio if you've um if you've done if you had the need to do any data labeling and you've been looking for open source projects kind of help you along with that um label studio is is is the most popular kind of you know by number of different metrics including number of downloads number of stars just you know usage across the board for you know being able to label your data in a free and open way um joining us for the talk today are are Michael and Nikolai who are the co-founders of both human signal and the co-founders of label studio um they have a kind of a a long story about how they they realized that data labeling was one of the next frontiers of of you know places where new work really needed to be done and it needed to be done in an open way um and uh you know they that maybe if we have some time they can they can share some of those experiences um but today we're going to be talking about automating data annotations with large language models um so you know thank you to everyone for being here and uh um uh you know please give a warm welcome to to Michael and Nikolai um so if we go on to the next slide uh we can cover the agenda a little bit you know it's important to set the stage about what it means to label data efficiently and the costs that are associated with that um you know we can we can spend a little bit of time talking about the challenges with manual labeling and and and why it's actually fairly important for it to be automated and then we can kind of dig into a little bit of how we can use llms to automate the labeling process covering a number of different ways to you know think about it like the naive approach of just asking llms to just generate you know just write a prompt and let and see what happens you know versus The Prompt refinement process and then kind of automating that process and then to kind of wrap everything up we're going to give a demo of this and so Nikolai will be will be giving a live presentation of label Studio how it works and kind of how it integrates with large language models to help you automate the data labeling process so we can move on to the next slide okay so let's start off by talking about the costs of labeling efficiency uh next slide so I think that one thing that's pretty clear is that the gold standard of data labeling is human annotated data uh data reviewed by human labelers remains the gold standard it it's the ground Truth for developing and training models and but the thing is is that human annotations are expensive that it takes it takes time uh it takes attention it often takes many um many annotators to be able to L label the data so that you can ensure the quality across different annotations because sometimes there's human judgment in annotations like if you think about doing sentiment analysis something that might be considered harmful speech to one person may not be considered harm harmful speech to another and so you can build up the quality of your data set by having more people evaluate it and then look at the correlations between those annotations to decide on what the truth for that you know so you can actually assign like what the label for that data is um but we've seen that modern models require massive amounts of data and really the amount of data they consume is is way way larger than can possibly be labeled and you can see this in all of the foundation models that are coming out right now that are just trained using um using unsupervised learning on massive corpuses of data and so you kind of see this tension here where the best data that you can be using is human labeled data but the biggest models and the best models right now are in some sense by and large being created by unlabeled data and so there's this tension here where we want to be able to um you know use human annotated data where we can but automate the process so that we can save that more expensive gold standard for the data that really matters so if we move on to the next slide you know you know so kind of like what we were talking a little B about before is that you know while human annotation Remains the gold standard automation also brings huge gains and so we have this latest revolution of foundation models that was enabled by using a tremendous amount of data coupled with unsupervised learning and if you think about it it's like having a giant library of all of human knowledge available to you and you have a librarian who has read every who has sped read every single book in that library of human knowledge um and can return the knowledge on demand it's not always perfect but it's actually but it's you know it's frequently impressive um and I think every single one of us has experienced this over the last year with the release of these ever more and more powerful large language models and other Foundation models so if we go to the next slide um but part of the reason why these models are so impressive is that human guidance has raised the bar when you train when use a lot of unsupervised learning on a huge amount of data there's a real danger of inaccurate or harmful information from the llms that have only had unsupervised training and um and so we've seen like one of the primary methods that we've used to do this is reinforcement learning from Human feedback where we bring human annotators back into the loop and then they assess the outputs from these systems and then um reinforcement models are trained off of their output and so you're taking that gold standard of humans evaluating that output bringing it back to the models and making them more reliable making them safer and so you can see that while we've had a huge amount of gains from the automation process the thing that really raises the bar and improves the performance and and is the huge differentiator between models that are just okay and models that are great is when you've had that human touch involved in it so let's move on to the next slide um so that kind of sets the stage for us and for the rest of the talk and how we want to talk about large language models how they can be applied to the to the data labeling process and how we can bring humans and llms into that Loop together to really build the ba the best labeled data sets possible in the most efficient way possible um so kind of having set the stage for that I'm going to turn the microphone over to Michael who will talk a little bit about about the automated data labeling process um thank you Chris uh maybe before we go into this uh this section um any questions so far from the uh from the audience that we can answer okay no questions um all right so I'm going to talk a little bit about uh how we can apply the llms to automates the the labeling process and um first of all I want to I want to say that uh in general uh lolms they encode uh a vast Corpus of knowledge into itself and uh what we are trying to achieve with uh uh with prompt engineering requirements is basically how can we extract those knowledge and decision making process and apply that to the tasks that you need to uh to label uh um in the most naive approach um we can just generate a prompt and you can see a prompt example at the uh bottom right where we're asking LM uh given that uh specific text uh classify that into the number of classes and return just a single uh class for it you can imagine that this is a pretty straightforward prompt for a very uh simple task but those prompts can be much larger and much more complicated uh with the tasks being also much more domain specific and uh that approach is uh what we consider a pretty naive initial approach that can still produce some labels and uh those labels may not be uh of the optimal quality and a lot of L quality of the labels depend on the actual prompt itself therefore there there is a need to further verif those labels that were produced to the uh by the model and we can go to the next slide yeah and uh for that verification there is a supervision process uh that we're introducing into the uh into this workflow uh basically the workflow uh extends into the uh including the human annotator or human supervision uh into the process where basically the job of the over a human is to verify the label that was produced by the llm and after that verification is done uh we can consider that a label or that annotation to be a ground truth one and we can go to the next slide and uh for that process to work effectively uh you needs some for some data label and Tool basically the tool where you can integrate the LM and you can upload all the predictions that llm is producing and those uh predictions can be uh verified by the uh by the human and annotators resulting in you having a ground truth data set and we can go to the next one yes and um this is where it becomes um interesting uh basically we are establishing a ground truth data set so we're asking the model the model uh with a prompt input to generate the predictions for uh different items in your data set we then verify all of those items uh using the uh tool like label studio and then we have a full ground truth data set and that ground truth data set becomes extremely important for us when we further want to uh create uh and refine The Prompt and we can go to the next one yeah so what happens uh in the next situation of that process is that we are uh we have predicted some labels based on the prompt and we can verify those predictions using the ground Truth uh data set that we have created then we do the supervision and we try to understand uh where the model is not predicted the labels correctly according to our ground truth data set and that process uh it's an iterative process that gives us uh the Ator and insight on how to refine The Prompt so basically identifying and looking through the issues where the prompt is not accurately predicting the label um we can uh get an Insight uh what adjustments we want to uh make to The Prompt so the prompt becomes more accurate and that process itself um uh you can repeat that multiple times before your prompt uh produces the predictions that are 100% accurate according to your ground truth data set validation um this process however becomes quite timec consuming because you can imagine that uh you would need to iterate on the prompt multiple times before you get to the prompt that is very accurate so it's uh good it it brings it to the good results but it's not optimal in terms of its efficiency and we can go to the next one yeah and um what we'll be showing in the demo is how you can gets to the what we call an uh automation of the pro prompt refinement process so the process that I have just described where you're trying to get that Insight um we will show you a system where the system kind of learns by itself uh and tries to analyze the mistakes that are it identifies from uh the this match of predictions versus the ground Truth uh the system automatically learns from that with a goal of refining defining the prompt automatically and the result of it is that you're able to get to the very uh refined uh and accurate prompt in an automated Manner and the dependency uh that you need to have and satisfy to get you there is uh a ground truth data set that is used for validation so Michael we have a we have a question from the from the audience here uh so so PES from IE University who's a student there um is asking you know then does the underlying model of the llm essentially become the gold standard for the problem that you're trying to solve with the data um it if it can become a gold standard yes it becomes a gold standard uh you may also find yourself in a situation where your task that you're trying to automate and label is so domain specific that uh llm does not have the knowledge uh of that uh particular domain and you just may not be able to utilize and get uh uh you you may not be able to build a prompt where uh the model would be able to give you the accurate uh prediction you're looking for we also have a a question question from Richard um the CEO of uh beobe works um uh he's wondering is is the process for just verifiable data sets or could it actually be applied to fully synthesized data sets um I would say it can be applied to the fully synthesized data sets uh just as well um because I think there is not U much difference in a sense that if the if your model if your llm it has the knowledge that is required to uh label the synthetic data set that you have created then you can basically utilize the same process that we are outlining here okay I think we can go into the demo [Music] now all right yeah so I so we discussed a bit uh like broader uh topic about the importance of the data labeling we discussed how we use the automated data labeling to kind of produce the the the data sets that can be used in machine learning pipelines within the human in the loop type of the workflows where there is the annotators uh uh that's uh that can verify the output labels and now we can go more deeply into uh the lowlevel code into how it works in practice and do some Hands-On live demo so uh hope during the live demo there won't be any life coding effects so but uh let's start from from the beginning so what I'm going to present you today is uh the workflow like more or less described before from the beginning from the initial um very brute force or straightforward naive approach where you can apply large language model directly to uh in zero shot maner to your labeled data set and uh produce the labeled data and progressing towards the way how we can optimize our automated labelers to produce more quality examples more quality labels as output so first uh we set up our environment so for the sake of demo presentation we will be using using uh open AI um provided llms so we will useing API provided by open AI however uh in a real world scenario uh we can consider as well some something that you can host locally mostly due to security like for for the sake of sharing the data as well as the cost implications because actually the process of automating uh data sets generation or labeling data asss is iterative in nature and you can uh quickly run out of money you pay for um for open the ey Services if you start iterating on powerful model from there so something that uh is not will not be covered in this um uh demo but uh impli it is that instead of opening ilms you actually free to use uh any other lamps like llama to deploy it locally which definitely can give more or less the same level quality with less costs and keep your data secure in your environment so uh we we get the data so we uh what we going to present uh as the task so there is a like commonly used data sets with uh Amazon product reviews that's um initially produced to um to be labeled as the for the sentiment analysis task so basically there exist labels uh that are either positive or negative and um they kind of represent in this uh data set however uh for this presentation it might be so trivial to consider the autol labeling data sets into positive and negative labels because most of the lamps uh already can absorb different data set and they may learn even this data set may already exist in a training date so we will not be using this labels but instead we um we turn this task into more um custom logic that we need to assign so let's say that we have the product reviews and our goal is to classify the product reviews into whatever they represent the subjective opinion or they have they State some objective fact so something that you can uh imagine might be useful uh if you start building your customer uh support chat B just to filter out something that represents objective opinion and concentrate Focus your team into objective statement so again like we have the text by now we we absolutely ignore already existing labels for sentiment however we can use this as support information as well but we will focus on the text and we will train our large language model how to classify the text into uh whether it belongs to subjective or objective categories so let's start first with this naive uh approach uh which also call like boost TR labels so um recently openi released a quite powerful model uh like the next generation of GPT 3.5 which is uh quite cheap uh and still it's the kind of upgrade uh on top of the GPT 3.5 turbo that uh uh follows the chat structure but instead we don't need the chat structure here we actually what we need is to to have the model that can perfectly follow the instructions so we use this uh GPT 3.5 turbo instruct that exactly find unit to follow the instructions so kind of like the single turn uh dialogue um yeah just just uh to double check uh do you see my notebook right yes yes we see the notebook yeah yeah do know from from the chat is asking if we're going to be able to share it after the talk oh yeah yeah absolutely yeah I sorry I was just your message I thought that might be nobody see okay that's cool um okay one thing to of course to consider is to for the sake for using open we need to kind of have your own open key obtain it from the open AI uh API platform so we put it in our environment so now we can use all the services uh like all open AI API uh to to produce the task um okay so let's start uh our naive approach and let's uh bootstrap the first label set so the main ingredient here is first our initial instructions like we use the initial instruction uh which tells okay classify the text based on whether it represents the objective fact or subjective opinion so that's our intention that we need to uh imply here and exract large Lage model to classify the text then which is like then uh we structure our prompt by providing this initial instruction presenting the text as the input and expecting our model to produce the output so this is a we convert our data set into augmented data set where each example now uh represent uh represents this prompt and we ask uh openi service to produce the completion so let's run it very quick um yeah for um it's uh it's about 100 examples selected from the data set just to for the sake not to waiting time but again for the real world scenario you may consider some optimizations and uh moving forward uh needless to say that the the more you invest time into optimizing your best folk your local models and they can definitely greatly be optimized which I can quickly cover at the end of the topic but the better uh efficiency you can get out of iterating your data State labeling so uh we just run our um first iteration on producing automated labels and we store all the results in this completion array so let's check what's the what's the output like what are the labels produced in general uh by this um uh by this process as you may see uh we have many different completions uh produced by large language model so some of them may sound something like we expect besides like there is some fact fact prefixes some new line symbols but some of them uh may be absolutely out of our expectations and it would be hard to convert them into our final goal so uh I'll remind you the final goal is not to kind of tackle with this completion the final goal is actually consume the labels and the labels should be like our expectations about the labels they should be either objective or subjective nothing else so that's actually What's um constitutes the hallucination so here like with a such a powerful model uh like GPD 3.5 hallucinations are not uh quite drastic but uh if you start applying maybe less powerful model but cheaper model you may find more hallucinations and more problems uh by uh that's uh requires you to kind of guard or uh steer the model towards what exactly you want to achieve in your task so you may heard that uh like the one of the straightforward approach is just to fine-tune the model uh to your task but that again may be costly and that's not something uh we want to uh start with actually there might ex there exists easier solution which is called constrained generation so the constrained generation uh is essentially the way how we can instruct the model to produce exactly the output that you expect so we're going to use the very like the wonderful Library which is called guidance and this Library provides the template where you can instead of just providing the plain text you actually provide a template where you uh instruct your kind of program which is called like labeler in our case you instruct this labeler program to follow uh some natural language plus the placeholders where we put our inputs and additionally which is important is the placeholders where we instruct to not to produce the generation free form generation but to produce the but just to assess the option like select basically from the objective or subjective classes so it's very uh natural instruction where we don't expect the model to to give us the free form text where uh which we need to then uh modify somehow to adjust to our particular Target but what we just directly pick from the generations the tokens that corresponds to our class so we actually we don't need even to generate we just need to kind of assess the probabilities over the tokens and pick only those so very very efficient approach so let's start with this simple example okay what are we going to do here so here we have the input there's highlighted is a blue so the our input is just the example from uh our data set and the output which now can deviate from uh two labels provided it's either objective or subjective but of course you may ask okay but maybe it's it's not the classification right so we can't understand whether it's that kind of certain confident in this classification or not confident which is even more important uh if you consider Active Learning scenarios so the active learning scenario scenario uh just to give you overview is when you continuously interact with the model and model can give you the next example uh like the most uncertain example from the model standpoint so you don't actually need to label all the data but you only focus your labeling effort into the most uncertain examples provided by the model and this uncertainty scores expressed for example by um probability is obtain it from the logits uh as the output uh sometimes they might be more complicated cases where uh lock probabilities uh uh will won't work sometimes you may rely on entropy or maybe even more sophisticated techniques to assess the uncertainties but uh the um it actually doesn't matter too much the only matters is that if you have the way to assess your model certainty or model uncertainty then you actually can uh select examples from the data set that you should focus your uh labeling effort first and hence reduce deficiency because you don't need to actually label examples that already kind of label it in a perfect sense so you you need to concentrate your work or the work of your uh labelers of your um uh colleagues who can help you with labeling uh into the examples that matters yeah this is a this is a great example so so so profes was just asking about this earlier in the chat if it was possible to to be able to you know choose which annotations you want people to be looking at based on the probabilities and so this is like a nice example of of pulling out the different confidence metrics out of the model and kind of returning them back um you know and being able to use that as an an evaluation tool so just wanted to make sure that I that I called that out oh yeah absolutely and I even show you uh in life how we can tackle with this uh scores in know label studio so let's uh so actually while we're kind of talking about the prompts here too um Paulina has I think a pretty good question about um kind of how llms interact with um you know kind of the behavior of llms uh particularly in like um you know she asks can we provide the llm with label definitions and what are the odds that it's going to stick to it permanently um as an example chat GPT can easily forget about the previous prompt despite the same conversation um so you know is there is there kind of a you know a good stickiness between responses from the llm based off of the The Prompt that you're using in the data set so um if uh so there are actually two two facets of of of this kind of very Broad and very valid conversation um and very reasonable question so like the first thing about forgetting so this is all about the like the way how LM works so they actually they are they cannot access the full information that we have they only have an access to some specific so-called context window and the context window means that uh it can only uh digest like say the last uh 400 4,000 tokens or like 1600 100 Tok some of all the L providers provide even up to 100,000 of the tokens but no matter how big the context window length is still kind of limited and if you kind of try to apply uh all your knowledge and put this entire knowledge into the LM so it suddenly start forgetting something that's was uh at the beginning and this is a kind of like the big problem and it's um there is many many different So-Cal like workarounds right now where you do the ret retrieval augmented generation where actually retrieve some part of the uh um information from your knowledge base and then you put this information into LM first uh Place uh that's LM actually get an access to broader knowledge but for with still being uh stick within context window uh so does it answer your question or uh I still not clear about like okay but if we talk about the uh this kind of labeler labels specifically produced by LMS is that uh something also you want to hear about but I'm to be honest I'm not quite clear about like the second part of the question if it's not related to context window so essentially when you like no matter what you fit into the model so okay say like for example we use the right context window so we are not uh exceeding something that's provided for this LM and L LM produce the like output saying like objective subjective so it it can be considered something as the again the chatbot system you put the sum input and uh the output is one of the response provided here and then if you want to do more manipulations with this output you're actually feel free you you you feel free you you can freely use this responses to inest it uh in the further um processing by LMS uh so mimicking some sort of the chat for example I can ask okay can you provide me the reasoning why you pick this uh here subjective and then large language model is able to provide the reasoning about about the subjective so that's how something how we can memorize the context and actually this uh also something I want to show you um further to kind of different techniques how we can um uh elicit some knowledge from large language model put more information into the large language model to actually enhance the quality so but let's first um uh get back to the if there is no kind of question on on this particular topic if let's go back to the uh example where we now know how to extract the confidence and the score from the um from our responses so now as um to recap so now we are able to kind of produce exactly the labels we expect and moreover we also able to produce the scores that we can use to uh to work and to manage data in a proper way and enabling Active Learning scenario so uh let's go and now with this techniques uh process the full uh data set as before okay now we get our data set processing processed we have again initial text uh the product review we have the prediction and we have the associated uh log probability with the this prediction so now we have actually everything to start working uh with this from the human supervision perspective so we actually want to evaluating the labels so we don't we we we we don't know whether these predictions are correct this just looks correct but might be some errors that we need to assess and evaluate so in order to do that we connect this label data set like what we just generated to the label studio so again uh label studio is the tool that provides you all capabilities to work with a human in the loop so to produce the um automated labels or even start from scratch without the labels anate your data uh plug it back into your machine learning pipelines or even like plug your realtime machine learning pipeline into the labo studio so you can just continuously interact with your model so there is many many features and capabilities available able in the label Studio that uh provides you seamless experience how you can work with it with this from the UI perspective but here uh since we already started uh working with it uh with label studio uh in programmatic way so we Pro we continue to be on the same uh path and I will show you how you can use the API uh with SDK to connect to the label studio uh import the data and uh getting the created ground TR data back from the label Studio okay so let's switch to the label studio interface so here you see uh this is like the main page of label studio in label Studio each data set you're going to work with can be created as a project so let's call it is like llm um uh annotation uh project so we create a data set the data sets uh now should contain the labels um should contain the specification of the task you want to solve and the importing and the data you import uh and you uh that's you're you're int intended to annotate so let's start with this so-called label interface label interface is essentially the task that you going to annotate so as soon there is a many different um uh use cases not only within the N but our today's Focus uh since we are working with the LMS is natural language processing and text classification so we pick this text classification but uh we will not of course we will not use the positive negative neutral because again it's a trivial we we have the different task our task is to classify the uh whether uh whether the text represents objective or uh objective or subjective opinion so there are two labels objective subjective uh and you could actually even modify some UI elements uh because they are not relevant uh anymore so we can for example pull the text here so again our label interface is ready we save this and uh okay so now our project is ready to get the data in and start labeling process so as you may see uh the project ID is uh 568 so we're going to use this to connect to our project let's call five 68 and uh we use label studos DEC to connect to our project okay now we connected to the project which is called llm annotation project that's what we the title we just assigned to this project okay our next task uh again getting back to uh data set we just automatically label it we use the same data set to upload it directly to our project so let's go and let's upload uh the project okay now it's done let's go back and see what we have here good so now we as you see we have our text so we have the index saved from the uh initial data frame we have uh like sentiment labels whether however they are not related but they can be helpful for us to work with the data we have the which is important back to the question discuss we have the lock probabilities which should be numeric representation and we have the predictions so what are we going to do with all of this we actually can manipulate the data in that way that we can focus ourself in something that is Meaningful for us to anate for example we can start um observing what's the what's the result of the objective classification so we can go and we can say okay I wanted EXT I want to extract only objective classification result and F uh furthermore I need to order them according to the probabilities assigned to to so like we order them in as sending order and we focus ourself in Focus ourself uh at the lowest probability assign so essentially it's the kind of manual uh manifestation of active learning scenario so let's go and see how it works so there is some product review and our goal as annotators to assign whether it's objective or subjective um okay like I will do some um just small fun or maybe boring for someone's stuff is assigning the labels but uh just to give you the sense of how it works in practice and what you're going to tackle with if you go with this labeling project so for me nice docum station for homework uh sounds like more subjective thing because it doesn't Express so if however it gives me some docking station specification there is some object it's still kind of like the subjective opinion okay I will assign it to the subjective here like we have the batter runs down so the battery um sort of the things that I would love my sport team to focus on like Focus for okay sounds like more objective criteria uh objective uh review so there is like people couldn't hear me to talk and had to pull out the earphone and talk on the phone also something that I would like to address uh my technical team to to work through this so it's sort of the objective thing so here is also like specification though something is is is badly happening here so we also so it looks like our kind of objective labeler like labeler onto objectives works pretty well um yeah also like something that's uh specified the um the battery uh dysfunctioning okay the subject let's take a look into what at the end of the list so at the end of the list should be the example that are um are actually not uh oops something uh and end of the least uh we should have the example so something is not connecting my but it's sort of the uh Network H okay uh so s of the network look okay so if we go uh at the end of the list at the end of the list we'll see the examples that are actually like the most confident from the model standpoint okay if we go back we can inspect and the lock probabilities are the highest one and which indicates that is like highest probability thing so it's like well packaged random time however I see like it may not be uh something that I would consider however no like a right the time it maybe okay so so the delivery team works perfectly so I I can label this as objective here is also there is like battery left time sh okay so we see that our model uh based on the subjective based on the how it consider objective label Works pry well uh okay what's happens with a subjective thing uh with a subjective thing um we can go the same route and I see and I I can you you can also uh see that the probabilities are sorted according to our expectations so the lists are uh at the top uh so here doesn't make the phone too bulky uh I think it's still kind of objective because it's it expressed although the model kind of give me the assessments as as the subjective opinion I think it's subjective because it's it stands for good protection it's also kind of like the something that's uh specified a device and how it connects to the keyboard okay so here we have nothing about uh the any details any specifications so it's truly subjective thing that's the same however I if if I if I don't know what exactly is I can skip it so with the excellent Bluetooth have said definitely something subjective and this doesn't express any specifics so it's definitely subjective so here good case excellent values are subjective and so on and so forth okay so um let's stop here um so we collected so far sort of the uh like let's move back the filter so we have like 13 annotations not too much but just for the sake of them now we can use this 1 annotations to as the ground roof data however like again it's very doubtful whether it's ground roof or not ground proof maybe kind of my initial assumptions are wrong and maybe like if I ask another annotator to annotate the same text actually it can produce completely different examples and that's like very another completely another topic how we can actually establish the ground truth and uh if you start asking yourself okay what's the ground truth is it will be hard to define the clear answer and you might want to invite the more people to label your data and more tailored workflows to uh control the quality and to understand which labels are good or bad and so on and so forth so it's not so easy as it looks but okay let's uh pretend that we create this uh ground roof annotation so now we can download the data and we can produce uh the kind of quality reports out of the data we uh provide so here are two labels uh and some Precision recall and like score metrics it give us ability how our uh initial approach scores against the um our ground prooof data so when you apply these techniques now your question is okay what are you going to do next um okay I I'll post here before I jump into the quality and just be mindful of the time how many time I have 10 minutes left on the timer as okay okay okay I will try to be quick um however like the most interesting part is here but okay uh trying to speed out the things okay improving the quality the improving quality the question to improve the quality comes to you when you see okay the numbers I I just assess are not satisfactory for me what can I do next there are a few type like actually I I present you a couple of approach but there is existing more approach that can help you to drive the quality up but uh most of them are um related to like the the broad classes of the first effort fusure prompting so the future prompting is the idea that besides the initial instruction you can actually insert in your prompts the examples how you going to create annotation so it might be some random examples from your ground through data it might be some examples of the errors previously made by L language model or even in more sophistication scenario it might be dynamically PR selected examples based on the task you're trying to predict so for example I see some text excert I search in my um database for semantically similar text and then I use the semantically similar examples with the labels to populate in my future scenario so here as you see like there is a couple of the uh error spots and uh I'm going to use these errors uh in my prompt to um to improve the quality app so besides the just uh The Prompt itself uh instruction I will also include like the couple of the examples of input outputs and the final kind of um and asking to complete the final examp so it's very effective it's even like pre chat GPT era type of the workflows where you're just showing the pattern and you ask the large language model to complete the partn uh where they are very effective at so the fuse shot scenario can be also extended by So-Cal chain of thoughts so chain of thoughts is very effective surprisingly effective technique where uh like you can extend your prompt your instructions with so-called rationals so rationals is the uh can be initiated by so-called magic keyword step by step so you can actually ask your model to reason step by step and you imply this reasoning into your promp so how it works in practice so we we put there and it's not only now it's not only produced the like the final output but it also produce the rationally why this uh uh text classified as objective so actually it comes with many benefits it's it's not only improve the output as you see for example it's now it's very confident based on the reasoning and it really can improve the quality uh in different workflows if you just include this uh reasoning step Chain of Thought step into your pipeline uh but it also can be used for your s to kind of present them the idea what uh why this can be labeled in this sense so it's kind of validating your statement you you can actually you can actually think of even improving this reasoning step and asking orators to fix the errors in the reasoning scenario if you see these labels there very effective and and actually can go further Beyond just the reasoning step but for example doing so called the self-consistency labeling so again like I described the scenario where for example uh me and like we me and Michael and Chris we start annotating um one text based on whether it's subjective or objective criteria and we might be disagree with our opinion about whether it belongs to one particular category or another and this is called disagreement produced the like the final wrongly labeled data set and a lot of bias in the final data set which should be fixed way before you start training your lar language model and spend thousands of the uh dollars in computing power so the same idea of like removing this agreement and kind of producing more robust labels can be applied in llm so it's called self consistency and there is even the uh the paper that will describe the approach so you actually ask you model producing not just one example but producing uh many outputs based on different type of the reasoning so you can see I can switch between different reasoning scenarios so it can sort of the simulation of the how the brain of anator works so we can use different reasonings and by different reasonings sampl from a large language model we produce presumably different outputs which then can be averaged for example on majority vote and hence like more reasoning steps we involved here the more robust estimation we can expect as the output but of course it's also come at the cost of generation if you pay for um uh for number for tokens generated by large langage model so I present uh this uh this way how you can improve uh self consistency and you can again uh you can plug it back your label stud scenario and then uh ask your to fix that but let's go to the final destination of our Dem today is uh actually how we can put this all automated so instead of just uh with all we uh we've been working so far is our kind of manual way of interacting with the instruct instructions and prompting which itself can be very error prone and uh and prone to bias because um and that's what we actually observed many times in the practice if you ask different prompt Engineers to produce uh meaningful prompts meaningful instructions for your uh large language models that can label the data they actually can produce different type of the instructions that's uh hard to merge and hard to understand where the ground truth is and hence the result is badly labeled data set which uh like badly trained model in your pipeline what if if we replace this manual process with automated process so actually what are we going to do we can actually start with initial instruction like and and consider this is like the set of the initial instructions we can use the instruction set which at the beginning contains only one one instruction to label the data then we can evaluate all our instructions uh like all the instructions against the ground prooof labels that we collect uh can continuously collect in label Studio see which instructions work the best and pick this best instruction and trying to adapt this instruction so so such as modify this instruction so that it can fix the initial errors so we fixed this errors and put this instruction back into our instruction set so iteratively we end up with the instruction set that actually can hopefully can fix all the errors we observe during this iterative process and since we implement this within the human in the loop we actually can put more and more knowledge continuously improving this uh framework so it's sort of the kind of free state agent that works uh without our intervention until we start kind of guiding what actually you this like agent should work with based on the ground proof labels so let's quickly go into the example so now we need some like generic LM labelers so which consist only uh only with in instruction like the the prefix to Pro to provide the input and the our output that we observ so far where we target is to have the object subjective so um I'm G to so there is a like uh evaluation instructions so this is Step where we evalate instruction and if we uh put there uh and start Evola instructions we actually obtain the instruction accuracy with this instruction which is like right now it's like d instruction and some errors that we going to collect to improve the model uh further on now there is like adaptation step the adaptation step is where you can ask to kind of having providing all this like providing current extraction That You observe plus you can uh get the all errors that produced by uh applying this instruction to label set but not the all errors of course because it might be like hundreds of them you can sample the errors somehow and uh asking large language model to produce the new instruction at the end so for now uh right now it can be more powerful like j4 which is costly but more powerful model because you don't need to run it all the time you don't need to apply this you only need to apply it once even more you don't need to actually tackle with your kind of Highly private personal uh data or sensitive data because now your question is only about okay have one instruction please produce me another one that fix all the errors I see right now so uh let's uh build up this function so it's like adaptation module and um yeah and now we can run this ad adaptation module to see how new extraction differs from our initial instruction so um it it takes uh a little time to kind of generates all the tokens uh and the background because but at the end we see okay this is our initial instruction just meaningless dummy instruction but at the end we see that now it produce very very meaningful results so besides the like input prefix we also see that it gives us the uh some sort of f shoted learning examples and some guidance and directions at the end even like okay super cool so now we are able to uh modify our instructions of the fly automatically without even human interventions all we need to do is just to produce the error based on our ground prooof data and and we can repeat this process which is called like optimizing instruction now we can repeat this process uh a couple of iterations to produce the our final optimized instruction so let's quickly go this we start with a very naive instruction which is just direct as Okay go again I don't know like actually I don't care about like what's the accuracy is because uh we may mistakenly label some data but the whole idea is there so just we start with a one instruction then we start reapplying this instruction and expanding our set of the instructions to produce more meaningful results so you see like the the quality gets up uh but uh compareed to your initial uh attempt and it goes uh more and more and more until it reached the final um kind of level of the quality so it's it's more or less kind of the optimization techniques uh but on the in the space of the natural language instead of like relying on the gradient uh distance related to the weight so as you see for example okay our first step produce the best accuracy ever so 0 so we started with just go and we end up with a kind of like meaningful instruction which uh if we uh can um print it out so how it's going to be it's optimize it instruction so all right cool so this is our instruction so it's it's not only gives the ability to apply this with a high accuracy out labelers but it also gives some like insights about like what language model considers internally to uh to make this labeling the best as possible so maybe even like this weird symbols actually matters I don't know from the label uh large language model standpoint and they actually dries the quality up it may be maybe not who knows that's maybe uh maybe there the way how it picks the examples maybe there some specific keywords in the text but the fact is it can optimize the quality purely uh based on this alterative approach uh without supervention and of course the final step is then apply this optimized instruction to get the fully labeled data set with the kind of expected quality we see on annotations okay so I I think I already kind of run out of time however there is again as mentioned before there are many more interested topic about how we can then turn this into kind of local inference optimize that so you can actually get this at a li speed iterations with this data set and give you the sense of you can like make this transactional logic about applying like um your auto labels to the data set with optimized instruction but that's maybe uh something we will cover in the next topic next demo okay I'm open to the questions if they have if we already kind of run out of time we can wrap up here so before we before we wrapped up I wanted to make sure that uh a number of people asked for the notebook um we're we're going to take a little bit of time to make sure the notebook's cleaned up and and and ready to go um I'm dropping a link into the chat here um which you should should be able to follow and request that notebook as soon as Nikolai has a chance to kind of like polish it up make sure we're not you know leaking any tokens or secrets into this right um uh we'll be happy to share it with you and uh yeah I want to thank you everybody for attending and um do we do we have a few minutes to take some questions uh there are some sessions happening now in parallel so I would suggest and I think a lot of questions were answered during the session right uh so to make sure that you know we we stay with the time my suggestion would be we we wrap it up okay thanks a lot thanks a lot uh for the great presentation and uh uh thanks for sharing the link to the notebook uh and uh yeah if you have if you have any further questions I think uh the folks are still available uh on mlops community slack uh and also in in gradual chat so feel free to kind of hit them up thanks everyone thanks for joining thank you thanks everybody for us thank you [Music] bye