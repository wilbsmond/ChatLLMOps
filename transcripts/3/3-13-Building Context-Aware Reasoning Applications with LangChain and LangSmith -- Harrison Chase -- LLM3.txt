you've got 10 minutes on the clock I'm excited to hear what You' got to say but we're going to keep it cruising because I am the shaman today I am leading us through this journey and you know how that goes it's all yours the stage is yours Perfect all right I'm gonna share this screen um and that should be in full screen mode now so there Perfect all right so today I want to talk about building context where reason applications with with Lang chain and Lang Smith um and so I'll walk through a little bit what that means and then chat about uh the two different aspects of that so context aware and reasoning and then some difficulties that we see uh people running into and I'll try to do that all in the next uh you know eight or nine minutes um and and so happy happy to chat more about this afterwards with anyone as well this is something we're thinking a lot about um so so just to motivate it a bit you know chat GPD is great um it is it is limited by kind of like the context that it has largely um so you can ask it questions about the data that's been trained on it's fantastic at answering those but you ask it questions about you know like recent information um private data anything like that and and it doesn't um it doesn't know that and so that's a lot of what linkchain was um built to solve um and so here is an example of a bunch of uh applications built on top of link chain that combine language models um with external sources of of knowledge and of computation and bring them together and bring them together in these context aware reasoning applications and so I want to break that down into a little bit because this is something we've we've kind of like we've looked back on on all the applications that are built on top of Lang chain and we think that Lang chain is best kind of like used to build these types of applications and so as we're doing this thought exercise what exactly does that mean so context aware means connecting the language model to external sources of data and computation we have a bunch of different modules in here to help with that there's different types of context that you can bring to a language model and they're all're they're different types no one's kind of like better than the other um they serve different purposes and and they have different strengths so first up you've got kind of like instruction prompting this is just when you tell the language model what to do and you're bringing it the context of whatever you tell it to do this is kind of similar to if you show up um to work on the first day and you get like an employee handbook that's that's telling you how the the workplace expects you to behave that here you're bringing the context of of your application and you're telling the language model how you expect to behave in this particular context after that we've got few shot examples this is showing the language model not telling so it's giving it examples of how it should behave um in in in particular scenarios with particular inputs and then then and then there's the particular outputs and it's using those to to show not tell the language model um how to do and and and this is this is really useful when it's It's tricky to actually describe what the language model should do so if I if I tell a language model to speak in the voice of Demetrius for example it's impossible to have um you know concise instructions for how to do that but if I give it a few examples of of Demetrius doing some of his wild intros it can it can maybe pick up on a few of those examples retrieval augmented generation is the next type of um context and this is probably like the most popular type of context that people think of when they think of context to where reasoning applications and and this is bringing uh you know context to the language model and then asking the language model to generate output based in this context so this enables question answering over private documents everything like that and then finally we've got fine-tuning this is updating the weights of the language model bringing into context the Thousand or so examples that you find tune on um and this is again good for cases where you need to provide the language model with a lot of examples that would be otherwise hard to describe okay so now let's talk about reasoning because you can provide context to the language model all you want but when you're asking to do some of these more complex tasks the language wall needs to be able to to reason about what to do um and so reasoning we kind of like Define is we've got some input and we've got some output and then what happens in the middle what is the language model kind of like orchestrating to to produce that output and there's a few different levels of these and and these are more levels increasing kind of like autonomy and so first you've just got a simple llm call um where you take uh the input and some context you pass it to an llm and you and you respond with that um and and that's kind of like the most simple and basic that you've got the next level up is chaining so combining multiple of these llm calls or an llm call to an action to another llm call and using that to generate its answer so still very deterministic you know exactly what you're going to do you're going to do this then you're going to do this then you're going to do this then you're going to do this and you kind of proceed along that and so an example of this is GPD researcher this adds this is this is kind of like a research agent very cool open source project I'd recommend checking it out the point is that there's a bunch of steps that it goes down but it's it's known ahead of time what the steps are third level's in you can now you now use the language model to decide what steps to take so there's different branches that can go down and so it adds some more optionality which the llm controls um and so I actually lied to you a little bit GPT research of the final step there's some routing going on and so it's not fully deterministic the final step it can route to a different prompt um and so that's a different step that it can take and so and so uh GPC researcher has a bit of the routing going on at the end importantly there's no Cycles here and that's the next differentiation between stage four or level four where we have these kind of like automatons or state machines and so you're still using the language model to determine what to do and what paths to take now it can enter into Cycles though and so this starts to become really really powerful um and so some examples of this excuse me some examples of this this is from baby AGI you can see here there's a few different um types of agents and it Cycles between them um and so it's basically adding uh uh kind of like it's giving different prompts to different agents and asking it to different things and it's breaking down the planning process into a bunch of discrete steps reflexion a similar one you can see here there's multiple LM calls and there's this cycle between them and just to ground it in a real world example we've got sweep. deev which is a coding agent and it very explicitly has this plan execute validate cycle and it can cycle between these until it's finished and so the basic idea here is that you have explicit steps for planning and validating or or whatever you want and breaking it down into these distinct stages makes it easier for the language model to to reason what to do as opposed to level five which is autonomous agents and you no longer have these discrete steps you've just got a single LM call and it's expected that inside this LM call it does all the planning all the validating and and and and basically everything is an implicit state in its head and so if we break this down into one chart we can see that we've got um you know and we've broken this down into what the llm is doing versus what the human is doing and so deciding what the output is that's a llm call deciding what steps to take now you start getting into like the router and the state machine and then if you define the state transitions the human defines those for the state machine in the agent it's up to the llm to do it implicitly in its head talking a little bit about the challenges that we see people dealing with when when they try to build these types of applications first up is just general orchestration what Subs to take in what sequence that's where Lang chain comes in handy we've got a bunch of these um cognitive architectures that you can use off the shelf next is data engineering bringing your data to the to the llm in the right format um again linkchain has a bunch of utiles for for pulling it in here as well as prompt engineering so you know the new thing here is uh language models you talk with them in prompts building that prompt up is is kind of like one of the most important parts and debugging all these things is is uh particularly tricky and so all the screenshots that you see are from Lang Smith which is our platform for debugging logging monitoring all these applic evaluation really hard that's probably worth a talk by itself and I think there probably are some people talking about evaluation um so I'm not going to go too into that but it's really difficult and then finally collaboration so collaboration not only between Engineers but also between product managers and and other people with domain expertise who do a lot of this prompting that's all I've got thank you for having me Demitrius it's it's really exciting to be here and I'll let you get on to the next uh exciting introduction dude dude Harrison it's always a pleasure man I really appreciate you coming on here as you know I'm guessing you're not going to say yes next time I do it because I just keep hammering that intro U but maybe one day we will do one of these for the Lang chain Community which I am hoping hoping for that'd be fun that'd be fun excellent maybe we'll do llamas and I'll make all kinds of other funny intros for you you just wait so anyway man I appreciate it look forward to seeing what other kind of cool stuff you're coming out with it's always a pleasure talk