[Music] Laurel are you with us I am yes hello um awesome okay yeah thanks everyone um so much and today we'll be talking um about some of the the challenges that um uh I've been facing at at a at a new startup called number station U really with actually taking these large lingest models um and deoy them on structured data T um and and going to talk a little bit about um uh a suite of a model that we released to kind of address address some of these issues um so I know we've all uh been in this space for a long time I what it's been a minute or two just kind of recapping um a little bit how we got here partially because it it really motivates um how these things are sort of lighting up and what what the challenges are for for deploying these models on production workflows um so again as we're all have heard on through many times by now Foundation models um at the core are just very very large neural networks trained over massive amounts of data but self-supervised learning and the key thing here with self-supervision is that you can train on data that doesn't need any manual engineer labels um to go and train right you can train on data that kind of exist naturally on the web um the classic example is the language modeling task where you literally are stubbing words the model and asking it to regurgitate you know the words next up in the sentence um next token prediction task for the most part and what this really opened up is the ability for us to scale our data to very large sizes because again we didn't have to go get it manually labeled so I could point to an entire you know from the last talk web craw dump even PDFs and trade a model over that now what we saw since around 2018 is era is also a massive increase in the size that we're able to train on this was both due to algorithmic um improvements as well as Hardware improvements um and so what you see here is a massive increase in the amount of data that we're training on and the size of the models that we're training on and what this what was Ed was this kind of open AI these GPT models um and the ability to kind of have in context learning which is really what's kind of breaking open um the application building space and at the core what this means is that you have one model that can do a wide variety of tasks without any fine tuning without any training just by changing that kind of input text that you're getting it again these models are blackbox text generators right you give it text it will spit out more and so what this means is that by carefully kind of crafting prompts um and inut these models they can do different tasks for you right so here are some VAR of simple examples of of um uh doing Capital prediction as well as maybe simplying something more in in the structured data space of like cleaning your data we formatting dates um you can give it a couple examples like you know a description of what you want to do um and then mods can go and go task for you now not only from the was this kind of just absolutely astounding that this worked um but this really changed the game for how we were building AC um and there's really three things that that I want to focus on to this top obviously it's um you know we seen with all the startups you know popping up around this there's a lot of benefits to these models um but some of the three really important ones I think are um this this notion about tactlessness um you know before foundation models even kind even in the Deep learning days with with Burt models and edting based models you had Fairly siloed pipelines and by that I mean you'd have a you know set of data a model and a task have kind of one model per T um and that meant that every model had to be maintained the data had to be curated um youd have mlop deployment kind of all those challenges um you know H have to be addressed as well but with these Foundation models you have one model um one model that sometimes you don't even have to host depending on on on how you use the model um and so it just makes a much more simpler pipelines that are much easier to maintain um over time so this other um another huge benefit here is this this notion of solving the cold start problem problem again these models don't need any data to train I can go and prototype a task and build a demo um in a day which used to take months of effort to go and sort of give a proof of concept that something could work um and so really all this kind of vast knowledge of how to do tasks and how of um different kind of information it's already latly in these models and so you can you can take advantage of that very quickly um again without having to go have that upfront cost of labeling data and this last bit um is the notion of deloc tizing access right you could argue that these models are coded via natural language right I don't have to go and know how to program to go and test out a task um actually for the most part build an application now do you see a much wider variety of people who are able to go access these models and take advantage of them um and this notion of natural language programming is just a very powerful Paradigm um uh to to to allow more people access um to to build off these models so the startup that I work at it's called number station um and we're we're kind of coming out of um kind of coming out of the Stanford um AI lab and we're really trying to apply language models to the modern data stat and in you know at a very high level and you know this kind of a very very simplified uh pipeline of kind of what the data stack looks like you know starting out with your raw data sources your integration layer then eventually move up to transformation layers um uh lastly to the business intelligence and kind of data analytics space and so this pipeline can be super complicated messy there's communication hurdles between all the different stacks and at the very high level number station is trying to use Foundation um technology kind at the top of the stack to help sort of um simplify and and make this process faster and allow users to gain access G insights to their data more quickly and in particular what I want to you know the the kind of core product that I want to focus on in this talk is this notion of data analytics um that kind of last layer of that data stack which is business users um business analysts trying to understand and then gain insights into their data and for lack of a better word take action on what what they want to do so how this pipeline Works to typically or traditionally which is kind of um shown on the left here um is usually a business analyst has a question or maybe a set of questions they want to see some dashboards um but they don't actually have any understanding of what's in their data they don't know the schema they don't know um SQL they don't know how to access any of this so typically involves roundtrip communication with data engineering teams sometimes even Tableau teams uh to go and generate that insight for them and and this process while it works can take weeks and even sometimes in the extreme case months for this business analyst to get an answer to the question um and so the high level Insight is that with these models again they're programmed via natural language which means theoretically a business analyst could just ask their question on a foundation model and the model could go um and actually generate in this case like a SQL expression for example to go and execute and get that result back right so the idea is um with with Foundation models we can go and allow business analysts to gain these insights with you know and almost in a self-service manner without having to go and spend a lot of time um you know ripping with data engineering teams uh to be able to to get access to their data so in theory and like you can go I mean there's tons of of uh uh sort of um uh tweets and videos showing that these models can do these tasks like text to SQL um so there's a lot of promise that thinking that hey look this is there's something to build here and something that can be very useful um to the modern data sta um but one of my one of my favorite phrases with these models that they it's building a prototype building a demo with a foundation model is very easy and very fun actually getting them into production and um it is much more difficult um and uh in particular I'm going to walk through you know three kind of core challenges that um I've been dealing with a lot in the last year um uh around What It Takes and some of the difficulties with again taking this kind of nice little prototype idea and putting it into production and so the first one that you run into um pretty much immediately when you're dealing with real kind of Enterprise workloads is these models are not customized right they're they're kind of Jack of all trades but they don't really understand the Enterprises um any sort of specific company's data or idiosyncratic language um or how users talk about the question um and so a very and it's is an example motivated from from uh uh from workb that I've been dealing with is so you know assume you have uh a table that's looking at sort of property data so you have a property maybe the city some some attribute that's called num wko and an an attribute called neutral and in real enterpr Enterprise data you get columns that are named things that don't make any sense to to you but you know there is in a subset of data Engineers who you who understand the semantics of that column and so the the qu the user wants to know what properties have a satisfaction score greater than 75% right they're asking from a business analytics perspective of like this is what I I want to know now the model if you give this to Tech jbt or kind of almost any model it'll it'll make a guess um and maybe it'll give you some some query that's looking at maybe the neutral being greater than 75 or something like that and it turns out that this is this is not a correct query at all um because the notion of what satisfaction score is isn't available to the model it doesn't know it was never trained on that it's certainly not clear from the data you have to go and actually get that Insight from the data Engineers who say oh satisfaction score is defined this metric is defined as you know the number of work orders divided by by neutral for example and so the correct query actually has this kind of business logic around what it means to have a satisfaction score and and without sort of customization or understanding how to teach the models how to be customized to an Enterprise they're not able to really handle these business analytic questions um because they just don't know the answers to to have business users talk about their data for Specific Enterprise so the Second Challenge here actually comes with the fact that that some of these models can you're you're lacking SQL expertise that are really needed to to address business users business users questions going back to what I mentioned earlier these models are are kind of Jack Trea they've been trained over numerous languages they are incredibly powerful but when it comes to some really Advanced SQL queries especially if you're looking at maybe open source models um uh you trying to move away from some of the private ones uh they really kind of fall flat when it comes to some of these kind of you know nuanced SQL queries especially with how users can ask for them um so for example if you're the the users again going after with this property data asking for some difference in um um in scores compared to the average of each City you know a model again will give you something um you know seemingly uh uh correct but but it's missing some of this kind of partitioning nested nested logic that can be pretty tricky forward right they're not expert SQL um editors and don't have again the SQL experts knowledge about really how to generate sqls so you were also Ed into just peely quality issues where even if it was able to get the business logic correct it doesn't always get the SQL correct um and now the last the last challenge is really addressed that I kind of hinted at this earlier with the fact that enterprises need privacy right and a lot of the models a lot of what you see today are being built off of third party models um third parties are going outside of the Enterprise and deep in that you know they they um their kind of private Network and so oftentimes even if they wanted to engage with this technology they simply can't um they don't want their data and especially their data schema so even their business questions leaving their um the company and so they really need to be able to host um models that that are can be hosted locally um within their Network and you're seeing you know companies um um trying to help address the situation um but really there been a bottleneck to sometimes getting some of these these tools deployed in production is the fact that they don't want to use these third party um models behind API walls okay so I just kind of quickly went over these these three challenges around customization quality um and kind of this notion of of local hosting um and and so now I want to talk you a bit about what we did at number station to to start to address this problem um and really lean into the fact that we want the open source Community to have access to models um not only that can be can use for Enterprise use cases but also for academic use cases for for anybody and so this is our what we ended up doing again to take a first step here is actually go and and say hey look let's actually build some models ourselves um that are good at this sort of SQL generation at text to SQL tag um and then we're going to release them and sort of help them be open source and and release a whole Suite of models that can be used by anybody um and so we went and and did that so we um uh we have about four um nsql models I'm now going to start to to kind of um uh now you know explain how they're how they're really helping us address some of the challenges I mentioned I mentioned in the last couple slides so the first one is that these models are fully fully open source for for academic and commercial use and so this notion of of being unable to to the models that lacked personalization you now have an option for personalizing them now I'm not solving um solving this issue per se but at least there's an ability that I can go and one of the natural cases that have been talked about in this in this sort of um event already is this idea of fine-tuning of your own data um and now that these models are open source and available users can go and take the models and start to customize them so they can start to understand that business logic um and how users ask questions right so it's opening the door for these models to be personalized to really address that customization issue that I mentioned earlier about kind of some of these third party or or or sort of general purpose models um so the next one is this idea of um lack of SQL expert Che um and for us and I'll I'll explain in in a couple slides these models were trained heavily over sort of heavily currated text to SQL data um and and so the hope the idea is that these models are actually somewhat of SQL experts themselves you know there obviously still work to do um but they've been really focused on people they don't they don't know python they don't know other coding languages they lost some of the generality of these big models but are kind of becoming Nuance seal experts and so with one of our versions of the model you can actually start to get some of this nested um more tricky SQL logic that these models can understand how to do because we' again focus them on SQL right so we we don't want them to be to be these General models anymore but they're they're heavily focused on SQL and so here we're dealing with some of the quality issues that we saw earlier with some of these open source models um not really having the SQL capabilities now this last challenge I mentioned was really around the fact that that um Enterprises couldn't you know couldn't always rely on third party models really want want to be hosting something on print well and so one of the things that we did to really try to address this challenge is not just release one model but to release a whole Suite of models at different sizes and the idea here was to really make it easy for Enterprises to kind of satisfy their own Hardware constraints and their own latency constraints well for for their for their for their business so they can kind of you know you can flexibly handle the trade-off themselves of what quality that they wanted U versus the difficulty of hosting it and ending in the speed generally speaking bigger models are slower and more expensive to host um but if you you know provide them a different kind of set of sizes again Enterprises have some flexibility and what they can do there and so the Hope here was that together these models allow for enterprising to really um address issues around quality they can out customize the model and again they can out host them locally um so they don't have to again be be accessing the parties so I'm going to spend the last uh four minutes talking a little bit on how we did it and then and then going into a couple high level results here um so at a high level when it it came to building these NS SQL models um it it was really this two-step approach and all focused on the data right as the last speaker said which is so true garbage in garbage out and so the data creation beta was 90% of the effort and so we ended up doing was actually having kind of a two-phase training um uh training approach uh and the first is this notion of sort of focusing the model and SQL we went and we scraped a bunch of SQL queries just from the web from from open source um repository and just for lck of a better word shoved raw SQL at the model um and did sort of the simple next token prediction task with the hope that it would start to learn kind of um keywords like SQL keyword SQL query patterns um a little bit around comments um and so you got this pre kind of pre-training phies over SQL um and then the second step was this heavily curated data set we constructed which is a had about 300,000 um pairs of instructions schemas and then the output SQL so it's basically a very curated set of text the SQL data that is teaching the model how to follow user instructions that actually fit out the correct SQL so after you pre-train the model you kind of have to F tuning instruction tuning phase over textas SQL and then the result is is the NS SQL model suite and so the Texas SQL data also if folks are curious It's also openly um available on hugging face or so please take a look um uh all the sources that we use were open source data so um all available on the web uh we did a couple tricks um around augmentations and and getting some of the questions labeled but but for the most part they were um again everything was was um just a lot of scraping and cleaning on our part so um uh so again please please take a look if folks are curious so at a very high level I want to briefly touch upon how how these models are are kind of you know addressing some of these these quality issues and starting to close the gap with these private models in terms of Texas Equal capabilities and so we have um four models um three of them are based on the coed models from Salesforce which they do an incredible job with their models and then also the very recent um llama 2 model um and so again we have these four models and so what you start to see is that immediately especially once you're you're moving into the multi-billion parameter model um uh the NS SQL models are kind of outperforming available open source Foundation models when it comes to Texas SQL even ones that have been trained specifically on code and this is looking at a very standard academic um Texas SQL Benchmark called spider um and in particular you see the lawn model um uh which is following the recent Trends in you outperforms um outperforms the rest and what you also see which is which is very exciting is that they're starting to also close the gap with proprietary third party models um and in particular um on this um on this bitbar some of the the Llama version is competitive and and on you know matches performance with with the gbg4 model released by open AI so you do start to see that if you're focusing the model and sort of specializing on a task not only can you get away with a smaller model it's only around 7 billion parameters but you're also able to match performance these very large proprietary models and in part because these the proprietary open AI ones have to be very general purpose they have to address a bunch of challenges whereas you know in this case you can just focus on SQL and and and mass performance now the last little kind of interesting thing to to hit at um is that all of this training that kind of twostep approach is actually really important to turn on quality what you see in the light purple it's like the base model performance the sort of middle bar is saying hey look just after pre-training we're starting to see lift right it's already trying to you know starting to understand SQL and then really that last Little Instruction tuning is kind of what turns on performance because it's learning how to pay attention to to to how a user ask um so to say that all the training again the more data the more high quality data the better um and you do start to see kind of a consistent Trend depending on for for both phases of of training so that's pretty much all I have is sort of again talking about what it takes to deploy these models and production um uh you know challenges around the customization and quality um and be able to host them privately and how at number station we went and actually built a bunch of models and released them on the open um to let users GO train customize and host themselves so do not hesitate to to reach out with any questions um links to the models and the data are all the slide um and we also have some some blog posts if if folks are curious so thank you so much and I'm happy to to answer any questions thank you very much Laurel this was absolutely fascinating uh we already have a couple of questions up on gradual uh and this is already something that I was thinking about too if you can move back to like to the slide where you guys were uh well at least you mentioned cleaning the data so one of the issues that you had was that I was thinking about well how did you even come up with like with the language to SQL pairs in the first place and then you said well you went and you scraped it all but then you had to subject it to a relatively rigorous pipeline of cleaning what did that cleaning look like and did you manage to do this in an automated way how opinionated is the cleaning process yeah I think it was this one yeah yeah know that's a great um that's a great question and we um a lot of it was taken um so usually we start out with there's a ton especially if you're kind of tricky with how you search for these things a ton of open- source kind of academic benchmarks that look at text to dashboards text to SQL um text to data like there's a lot of text to XYZ and so a lot of it was us kind of curating um and figuring that out and a lot of cleaning was around simply making sure the sequel is executable making sure the schema match the sequel oftentimes youd have mismatches across you know data was just messy in that s you had to have it kind of be answerable and so a lot of this although it took time was all all automatable once you kind of understood how to use a SQL parser and and how to kind of do checks and make sure things were runnable um the most interesting piece to me is that actually what we ended up doing is sometimes we'd get high quality SQL and schemas but the questions were garbage right the questions either didn't makes sense um and a lot of this was just us manually looking at errors um for and so we see data entire data sources where the questions just couldn't be trusted um and so in that case what we'd actually do is use other open source models can't remember which one we use we have to use lwas for this um we actually used open source models to help us label the data so we'd start with the SQL um and we'd have the models generate text for us um SQL is very again as that the whole problem is that going in the forward direction is hard it's hard to have bottles really output good SQL they're really good at explaining sequel if you give it to them um and so you could actually leverage open source models to label a bunch of data um uh so that was another thing we did and then also there's a couple tricks you can do just with augmentations where you can go and like expand your your test set or training set by kind of swapping out different order by Clauses or changing up different um uh things in the group by like little things like that you kind of make deterministic tweaks to the query and then again go get the question reeled um so at the core it was like a lot of parsing um and a lot of sort of schema sanity checking and then again using models should go label data for you which is a a very interesting Paradigm yeah so then you must have also then used okay so perhaps this is what you're saying you also using models to then uh classify the quality of the question too so like how would you know if you have 290,000 samples uh to have people come in and just like sanitize or clean uh or even throw away discard bad text would you have a separate model that kind of classifies the Badness or goodness of that text you put we didn't again we kind of just looked uh I mean there were three sources so this case there was a little Manual of us just looking at each Source um and and making sure that the that we thought the quality was was good enough that certainly not everything's perfect the other idea is that if you get enough data you know you could handle a little bit more noise um so the smaller the data set like the more curated it needs to be um uh but uh so so yeah we kind of knew beforehand whether or not the source needed to be relabeled um but you could imagine um uh using more I don't know I would have relied on a Model to tell me yes or no but you certainly could have done things around hey look if I send this question to 10 different models and they all give me wildly different answers it's probably not a good question like it's too vague it's too ambiguous so there are a lot of things you can do that like take advantage of the faculty models are noisy to actually understand how trustworthy the question is um we have a few more questions here I'll try to serve them in a rapid fire sort of way okay great uh what flavors of SQL andc transact uh does this work qu yeah so right now just um uh uh SQL light but we're we're actually actively working on on um adapting it to a couple other other dialects that's not too bad you can kind of use existing transpilers to kind of go between dialects but um uh yeah right now just SQL SQL L okay Jimmy here is asking wondering if they're able to get the matching table schemas that SQL queries were based on yeah yeah yeah so this data especially the instruction one does have all the schemas there um it's it's um you really don't want to do Texas sequel without you can it just doesn't give you anything that useful so yeah all the ski was are here which is made getting data even harder yeah we got one from Dov is there a similar model that is trained to only answer in Json yes well not not from us there are some uh acmic works that have done text to Json or at least um text to uh some some of them even used proprietary models like there's a whole um open source product called garbage which uh helps you like get your output to always look like Json is one of the many things that it does so a lot there is some work in that space um uh yeah yeah we got another one here from Louie to be able to use nsql Lama in a company you need to have self-explanatory column names right and as the prompt is the table structure what would you suggest if the columns are not self-explanatory yeah that's a great that's a great question so a couple things that you can do there um the two big ones are um trying to get any uh there are ways that you can actually go and like get a fairly good semantic description of a column U like sometimes you even literally go have a model rename a column for you so you have like a translation layer um if you give it examples of it of the column itself often times the model can be like oh this is an identifier or this is um uh a specific uh type of variable so I'd probably look into that basically either describing the column or or kind of having some kind of model friendly train pleas um the other thing is just simply using in context examples showing um past questions issued over this table can often times be really helpful for teaching the model what to do it'll see patterns between like oh when a user asks for you know XYZ the mo you know this is the right column here um so a lot a lot of stuff can be done within context as well to kind of further customize the model cool a couple more here am I correct in reading the slide that you trained on spyer queries as well as using spyer as the evaluation set this is from um so we had a um in the in the blog post we have an evolation that looks at um so spider itself is there is um uh so with some models that were again in the BL so the one that we fully released we trained over the spider training set um because the the the databases there are fully are fully separated um uh we do it in the blog post show oblation training on no spider at all um but for the for the open source model we didn't we train over fighter training because we just wanted the absolutely best model that we could um uh yeah so again but take take a look at the blow we do have some stions there I'm going to try to squeeze in a couple more couple other ones uh from bves most use cases involving queries like SQL or say bash scripts would be deterministic um how at all something as stochastic as a large language model not to mention the vagueness in questions can be used for these and perves is mostly considering security issues I see so like how to prevent sort of potentially even nefarious sequal queries um yeah so I I will say the uh I I don't have a a fixed answer besides um there are a lot of guards that you have to put on the sequel query itself so the model is that one but you should often times not actually let the user have completely open door access to that like there's Val validation that you can do on your end by like you know simply be like is it executable is it touching these sensitive columns um things like that on the output and you can even kind of Reas the model to change things up if you think it's making a mistake um and also having really good auditing pipelines for users and data Engineers like the goal here is not to replace engineering teams because these models again are noisy it's more to help them do their job and and allow business analysts to be to be more self-service so there's a whole product that needs to be built out around these things to address these very these very questions um uh but those are all like it's still and sometimes it's still Evolution they like you know as you said it's not perfect and and and there won't be um so it's really about how you build a product that handles this noise I know where're running out of time and uh up next is a musical break so I'm going to take the Liberty to just ask you one more quick question uh have you thought about this or like how do you think about almost like a like a single shot uh llm query versus more of like an a an agentic framework where perhaps an agent is able to First understand some aspect of the problem and then gradually plan various sub nested C Is there a way in which you can sort of like build a more complex topology of uh querying the model yeah I don't again I think yes but I think also a lot of it is actually not only does it help quality and it's kind of I mean also interesting um but users often times there's a limit to what they can express in a single question right you'll see queries and logs that are like eight levels of nested with five different CTE and there's no way a user is going to ask that question worker shot either so actually when you do really want to be building a kind of multi-step pipeline where you either building the query in step in steps or like having intermediate checkpoints um but it's also really based on giving the user Trust of what's going on and engaging with them so that in essence what you want is the building blocks to be single shot questions um uh so so yes like you have to get there that kind of I don't know if I'd call it like a fully automated but like you want you need to be able to decompose stuff because otherwise there's a whole school of queries that like I don't even know unless I'm like writing an essay I don't know how to even describe it in natural language that's another another interesting thing that like for the first time Texas SQL is actually running up against which is like what's the limit of what a user can ask in a question um uh because like before models W even good enough to even really get there and that's where we're star to see this happen now where you have to post it and break it down Laurel we have uh thousands of people at the conference today and I'm seeing raving reviews uh about this talk so thank you very much for joining us great thank [Music] you