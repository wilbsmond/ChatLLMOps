Quantum black is a center of excellence in Ai and machine learning at the mckinsan company we are focused on building machine learning models and leveraging them to really improve businesses and drive their performance so we have offices around the world with perhaps a major Hub still in London and this is exactly where Daniel and I are joining from we will be joined by our colleague based in Brussels Pascal um and yeah like today we wanted to share with you some of our learnings from the last few months in terms of challenges and opportunities that we faced when we're building data science Solutions with llms so um I'm really excited to be here Daniel perhaps would you like to introduce yourself before we begin [Music] in the London office originally physics PhD and yeah really excited to work now on alarms and actually brings them to clients wonderful just in time indeed thanks for joining us you're joining us from Brussels right I didn't lie Amsterdam yeah [Music] backstage area um so yeah um today we wanted to talk to uh our lovely audience about the challenges and opportunities um that we faced when building data science Solutions with llms and um we represent our strong community that is of course very excited about all the latest advances in large language models on channel AI in general and of course things are moving really fast and sometimes it's really hard to stay up to date with what's going on and um things really um um sometimes feel like they get out of hand so we really wanted to focus today on things such as risk and compliance and all the important guard rails that need to be in place when we actually start deploying these models and start bringing value to the end users um so Pascal uh perhaps given your background and I would also love you to say a few words about your uh your background before you join QB and uh at QB um yeah like who would want to hear a bit more about um how software engineering developments and innovations that happened in the last few months affected um the trends that we see in using llam's and in building data science Solutions with cell alarms so of course you know for a long time llams and really had a very high entrance bar and we're really a matter of a few lucky ones but now we see that the applications are really Rising every single day and like it feels like they're growing exponentially and of course a lot of this acceleration is really enabled by apis that are now exposed and that would be pretty interesting to see your take on how other Innovations are really um affecting this democratization of Technology oh yeah sure um yeah so maybe I'll just share a little bit of like how we approached it so essentially a couple months back I think the whole world got overrun by uh Chachi BT essentially and it was in everybody's uh on everyone's mind um I think the moment when your parents-in-law start chatting with you through translations from chatavity and your fitness trainer um just says okay to based class was activity based um you realize it's mainstream and it kind of reminded me of this a couple of these memes back in the in the blockchain hype days whereas like when your taxi driver is asking you what the latest is on blockchain then you know it's time to to jump ship um and so I just realized or we all realized okay we have to get involved here um and um and I applied a little bit of my my data engineering background which like I built two or three years of data platforms and uh have a lot of kubernetes experience um and we looked at what was out there on the on the cloud providers so this is like Q4 last year um and we very quickly hit the boundaries so if you look at gcp it was impossible to host these large models they're just too large so vertex didn't support it sagemaker there wasn't really anything there um Azure also wasn't it wasn't yet so clear How Deeply integrated Microsoft and uh and open AI are going to be so we realized okay there's definitely nothing not anything out of the box um and so let's apply what we know which is let's use kubernetes let's see how big the machines need to be um and then let's try and containerize it and bring it into a world where we can apply our existing knowledge around machine mlops and hosting let's say normal machine learning models for smaller ones um and get them to work uh and so we looked at Frameworks like uh Selden and McKinsey also has uh recently acquired egrasio so we also looked at that um but we then again hit this this threshold of well it doesn't actually fit on a single instance because some of these models were so large we couldn't fit them on a single kubernetes node um and so while all of the tools were there they weren't meant to handle 300 gigabyte models because of course Daniel and I instantly wanted to load the largest blue model because why wouldn't you start with the largest one because then everything else um becomes easy afterwards uh yeah and so like we and it actually ended up making everything work we used Rey in the end because Rey allowed us to uh cluster across multiple nodes and spread the spread the model across different instances and it also just felt more mature because Rey comes from the same people they came up with spark and Spark just became so democratized or democratized big data so much it felt like a right move so we switched to Rey and got the blue model running there um and then also looked at other models and got some of those running and so now this is two and a half months ago and I feel like it's completely obsolete because somebody ported everything to C plus plus and then colleagues sent me pictures of them playing around with Bloom on their iPhone um and so like if I just take a step back now I realize we probably don't need the complexity of kubernetes anymore vertex just announced that they are going to have llm support sagemaker didn't really make a big fuss of it but they also supported now uh Azure supports it now um the models become much more tameable again because people are showing that seven to nine billion models are also super useful and um the space is moving so quickly that it's actually really fun to see that code that you thought was a really good idea two months ago and soft infrastructure that you've built two months ago uh you can pretty much get rid of because you can stand at the shoulders of giants from Google and Amazon and not handle a kubernetes cluster because ultimately that's just a lot of work for for very little benefit so yeah that was kind of our our journey over the last three months um you know it was still very good to learn because we learned about all of the infrastructure challenges that you have when you're trying to make these things work and you're trying to provide sufficiently large GPU workbenches um trying to bring these models in a way that you can scale them up and have Auto scaling scale to zero is very difficult um but then I think taking a step back again realizing to build a product it's not necessarily to pick the coolest technology but just to get the job done and turns out chances are the you know hyperscalers are going to be able to to help us a lot with these things perspective this is very helpful Daniel yeah given that you were also one of the the cameras do you want to comment on your experience and also given that you're coming from a bit of a different background and how was that for you um after there's a journey in the last few months was uh super exciting so I think one of the use cases that really stood out on our side was the whole topic of uh document based question answering so I've been starting to play with this um in the second half of the last year so just putting together on Smart prototypes nowadays in pretty much every industry so uh from final sustainability over Healthcare education you name it people do face the problems that they have to ingest huge amounts of information and usually they're looking for some very specific insights from you know a range of documents structural data sources you name it so one of the tools that we listed out and were there was really exciting development happening in the last few months in this line chain um by the way congratulations if anyone is here onto college you know raising this 10 million seats around and the parts that most people are getting really excited about is that it allows you to take these well chat equity which is already really really good at answering questions from a vital range of General problems to really Taylor it to the specific problem domain also another big Advantage is that by providing resources you would use the hallucinations and on top of it you have the chance to validate the model outputs and cost check them so that's a topic that because at the moment uh yeah and Daniel for you as a data scientist did you feel that all these new libraries got popped up and um were like developed by the community really helped to democratize access to other lands not only to the data practitioners but also to The Wider population um I would say it definitely unlocks a lot of capabilities that you know most people wouldn't really have seen two years ago I guess uh people were working already previously and saw what's possible with dbt3 got early access to the API is very aware of what can be done but you're currently seeing it yeah along its mass Market especially thanks to the hype generated around chat GPT um one minute um do we maybe briefly go to the commands we are seeing here so there's a question for Pascal uh could you please share the list of tools you used in the last few projects and a second question about infrastructure challenges any specific ideas and tools helped you to fine-tune the Beast I guess that would mean biggest models um yeah I'll so the first one um we try to stay pretty Cloud agnostic because um in general it felt like if you if you can somehow get into the kubernetes world then it doesn't matter if you're on premise whether you have um a a cluster in one of the hyperscalers and you can imagine that also a lot of the very large Enterprises which are often McKinsey clients are um they tend to have still a fair bit amount of on-premise stuff um and that's actually your super interesting World in which it's fun to to apply this technology because um when you have all of this knowledge that's kind of locked up in some on-premise systems making that available of course is super attractive but um what seems to be a bit of a pattern there is you bring the data to the model or do you bring the model to the data and I think a lot of companies actually prefer bringing the model to their own data rather than sending all of their data to some other Pump Company and so we went for kubernetes and then um I think state that open state with that open source stack so kubernetes Prometheus grafana Loki for all of the like you know non-functional tooling and then um let's say on the on the llm stack it was really kubernetes um of course making sure the GPU uh or the gpus are available for the pods and then um we had Rey or array cluster running on top of kubernetes because it then allows us to apply or to deploy a model across different modes and we used Alpa in the end which was I don't even know when Alpha was released um to get the very large models running um and then I think for the second part like what the um what the challenges wait okay um perhaps you don't know you could also comment on that yeah Daniel do you actually think what we used is still applicable because I feel like I just want to get into the new tools that were released over a lot like deep speed I want to get involved in or I want to try yeah deep speed uh was a useful tool so that made it really really accessible also we see uh you know accelerated equation from hugging phase I'm really really excited about trying out a deep speed chat so I was just like yesterday or today in the morning looking at the performance figures that they gave on you know what kind of machines you can use to find tune aux30b model and hey you can do it on one instance 8A 100s spend a day or weekend on it that sounded very promising yeah some some more questions specifically on the bloom project here from the chat so any any thoughts on that Daniel um that was of course one of the few large language model options uh generally available that you can run your own environment and find you into specific purposes so yes we used it for that I think fine-tuned it yeah a lot of the world used llama right because that was or a lot of let's say a lot of the people that publish online um because they're just doing it for research they all use llama and so that seemed to over the last month and a half or so make the most progress anything that's kind of a llama derivative but if you do anything commercial you can't use it all of the meta models are Untouchable essentially and so Bloom was the only one that was really feasible and now I think databricks came around with dolly so I'm also very keen to look into that because can we now use the innovations that we've seen over the last month and a half with alpaca Etc apply that to a private to Dolly and see can we maybe do a fine-tuned model that is specific to a to a domain like an insurance document specific model or something that um I'm pretty sure most people know like the the medical literature fine-tuned bottles I think that's super interesting to see indeed so before we move to the next question from the chat I wanted to address another question to Pascal so uh yeah we see that indeed as you mentioned the space is moving so fast God knows what's going to come out in the next week and how this is going to change our ways of working um so perhaps it would be interesting to get your view on the existing limitations that you still see in terms of the infra and Tech architecture and perhaps you know like the big breakthrough that you believe could help us overcome these limitations I actually I'm getting really positive or becoming really positive about it because I feel like um we're getting to the point where if you just want inference like I think we have like these three stages right if you just want inference that's pretty simple at this point you want to fine tune that's harder but still pretty doable and then if you want to train from scratch of course that's complete completely different Beast um but just the inference bit we're getting back to the point where it's it almost feels like just another model they're larger but um the platforms they're adapting pretty quickly and they're making it visible so then I think the major part of work is not actually going to be the llm but it's going to be all of the other engineering that we already know for a while it's just it takes time um if you want to do question answering like Daniel refer to you need to have a vector store and that Vector store needs to be integrated and you need to have some form of process flow okay the user asks a question you want to enrich that question with additional context now you send it off to the llm you want to keep your risk and ethics checks uh involved there as well so you need some kind of um process flow that organizes all of this and that's classic software engineering requirements which I think we'll now again see that you know there's there's the entire complexity of building a product and then the model is just one small little piece it's an old image that has been used for a while but I think we're going to come back to this where llm is just a small model in this larger bucket of thinking about the product thinking about your um the technology stack where's the data if you can't if you if you don't even have access to your own data because it sits in so many silos then it's very difficult to bring it into this one vector store indeed indeed and it almost feels like you know with very very similar to what happened to you data science um when envelopes became a thing it's gonna yeah like the new advances in general are gonna disrupt uh the skill set the data scientists and machine learning Engineers need to have so would you would like to share a perspective on what you would you would recommend data scientists and the engineers to develop as a skill set um as we move forward Daniel do you want to do the data science first um I think you have a college go ahead okay uh yeah so from my perspective like data engineers need to be again more and more software engineers um I often have this feeling like if you if you talk to people what is a data engineer you either have the campus former software engineers and now just do a lot of data work and then you have the second Camp which is I write SQL queries and um sparkcode and I think that second part that might not necessarily be the most significant uh skill set anymore but the first part of bringing a large complex software engineering project together and connecting to all of the different software Data Systems and bringing those data assets into one place and making them available for the llm that's something I would focus on and definitely look into like vector databases are so such a curious new kid on the Block that I haven't learned about in University and now it's so obvious like why wasn't this always a clear database style or Paradigm that everybody always talked about thank you Pascal yeah please standing I'll go ahead and I think this is also a nice segue to our next set of questions of course so on the data science side I have to say compared to traditional machine learning where it's usually straightforward okay you have your r squared and now you're trying to optimize for it by adding features to gabapometer tuning sometimes uh the whole prompt engineering Etc feels much more like a soft science so when you're only a consumer of these large language models in general we'll take question of how to evaluate the quality of the output in a structured way is a bit of a tricky one and I haven't seen a good off the shelf solution for that yet and other than that I think it's a matter of new field so you have really a chance to be creative and come up with new use cases that get unlocked with last language models so yeah um so they also pick up the value and custom tokens question or so yeah let's perhaps leave it to the end I just really wanted us to talk a bit more about um an actual um example of the application and um yeah perhaps Daniel I could share a use case um that we've um we've worked on at TB and what exactly takes right like to build a solution end to end so Pascal started describing the flow but it would be very interesting to hear from your perspective on yeah what exactly needs to be built to make this whole Machinery work yeah of course um let's maybe stick with this um Lang chain question answering example um it's a foundation but the foundation model as the name already says um in the next step needs to be enriched with uh the additional data stores as Pascal just outlined so set up your actor database in just also one of them data make sure the permissions Etc are appropriate potentially depending on you know if you chose the API consumption yourself hosting would you might have to tailor the model a little bit so for the public domain for the use case on top of it there's a few other layers that you have to build you need to build the whole infrastructure together feedback from the users so you actually have a chance to iteratively you models you have to put in place actually a good amount of risk infrastructure both on the input side so when users asking the questions so you don't have one so you're reducing the likelihood of do anything now moments and also a review of the outputs to make sure that you know especially if it's but available to a wider Bond of people in the organizational externally the output is again filtered and then yeah you have to build think about the whole ux perspective UI perspective especially if you're thinking about use cases that are going Beyond hey I want to put a chatbot on my website just a little bit better so if we double down on this question of validating and evaluating the answers which of course in the case of um a textual data becomes much trickier than just like checking performance of your model where it's just r squared or you see or whatnot can you share any thoughts about how that can be improved or committed accelerated and yeah if you have any um any learnings that you could share with the audience I would say there are two or three potential avenues that you can take you can try to go with the Swiss Auto Value attribution and automatic validation you can try to use the fact that the underlying models are probabilistic and not just generate a text but what are the likelihoods for different outputs and potentially it's also possible to move towards more automated evaluation methods so we're thinking about the approach that is take in real possible learning from Human feedback with a small quitting model now of course this is all still you know properly evolving at the moment as well perhaps you you could also share your perspective on um yeah how you see that part of the whole flow in this solution with further automated and and improved um yeah but if you don't mind so Daniel just or Daniel's description particularly in regards to the risks um made me think a little bit because I know that or most of us I guess know that open AI invested very heavily in aligning the model and making sure that it behaves in a certain way not in other ways whereas these raw models of course have not gone through this kind of alignment process as much and so in theory um as we have more and more of these open source models available and deploy all over the place we have to replicate all of these risk safeguards again and again and again um and so I was just imagining all these different organizations having their own model that can do all of the or will do all of these things that we've seen with Bing initially were being um just says I'm tired of answering your questions and ask me something intelligent please um but then I also wonder is this just a phase where for a while we're all going to have a lot of fun um breaking these models out of their out of their cages but then at some point it just becomes boring because ultimately I think then we've all tried it once just like we've sent memes on WhatsApp um but then at some point it's just a tool and we all become a little bit more mature about it and just get on with our lives and use it for the problem that we're trying to solve I don't know what's if you you shake your head Daniel yeah let's see I think uh the human nature of trying to break things and getting unintended reaction is not going to go away anytime soon yeah true yeah I don't know if there's any good tools or Frameworks in regards to risk and compliance that I would feel like are a drop-in solution and just take care of it for you that's probably something interesting to watch I think this is very interesting because you know like even before I um was a thing um in traditional Amal and AI it took us years to come up with some Frameworks like not just the general framework but some Frameworks around risk governance and compliance and ethics to Monitor and like have some ideas on yeah indeed you know our models are prone to be biased and we need to actually do something about it so I believe yeah given the the pace at which this technology is evolving like we definitely need to move faster but I have a feeling based on um how that's been so far it's gonna take us you know like months it's not years yeah but yeah like um this is very interesting that you mentioned that of course I guess part of the validation part and definitely a layer of risk and compliance is extremely important and especially when you start working in organizations with their internal data this is becoming even more important um and uh yeah perhaps just like to finish it off um Danielle could you share some of your experiences with um with the organizations on how the approach how open they are to this kind of systems I would say it's a lot of enthusiasm at the moment to use you know gen AI mainly inspired by jtbt one of the biggest challenges is to manage the expectations since it's cool to go to the website you enter something you get a response but of course it's really expensive as visual subscribe so there's still a lot of steps to go through um maybe also on the west side of using these tools I think at least in the beginning it's a good idea to have humans somewhere in the loop especially when it comes to uh but outputs that are being used Downstream and posters that might affect individuals so I wouldn't completely go on because that automation yet and yeah I'm not sure I'm just talking to if you want to go Victoria um I actually believe that and this is yeah we went full circle in uh I would actually want to pick up some questions from the chat uh so I see some of the questions already dropped here um specifically for Daniel so the one I'm gonna read out loud I'm also playing with long chain and also baby Aji okay good start I wonder how do you think it can be used for commercial these kinds of tools require generating lots of tokens and can be really costly so yeah let's discuss the cost part of it um actually that's an interesting point yes [Music] it costs a bit of money to use the large language models and in the beginning I would have expected okay to get a good answer um you're going to pay let's say a dollar question now a few weeks later there was the announcement yeah we are having uh GPT 3.5 turbo and the cost of reduced by a factor 10. and you know suddenly you move to 10 cent and you're like oh okay that's a good price with probably further reductions uh coming in the future but more providers ultimate marketers comparable models and bonus to become more efficient um also I would say commercially yes it costs you I mean worst case let's say a dollar to answer a question but if to get a similar answer you would have a human spend half an hour going through multiple multiple documents control effing and then writing up the answer um actually that might be a dollar of aerobic sponge so it really just depends on the use case that you're exploring I would assume the economics would be very different if you're running a public-facing website and you're trying to finance the service that you're providing only with ads in that case the cost of function will provide of course play a bigger role I mean I had this question is going to be an interesting one because the whole ad business of the internet is currently being challenged so you know how much can you rely on an ad-based business model of a website to to solve your problem if the technology that you're now leveraging is actually challenging that ad business model in the first place what do you think about that one I don't have a qualified opinion about that just time to perform it um thank you I think I like the point like um never underestimate your the value of your online if it saves you 10 minutes that's 10 minutes you can have quality life if you know for a walk I think that's probably worth a hero for most people that's a great philosophical spin on that Pascal um so yes next question to you then uh I imagine that European companies especially in financial defense are super hesitant to use U.S cloud providers or us-based API Services given the US Cloud Act um so I don't see the second half of the question but yeah I believe that the worst um some requests for the commentary on that um and yeah perhaps you could share uh your opinion on how that's going to be how that needs to be managed and for the European Solutions no I think we just got the second part of the question oh yes the competitive disadvantage of the new companies due to the to this regard to llms and to what degree can we get something working maybe community space within this reality uh in the EU so I mean I don't think that this Innovation only happens in the U.S um if there is a sufficient I mean there's there's close to half a billion people in Europe um and that that's more than enough of a market for for companies to say okay let's let's create a similar offering in Europe if that is if it's worth it if there's a commercial value in this but maybe um I'll not go on to the European level but I do think there is a huge value in creating a product that feels almost like a document QA in a box where you commoditize it to a degree where a smaller medium Enterprise can just take one of their virtual machines or their virtual appliances and then install it as a web interface and then you load a whole bunch of files in there you just drop them all into a folder on on the Windows File system or on a Linux server and then you have this document QA in a box I think that is something that is super democratizing and I wouldn't be surprised if that comes out and not too long for now and that would resolve a lot of these arguments if I don't want to send data to wherever it could be us could be China it could be Europe could be Cloud it could be to my competitor thank you Pasco so yeah I believe um we're a time any final thoughts remarks comments um I would say it's super exciting at the moment and I think there's a lot of interesting things coming up but once the reduction also cost for training influence um additional open models coming out hopefully it's a whole reinforcement learning agents on top of it distillation of models and all those types of data augmentation plus uh action Transformers so I think it's going to be an exciting 2023 yeah from my side I feel like we should not forget that this is a technology and Theory should make our lives easier and better so this is I I keep thinking about this how can we do less of everything and not more now that we have gen AI how can we we do less emails less reading articles less just trying to stay on top of everything and just doing a little bit more of the things that we actually want to do so I think that's just a reflection that people come into my head I think it's a very beautiful place and thank you both and yeah thanks everyone for listening and for your wonderful questions foreign