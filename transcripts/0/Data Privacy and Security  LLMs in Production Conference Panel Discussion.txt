now let's get through this panel on data and security we've got a few people who whoa what's this Diego is going to be leading us through nice seeing you again Senor Diego I'm gonna bring on my man Vin dude Ben uh I gotta tell everybody Vin was about two years ago he came up with the best quote ever which is kubernetes is a gateway drug and now I think we need to update that quote and it is GPT is a gateway drug to starting with machine learning I'm just gonna leave it there for you I'm also going to bring on sahil where you at man and Greg Grove and Shreya where are you Shreya let's see if we can get you up here too I will let Diego take over because he is the moderator of this panel and [Music] there we go all right oh looks like Shreya may have had some technical difficulties so I'll bring her up on when she is ready in the meantime Diego get cracking man oh you're on mute uh of course had to do that one right yeah I know how it goes you're just following your um your example here hey everyone uh so really excited about about kind of leading this panel so like the core of it is uh you know as is in the title data privacy and security so you know we've talked about some of these uh you know what does it mean uh to um you know the privacy and Security in the context of uh large language models uh what does it mean to trust these new AI systems so there's a lot of questions around uh you know hallucinations and and we I've talked a little bit in my in my keynote around the you know low affordability like high affordable use cases so without further Ado I have some amazing panelists here uh who are at the at the core of this on both uh is it fair to call the previous generation of ml it feels like makes me feel so old uh and uh but um you know uh so I'm gonna really quickly start and let them introduce themselves so and ask YouTube uh you know uh you know your name what do you do um and kind of like give me one little thing about like you know in the space what you've been thinking about so you've all been thinking about this space a lot so I'm a little nugget uh about it so so here we'll start with you since you're on my top right here it hurts um thanks for having us um so my name is sahil I am an engineer at u.com which is a conversational AI search engine and one of the topics I've been thinking about a lot is how do we best combine a lot of these advances of generative AI with advances in information retrieving Vin I'm ven vashishta founder and CEO of V squared been in technology for over 25 years data science machine learning for over 11. I do data strategy and AI strategy because well they wouldn't let me do any cool projects until I figured out how to get them paid and make people money so that's now my majority specialty figuring out how to make money with these models what I've been thinking about is what comes after this because these this is just the beginning and we've got probably a few other Evolutions coming afterwards things like Robotics are going to come to the front too so that's what I've been thinking about well it's next right keyboard hello I'm give work again I'm co-founder and a CTO AT xero Systems uh I'm leading the both a product strategy and the technological strategy and uh what we're doing zero we develop um co-pilots for knowledge workers which are augmenting them in a very like you know a high value sophisticated tasks and actually what we do what we think like you know uh the future will be in the intersection of uh automation of sophisticated workflows with with uh uh Foundation models and we are super excited to see how the businesses are being transformative with this technology excellent great and finally uh last but not least Freya uh hey everyone very excited to be here um my background is also in machine learning and a lot in like previous generation of machine learning as Diego said so I've been working in ml since uh yeah I think eight or nine years everything from ml research in um you know classical AI decision making under uncertainty deep learning um also work in autonomous systems and self-driving doing machine learning and deep learning for a few years and then it's most recently the founding engineer at an mL of startup also doing the machine learning infrastructure applied ml um I'm a top of mind for me and I guess also the reason that I'm here um talking on this panel is that I'm the creator of an open source Library called guardrails which as you would expect adds guardrails to the output of large language models and makes them a little bit more reliable and safe um yeah excited to be here great awesome um so let's just start about like kind of like let's high level like how should we think about uh you know the difference in some of these data privacy concerns returns that exist today between like kind of you know how we were building models and you know maybe a couple years ago and now using some of these kind of foundational model apis like how do we frame this uh anybody can can go ahead like I'm trying to think how do we should think about the framing here I'm like I'll just pick on Vin because he's right there in front of me it's always me how should we think about these I think it's the biggest piece that's missing from the conversation is that we're not thinking about the patterns they can uncover it used to be we could find fairly simplistic patterns the more complex machine learning and then eventually deep learning models got the more complex the patterns that could be discovered and so when we think about data privacy data security with respect to these types of models it's no longer the data itself it is the patterns within the data that can be uncovered and create vulnerabilities for anyone that has a significant amount of data out in public there's a study that was done by uh it was called short at Pepperdine where they realized they could through some creative prompting get these models to give a basically craft a VC pitch in the style of different VCS and it was it was convincing so there are patterns that are built into the data sets that we throw out there all the time on social media and they allow for more than just our data to be learned there are deeper patterns now and I think we need to start thinking about the implications so so how do we think about to kind of continuing that I'll ask you like you know you're working on information retrieval uh and a large scaler how do you how are you thinking about like the framing around these kind of like this patterns like when do you use when do you think you can use these open generic generic apis versus kind of like need to bring in models in-house like how do you frame that yeah no I think um that's a interesting point around some of these patterns and some vulnerabilities there I think there's probably my head kind of two ways in which we approach thinking about some of these issues so on one hand a lot of these models loosenate so they'll make up content I think we're all aware of that um so in some ways you know there's obviously a lot of technical work to be done on reducing hallucination better grounding essentially a lot of these models so that's one area but then on the other side um just because something is hallucinating doesn't mean that it's not a useful tool for people so I think it also is somewhat of a product question so how do we make sure that people have the right expectations when they're using a product than most language model they can get the most out of it so I think when we're thinking a lot about this type of stuff those are the two angles in which I think a lot about it is it's not only a technical question but also a product question around you know what are the right expectations that you know we present to people using these tools and how do we make sure that they're not going to be misled and they know how to responsible user we have a great and great point in terms of like how to use it and so I'm gonna I'm gonna move to you straight and kind of like maybe for the audience kind of frame some of the challenges around hallucinations and kind of like how you need to think about it and then obviously you know tell us a little bit about your work in terms of uh what's your hypothesis here like you know you obviously built this like fairly popular open source project that's having a lot of adoption so uh very curious to hear from you uh you know kind of like how you how you frame in this context yeah yeah I think Hallucination is a very um interesting problem like when people think about hallucination it's actually you know like a combination of problems that all kind of get grouped under this umbrella term of hallucination uh I think some of those problems are basically falsehoods Etc or even like you have multiple conflicting sources and you aren't able to trust like which one um you know is the golden um is the golden source that you should kind of Base your answer on so it's a bunch of like kind of complex problems going on here um I think like grounding honestly um is is the way to go is the way to kind of solve all of these uh solve you know very domain specific um hallucination problem so I do think that um trading better models training bigger models you know that are kind of like um uh primed to uh you know be less susceptible to this is like one way to go about this with at the end of the day you know as as all of us have worked with them now uh we kind of know that it's really hard to kind of get that level of certainty with any machine learning model and so being able to take something that is so powerful um and you know then add constraints on top of that that make it work really well for your specific use case I think is you know um more just more like more tractable essentially as a problem to solve rather than just make hallucination go away um you know as a blanket thing for LMS um and so one of those things I I believe people have touched upon this before as well but like is the way to go is um you can essentially connect what you believe are like good data sources or good kind of like fact checking um um you know either agents or tools or um um or or even just like um embeddings of um you know good data sources with your llm outputs um and then any kind of like LM outputs that are generated would get you know validated against those like ground rules so that's kind of like the guardrails way to do it which is that um you use your large language model to um generate something that you know functions and then on top of that um for your domain you think about like what are my constraints um and then impose them you know using like external sources or um um yeah or or external data connections you work in a very applicable space right you're building for information workers inside Enterprises kind of like these assistant like accuracy matters trust matters security and privacy matters like as you leave like how do you think like you know kind of what are some of the principles that you're thinking about uh you know today as you develop the product obviously don't reveal anything proprietary or uh you know trade secret but I'm very curious like how you're thinking about it because it has to be relevant I mean you're trying to get the trust of these Enterprises to not only connect their data but also like use your system inside their workflows like walk us through that absolutely so currently the Enterprise is already see and believe in the power of the generative AI the power of the large language models so it is like very close to them like they can play with that the charge GPT for all for their like you know personal use cases but when it comes to the Enterprise use cases and we are working with for large Enterprises such as Fortune 500 companies the largest law firms in the world so their data is very confidential and it's actually their client's data and they have like you know contractual obligations about how they are going to govern that data and of course like you know now there's like you know there's a hugely like you know cousin between the opportunities and the reality and what we are doing uh we strongly suggest not to use the apis like child GPT for the confidential data and for those cases just bring AI inside the organizations because nowadays there are already a lot of great models for like you know several billion parameters you can bring inside the security perimeter of the Enterprise fine-tune on on their domain specific data give a product iterate on the human feedback and reach the level of the quality when the users will trust your system so there you go your absolutely right the trust for Enterprise systems is absolutely must in case they will lose the confidence in your product they'll just ignore that totally absolutely into you know because I you know I I could frame one of the things I'm always kind of curious about I've been thinking about like there seems to be this um people applying the the you know kind of like the use cases to a one-size-fits all like framework and like you know like and and it's problematic right because there's times that like you shouldn't care right go use an API whatever's faster cheaper whatever gets you there and there's other times that you should spend the time to bring it on you to your point bring all the AI into the Enterprise but that has a cost right it's it can be expensive you need to have knowledge and stuff like that and so being able to do the back and forth based on like how you're thinking about security and privacy and not applying everything with uh you know one size fits all I think is really important I want to kind of push a little bit on the um you know like what have you seen in an industry in terms of people like let's talk about that framing right like how to think about the use cases how to frame how to you know if I'm listening to this talk right now and I'm trying to bring some of these use cases into my organization like how should I frame it right in terms of thinking about how should I break down the problem should I go in route a should I go in route B like who can help me and kind of like guide the kind of like questions that I should be asking my myself in terms of like where to run this and how to run it any of you can jump in yeah so like one things like you know when you are currently thinking about the use cases at first you need to understand that currently you need to put every single truth that you had in the future like under the question because you had some understanding like what is solvable what is not solvable right now everything changed you need to come to your business and understand what which are like you know the the major kpis uh that will contribute to the like you know growth of the your business where are you are you know there are your opticals you know where the protests are sophisticated you are spending a lot of like you know money with uh like you know less input and understand if you can like automate that and bring in the people who understand that and they say oh you know with new technology it is possible got it then you work on data strategy a lot how are you you know if I came to you today and I said I needed some advice on how to think about this can you frame it for me yeah definitely what I tell companies is I tell them this is kind of an arc there's a whole bunch of use cases that you could have but they haven't been proven yet and if you're not meta don't be first because you don't have the capabilities you don't have the background you don't really have the domain expertise in this area to be the Pioneer for a particular use case wait until someone else proves it out and then enter in but that doesn't mean you have to wait to your competitors get into the market you can look at each use case as a category you look at the ability to service customers and there's so much that you can do there but you also at the same time have to be protecting your customers which is not something most companies are thinking about what happens when their customers submit a query across your website where does that go how is it stored what are the Privacy implications that you're not thinking about and that's why I say a lot of times you don't want to be the first company to do this because you don't have that in-house capability to really at an expert level think about these things but at the same time what you should be doing is some really targeted opportunity Discovery thinking about different categories of capabilities and problems that you've seen solved in other Industries and then asking years of how could I apply that problem solution and fit it into something that I have in my current business internal use cases are always great for proof of Concepts because you're banging on it inside and the risks are significantly lower then turning around and you see you know companies like Google did this Microsoft did this they consumed it internally and then they turned around and let companies externally play with it and so a lot of these paradigms are what I'm talking to clients about now but it's really important to be thinking through use cases and connecting to Value propositions not well it sounds cool so let's do it no no start with the ROI if there's not a significant Roi you know if there's not a big dollar value on the other side of this why distract yourself from your core strategy and your current competitive advantages you have to adopt this at some point so you should be forward-looking and prescriptive but at the same time it's all about the returns if there's no significant use case that fits that will deliver cash don't do it yeah actually um I was I was gonna ask sahil about his so you know you work in search you work in the future of search right and retrieval and personalization and I'm kind of curious like how you think about you know let's go you know like you know if one argues not only company but our personal data is kind of like the most valuable thing we have right but we obviously want to contribute that data to search experiences that are great for us uh how do we think about like you know what's the future look like can you guide us through that like uh in terms of like how you're maybe how you're thinking about it at you or maybe how you're just thinking about it personally we can detach those two things if you want uh but I'm very curious uh you know what the what the future of personalized search looks for look looks look looks like yeah I think it's honestly I think it looks super excited that um yeah I think the future of search is probably more exciting now than I think it's been in you know the last last couple years last five years maybe um and I think there's a number of reasons why I think a lot of it is obviously the recent advancements and you know natural language processing Etc I think when it comes to personalized search um I think it comes down to you know how like I guess when we think about if we're thinking a little bit more into the future um you know what can we do to really allow you to control your search experience so I think that's something that will have a lot more ability to control I think a lot of times now when we're interacting with some of these models for example just think of the concept of a system message so when you're using you know one of these models um you know there's this idea where you can specify a system message and it will basically you know dictate how the model is able to adapt to that so that's that that in itself is a degree of a personalization of AI that we have not been able to do in the past so I think ideas like that basically will allow us to really personalize the results that we get from search in the future if we kind of apply that more broadly and then also in terms of bringing your own data I think there's going to be a lot of we have a lot of ideas at least we're thinking about you know building an open platform where other people can contribute their data and essentially what we call apps into search and we'll incorporate that into our chat slash results so I think there's you know a combination of open Community efforts that can make you more personalized um as well as um personalization enabled like technology itself cool so um we're gonna go do uh we're gonna have to wrap this up even though I could probably talk about this uh you know all day so I'm gonna do one quick uh you know rotation through everybody and I'm gonna ask you to either recommend a tool it's totally fine to recommend the tool that you're working on a uh you know recommend a resource or kind of like give a thought to the audience to go chase in terms of like how to be thinking about data privacy and security and trust in these AI systems so so I'll start with you uh and uh and go for and go that way yeah I guess maybe I would start I guess one thought would be um maybe just you know what you currently find um these tools to be very useful to you right now where you know I think sometimes it's easy to think of tools as useful um in abstract or maybe on a couple examples but what are some ways in which you've been using some of these Technologies and consistently useful for you um and then you know from there I think one can imagine what the future of these cases will be good work yeah it's a great question so since we have like a very uh like you know a big audience here so and I believe that not everyone uh started to like you know work and experiment with like you know uh generative Ai and like you know bring the applications via length chain so I strongly suggest uh to do that because you'll be very impressed how fast you can have a great result and then you're already will have a good use case you can order the like you know double tile on the accuracy at front like you know your user experience right Vin uh I would start looking at Auto GPT the whole concept of self-healing self-correcting those are some really fascinating use cases there's danger but a lot of potential in that direction so I would say look at those tools if there's anything that comes out of this that I think becomes an exceptionally powerful construct going forward that's the one to keep an eye on from a forward-looking perspective got it and Shreya and I you know I I expect what you're gonna you know which what tool you're gonna expect to push here so do it uh totally happy with that I think I'm going to basically talk about guardrails and I'm going to talk about it more in the context of like this idea that I want the audience to kind of like think about and like take home you know um um uh yeah some take-home inspiration and like why guardrails kind of fits inside that um so I think essentially um we like these tools are these uh these models are really performant right and we see like really interesting use cases and everything but like are they ready to be deployed into production where they can you know like work reliably work like 100 of the time and not you know um return like awful messages to your potential users Etc right and so I think the idea I kind of want to share is that this isn't going to be um the this is insufficient enough to like actually put a lot of you know the applications that we're building into production and the actual solution would be a hybrid of you know more traditional machine learning uh more traditional like rule-based and heuristic based methods in addition to like large language models and I think like that kind of gives us both the performance as well as the kind of reliability safety guarantees we care about and I think that's a very powerful construct of like ensembling those two kinds of methods together and so in that context I think like guardrails is a good Tool uh that I want to push uh uh obviously I'm biased but I think it's a great tool that you know allows you to kind of like get a lot of those um a lot of those guarantees Straight Out of the Box yeah awesome well hey thanks all of you for a great panel uh I believe we're uh we're we're here wrapping up uh Ben gervorg uh sahil and straighta thank you so much for taking the time they will all be in the slack channel for the conference we'll also share the links about what we uh you know what was talked about today uh Demetrius back to you all right wow that was special so I knew it was gonna be good I'm not gonna lie uh you get this many hard hitters in one place on one virtual room and what do you expect [Music]