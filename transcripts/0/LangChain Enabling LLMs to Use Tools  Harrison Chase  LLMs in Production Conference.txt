let's hear it for none other Mr [Music] [Applause] [Music] s [Music] oh you blushing dude that's ridiculous what are you doing that's ridiculous I appreciate it thanks for having me here man this will be fun so here we go man I'm gonna hand it over to you and let you get started awesome thank you so yeah I mean there's a there's a lot to potentially talk about uh you know I think uh Lane chains been really focused on kind of like prototyping for the most part but now we're starting to think a lot about what does it take to actually run these chains and and agents and and everything that people are building in production and so there's a lot of different things that I considered uh talking about um but I think the one that I settled on is basically how to enable llms to use tools because I think it covers a lot of different components that um you know even even in willem's talk just before the study that he mentioned a lot of those are really relevant for this um and then this is also very top of mind with with all of the AI plugins um the the chat GPT plugins and and and all the like Auto GPT baby AGI stuff going on so I figured this would be a fun uh conversation for today um so uh yes so I'm gonna try to talk in 10 minutes about why is tool use important different types of tools then the main chunk of this will be uh talking about how to get language models to use tools um and some pitfalls uh that that occur and then and then common fixes for them um and then a little bit of Spotlight on some of the open API tools that we've been working on over the past few weeks again kind of driven largely by this AI plugins chat GPT plugins announcement so why is tool use important um I think there's a bunch of different uh reasons I think the two main ones are allowing it to retrieve relevant context so so get in information about current events um pull in information about proprietary data navigate complex data structures so so tool usage itself can actually be used to interact with data structures and then also allowing the language model to interact with the outside world and by this I really meant kind of like taking actions um so whether it be pushing something to a database or or some more complex things like that basically you know language models are themselves just text in text out or or roughly that and so hooking them up to different tools can enable a lot of different and really cool capabilities on that note different types of tools this is still I think a really uh interesting area to keep on adding more things but the main ones that we've kind of seen are search engines this is really relevant for uh kind of like getting current information in calculators alarms aren't great at math necessarily and so adding in calculators can help them with that retrieval systems this is again around pulling in proprietary data there's been some really cool stuff around coding agents and having language models basically code and so interacting with python repels or other Rebels for that arbitrary functions are kind of just a generic catch-all you can you can really make anything a tool that you want and then apis and that's bolded because yeah with the with the chat GPT plugins has been top of mind for a lot of folks um so how do you get language models to use tools like uh like everything with language models you just kind of tell them to um so you tell them when to use them you tell them how to use them and then you want to tell them what they return as well and so this is a bit um over simplistic obviously but I think it does uh underscore a big part of the the and I'll talk more in depth about a lot of this in in just a second but you know you tell them to it's kind of really a real answer for how do you get language models to do things um it's uh I think yeah it is really about what you put in the prompt how you put it in the prompt um and then and then how you use the output as well um and so so you tell them to is the quick and and and short answer but there are a lot of challenges with this um and so some of the most common ones that we see people running into in link chain are how to get language models to use tools in the right scenario um how to get them not to always use tools uh oftentimes you know you have a conversational bot or something and you may want to to have the option to use a tool but it's also totally fine if it just wants to converse with you and so it's striking that balance is really tricky um and then the third one that we've seen a bunch is basically parsing the LM output to be a specific tool invocation um and so I'm going to Deep dive on these for the majority of this presentation so um for the first challenge getting them to use tools in the right scenario um so there are a few different kind of like tips tricks techniques um that we've uh discovered heard um kind of see to deal with this um one is making the instructions uh really clear whether it's instructions in the prompt whether it's a system message for now these new chat based models um you you kind of have to uh tell them to tell them to use tools tell them what tools they have available um tell them what the tools do so this gets to point two around tool description um telling them when to use tools in certain scenarios is really useful so you know if you give a language model a search engine that's really good for like current events or something which I think is the main use case for for search engines um I've found that you know you want to put in the description hey use this for current events um otherwise it will it will do some guessing and it won't always be perfect so for a lot of the questions around you know the language model isn't using my tool in the right way the answer is kind of like beef up the tool description um and then tell it that it should use it in the right way um repeating instructions at the end especially for some of the older models has been really helpful because I've observed purely anecdotally that if you put kind of like instructions at the beginning by the time it gets to the end it kind of like forgets about them a little bit and so my general technique is put instructions at the beginning like hey you have these tools you can use them you should use them in this way Etc and then and then right at the end be like remember to like uh format uh the output in the correct way or remember to only use tools if you need to um and so a little reminder at the end goes a long way um and then the fourth one is a bit newer but this gets around um and I think Willem kind of touched on this a little bit earlier about using some like embeddings or semantic similarity to decide when to use tools and this is really useful when you have a lot of tools so if you have like 100 tools you can't you you probably can't put them all on the prompt and and ask the language model to choose between them so one thing that we've seen be helpful is basically do some tool retrieval step first retrieve them then put like the top five tools in the prompt and ask it to decide between those um so that's around getting them to use tools in the right scenario um the second challenge that we've seen is they don't always need to use tools and so again kind of like telling them that in the system message again repeating the instructions at the end and then the third interesting thing is basically adding a tool which itself is basically like just responding to the user um and so we've seen this be really helpful um because yeah the the instructions sometimes Aren't Enough by themselves and so explicitly having a tool quote unquote that it can call to to get um to get uh a response to the user has been has been really helpful there um and then the third challenge that we've seen is it's basically parsing llm outputs to get a tool invocation and so the solutions that we've seen for this are basically using more structured kind of like response types like Willem was talking about um so Json typescript have been have been really good ones um and then we have a bunch of Concepts in link chain around how to do this kind of like explicitly and easily so we have a concept of output parsers um and we have also a concept of of fixing output parsers so jumping through some examples really quickly there this is the base kind of like output parser example you actually Define it in pedantic um so so super common to those who are who are familiar with python um in in the JavaScript library we have a different kind of like schema definition thing and then we automatically can convert the pedant object into an output parser you can then use that output parser so if you look here we do parser.getformat instructions and so this uh uses the the schema to generate some format instructions and these are typescript Json and and then we put those format instructions into the prompt itself and so that's how we tell the language model to use a specific format and then we can then parse the output explicitly back into this pediatric object there's the obvious question as as Willem was mentioning like what happens when that fails um and so as we can see here we have an example of a output parser that's misformatted and so we have um we have some stuff in LinkedIn to basically fix that by passing it to a language model and asking it to fix the the in this case the Json decoding errors there's an interesting kind of like Nuance here where this doesn't actually um fix all the issues that could possibly arise so if we go to the next slide we can see here that uh the the response in the at the top is actually invalid not because it's bad Json but because it's missing uh argument and so if we ask another language model to just like fix this thing it won't actually know how it should fix it because there's a second argument that should be there where there is some kind of like correct meaning and so here it just kind of like puts a blank string but that's not actually what it should be we can see at the bottom when we use this other type of output parser um it kind of retries with the prompt originally so now it has all the information um and I know I'm running a bit low on time so with the last slide just wanted to Spotlight how this all comes together for some of the open API tools which are these chat GPD plugins um we can use some of the prompting and output parsers um to to communicate the Json and typescript parameters for each endpoint and then this is a bit of a tangent but basically we've seen that language models still struggle with some of the more complex parameters and and function definitions and so we've found it really effective to actually wrap each endpoint in its own chain and have that chain basically be responsible for a single endpoint because then it can kind of like learn and know how to interact with that endpoint and those complex parameters better and then we have the agent this basically router language model communicate with each chain independently and the input to those chains is just a string a natural language string and so it's way simpler to kind of like tell the the agent to interact with those chains um that is that is all I have for today I think I went a little bit over so I hope you're not too mad at me Demetrios for having me um yeah people are NSF I would love to see you at the Meetup tonight there we go man hello [Music] foreign