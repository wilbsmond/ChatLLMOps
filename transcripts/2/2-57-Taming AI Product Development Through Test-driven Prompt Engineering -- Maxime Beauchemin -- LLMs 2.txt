you want to try and upload them and see if you can share it that way if it's breaking out your computer the the old-fashioned way Maxine we're waiting for you to share your screen [Applause] [Music] let's see if it bricks out your computer come on [Music] I'm looking at you man [Music] let's see what we got today with Mr Maxine [Music] oh tell me foreign [Music] [Music] I gotta bring you on here because I just see you suffering backstage and I'm feeling bad for you do you want to give me the link and I'll share it yeah I put it in the private chat I was gonna go get my guitar like I was like this this all right yeah give me the link play play guitar while I oh it's already in here isn't it yeah I put it in there maybe I was bricked when I tried to upload or to send it to you but you should be able to share it hopefully yes I got it right here I've got it I will bring it on stage uh and the fun is over with the guitar or dude grab yours Liz rock on why don't pass driven prompt engineering is what here's a Taco Bell is the thing that like playing trying to jam online is really hard you get like a few milliseconds too much yeah and then you start like slowing down you know a little bit slower to you know make up for years yeah yeah and I I would not uh I will um kind of protect your audience from my guitar playing yeah there's a better thing for uh for all of us awesome dude well we've got this here you're just gonna have to make a like uh a sign when you want me to change to the next slide yeah that'll go pretty fast because this is a lightning talk so I'm gonna I'm gonna yeah supposed to start what two minutes ago where are we yeah that means I got I've got seven minutes left so I'm gonna I'm gonna Blaze through this you can take the whole ten we're uh we're all good we we accounted for a little bit of cushion so there it is I'm going to say for people who want to know more like there's the blog post so we'll hit up a slide that talks about the blog post that is a little bit of a companion to uh to this to the stock so this despite like an hour's worth of content I'm gonna try to cram into 10 so it's pretty heavy um there's a lot to talk about but I'm gonna brush the surface um and then there's the blog post and there's the podcast episode that uh we we recorded just uh last week if uh if I'm right about my my time blurb my time blur um all right so we're talking about test uh test driven prompt engineering today um maybe let's jump into a slider too I think uh the next slide is an intro about me I think you did my intro already so we can uh we can go through that very very quickly but I wanted to point out like my my professionals life mission has been to uh work on on open source lately and then I've been really pushing on uh apache's super set I want to say a few words about that um superset is a open source uh business intelligence platform very much right so it's very competitive to the space if you think you know Tableau uh look here you know and all these bi tools so open source and that in that area through superset has gotten really really good uh recently since we've been working um at it like you know I appreciate the community has been working real hard so I encourage people to check to take a look at Apache superset if they haven't uh done that in a while and then you can try it you can try the latest greatest version at preset for free so um encourage people to take a look at that and to switch to open source like why you know paying for these vendor tools all right so let's jump into the topic of the day which is uh test driven from engineering I'm going to start with just a bit of context I think things that's pretty established given the you know this conference here and what we're talking about but everyone right now is looking to bring a the power of AI into the products they are building right and that's a big part of uh what this very conference is about and if you talk to anyone who's a PM a product Builder a startup person like everyone is trying to figure out like how do we harness the power of llms and bring that into the context of our product or application we're building um product engineering is very new right and it's a new field that's pretty fresh and uh llms are are just weird freaking animals you gotta deal with right so it's a new we've been used you know as product Builders to use you know proper apis with schema for input and output and things that are very very deterministic and all of a sudden we have this like this weird animal that's very providilistic and uh that has an infinite API surface that has no input or output schema uh unless I guess in this infinite API space you can Define some sub areas of the API surface you know and you can ask for schema and you can kind of uh you know dictate a schema in some way uh and this stuff is evolving very very quickly right the the models are evolving quickly the the limitations around the model The Prompt window sizes um all these things are evolving very quickly all right so next slide um so this talk is about and it's a 10 minute talk so it's very quick but uh it's about advocating for a test driven approach to prompt engineering like try to make the stuff that's very probabilistic more deterministic um I want to introduce prompt demise which is my take on an open source toolkit to Define these test cases or prompt cases to evaluate your prompts uh and bring this this this idea like test driven development to prompt engineering and then I want to talk about a little bit about our text to SQL use case at preset so the reason why we I went and built proper minds and got involved in the space is because um we wanted to build um text-to-sql type features inside super inside the preset two percent so I'll talk about that uh this is the blog post it looks like it's not rendering the image but uh here it is so you can go to preset.io blog there's a bunch of blog but they're blog that we're referring to here is the one called mastering AI powered product development introducing promptomize for test driven prompt Insurance quite a mouthful but uh that's what we're talking about today and there's a lot more structure examples pointers um and You Know Rich Text uh there so to maybe pop this blog post open if you're interested um or if you're you know curious to learn more after the stock to go and look at this all right next slide uh so our use case just like to set context like why are we getting involved into this so superset has is a full you know bi platform but it has a a SQL IDE as part of it and uh we wanted to bring a few AI assist type features uh the one as you see at the top there there's like a a little blurred like where you can do text to SQL so natural language that will generate SQL uh we'll show you some results and then we will also recommend chart so the recommended chart engine is also an AI use case where we want to integrate I know a product so in in this talk I'll refer to that example use case that put things in context all right next slide all right so very quickly I think people are familiar with prompt engineering but you know I think there's been confusion between prompt what I call Prompt crafting and prompt engineering from crafting is what you do when you interact every day with uh which at GPT or your favorite llm and you get smart about you know crafting some nice prompts prompt engineering to me at least in the context of this talk is when you want to bring you want to use an element an llm as an API and you want to bring that inside your your product you actually have to do some prompt engineering and do some proper things there not just like you know craft around and ask if answer your question uh so prompt engineering to me is like adding the proper context private from your product your application um specifying an answer format right say like a llm I don't want you to write an essay I want you to return a Json blob with uh you know your confidence score and some SQL um and and maybe some handsets to out and improve my prompt right so you can define a specify the format that you want and it can be uh bringing structure to to its output limiting scope setting guard rails and measuring success which is what we're going to talk about today uh the idea of measuring success is there's so much you can do when you do these prompts right you you have this natural language interface you can say like hey I'm going to provide some sample data or I want or five five rows of simple data I will um I will you know specify which sequel dialect I might want or I will put like a capitalize like import it don't forget to do this um so there's so much you can do there and this will influence the result and that's why it's so since they're so probabilistic and and uh potentially like unpredictable I think it's it becomes just more important to have that um here I'm going to go really quickly on this slide so they're just pointing out the blog post talks about parallel between test driven development so tdd is for test driven development and then applying some of these Concepts and ideas to prompt engineering uh and translating the two um there's a lot that's applicable right there's it's intricately similar there's a lot of transferable Concepts there's also things that are very very different and that's why I talk about here and in the blog post right for for instance like a a test a normal testing tdd Library it's either you're right or you're wrong in the case of an uh an llm or problem engineering it might be you know 50 right or 80 right right so we're not assuming that everything is uh Boolean uh when when doing that so if you're interested in like the parallel and differences between um test room development and as it applies from engineering there's more in the blog post about that now what does the prompt iteration life cycle look like right so so clearly and here I'm thinking this at reading a book from a page from the the tdd book which is first you start like what is the behavior what is Define your use case and the desired AI Behavior like what's the input what's the context and what's the output you want from the AI then you start before writing your first prompt you define your test cases right you define a suite of tests that are like if I ask this question given this database schema I expect the following SQL or SQL that contains uh these comments this columns or these tables and then we're entering the iteration Loop here where then you'll run your test you'll evaluate the result right that was my prom performing you'll refine the test perhaps and refine The Prompt and then you Loop and you you stay in that Loop until you reach the point of wow this this area I can measure and know for a fact that this AI is helpful and my prompt is successful and it matches the the success criteria to bring into my product and then and only then is when you would put it you would bring this prompt into production right similarly once you bring your your prompt into production you probably want to improve your prompt like there's a lot you can do you want to do some more engineering get it to be more accurate you want to be able to measure that your new fancier prompt that's using you know a different model perhaps or using a fancier Vector database or just as using like this this slightly fancier you know prompt um generation technique that it's actually working better than your previous prompt right and you want performance metric like how long does it take how much does it cost to actually like you know run my test Suite against the say open AI API and you want to Loop over that and what I'm talking about today is really about like this area duration Loop and building this this prompt case testing Suite foreign I'm sure you're all familiar at least like the engineers in the room familiar with the test libraries and python there's Pi tests right and then uh there's some specialized libraries too and say JavaScript like enzyme for react or react testing Library so front devices is really a bit of a testing library and toolkit right a test a way to express test a way to run tests and a way to evaluate results from tests um and that's what it is about I think in the next slide I'll talk a little bit about like some of the the core key features of promptomize it's a way to Define prompt cases as code um attach evaluation functions to those prompt cases generate prompts variations dynamically potentially so since you express your prompt cases your your test as code you can generate some some problems dynamically perhaps in some cases um execute and rank across different engine so run so it's a it's a prompt test Runner and then a report on the Chrome performance I produce report of like the detail of each prompt whether it succeed to succeeded or not what was the input what was the output I'm compiling results on it um this is uh an example that we have if you're interested to kind of see the mechanics of it and how it works if you pip install promptomize you will get these examples right so you can play with these examples so this is an example where we craft a prompt that generates python function right so this this specific example is like you give a prompt like write a function that tests if a number is a prime number and returns a Boolean and then we attach some evaluator functions to it in this case you know is is two prime is 4 Prime is seven Prime um and then what prompted my skin do is it allows you to express these prompts in a specific way and then to run them and validate them and produce reports uh next slide so so here um so here we have a fancy little CLI that is frontamized run you know and shows like all of the some of the options but it's a smart test Runner so we'll find your tests or your prompt case is it will run them for you and there's some some things to allow you to do human review right so if you want to do like force a yes or a no uh in some cases you can do that so there's a bunch of like little uh fancy features uh around test around around uh running things and then next slide it will be a very very quick high level overview of some of the reporting functionalities on the on the right side you can see that uh just an example of a prompt case run for a single test and we produce a big a yaml file that's a big a big um a big kind of report file that has all the details of of everything that ran in the background right so for each test I'll call it a sweet run right so maybe you have 600 tests uh that evaluate my text to SQL I go and run these 600 tests I will have the atomic detail of each test I'll perform and it would produce this big yaml file with all the details for that Suite Now using this Dash you can also run other problemize report commands where you can see what is the percentage of success right and um what is uh the performance you know the the percentage of success per category uh and then eventually right look you have these dcml files but you could ask questions to these yaml files like uh much how long did it take an average well is my P99 P95 and a p50 of all I took to um execute the the prompts and what is the you know average number of tokens so you can do you can build on these reports and below our statistics some features we don't have to that are intricate and interesting is you could have two tests run and you could say diff the test that succeeded and failed um in these different version right so you can understand uh well this is performing better but it's actually performing lower in certain cases right so it's all about the producing that and having a more systematic approach to evaluating whether your prompts are working well or whether they're not working well they're more expensive but they take more time next slide um so this is just yet another pointer to the blog posts uh so much more information there and then there's the GitHub and you can install promptomize and play with it um you know for me I think uh that it's it's an ambitious project in some ways but it's pretty contained uh but what what is really interesting here to me is more the approach the reference implementation uh we used prompt them eyes you know at preset to tests or prompt but it's it's still a very very early project so I want to get involved it's a good time to influence the the future of the project and get involved and then shape the direction since it's super early on in this field and in this specific uh project and community and I believe that was my last slide that might be another one I think it says so that's that is all folks that is awesome I just I threw the blog in there and I also uh let people know in the chat that I am a huge fan of this I mean we talked about it for like an hour and a half last week and it's just it's so cool to see the idea of being able to really like put some numbers around your models and how the models are working and and how your prompts are working with the models and is your specific use case so I love it we're going to be dropping that podcast episode probably in like a couple weeks and so if anybody does not watch our podcast this is a great moment for me to plug it right here scan that QR code and you will see Max and I chat chopping it up in a bit uh dude Max awesome thank you so much I'm gonna kick you off now because we're like 10 minutes behind and I've been telling everybody I'm gonna be like a clock today like Ringo you might as well call me Ringo because I'm keeping the time so tight but I am not man I have lost that title uh that's all I want to say dude thank you though Max and I'm going to be in San Francisco in two weeks and so hopefully we can meet up if you're around yeah let's try to see if we can uh for a drink or something and then um if I believe there's a slack too so I'm gonna go into slack and take questions and talk to people for a little while too so I'll be active on this like if you want to pay me directly and I'll be scanning the channel so I'm happy to connect with people and even get on a zoom with uh whoever's interested here we go you don't want to distract from the mainstream like this is live you should probably be here and be full attention to this mainstream uh live stream right that's it there is there is some questions coming through in the chat that I just dropped into our chat uh because we're mainstreaming on a different platform so you can go through there and see and um I'll have like the slack open and the lights all right thank you that was a pleasure see you dude it was great [Music]