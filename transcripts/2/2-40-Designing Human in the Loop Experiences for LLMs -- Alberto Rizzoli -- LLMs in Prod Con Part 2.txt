so let's give a warm welcome to our first Speaker of the day on track two Alberto uh who's joining us from V7 um and he'll be talking about designing human in the loop experiences for llms and I think this is going to be a great talk to start the day off with so without further Ado let's bring Alberto on go hello how's it going hello everyone thank you for having me Lily it's going great uh it's very warm here in London um I you know right now I'd rather be in Bosnia with the with the rain and cooler weather we're excited to be here and to present to you awesome I like your background as well I can't tell if it's like bugs or animals this is the original image classification so after Darwin there was a craze about actually depicting we're already starting to talk I guess so I can eat until my time but uh depicting animals and creatures and plants by their their grand truth classification so it's the the original way of depicting what data should look like and if you're creative enough and you can notice that there is some very broad level of clustering this is almost like an embedding space wow very very cool awesome well here are your slides and take it away we only have 10 minutes so I'm gonna go in a Flash and we're only gonna be able to go at the surface level on some of this problems and it's probably a good thing because when when I was first invited um to talk I I thought that by now given the rapid progress of how llans are making their way into products there will be a lot more am I good yeah are these coming through cool um there will be a lot more to talk about in human and the loop interaction within Airline and by human in the loop I mean specifically anything that has to do with labeling or teaching or getting information that's inside here to make its way into a model's knowledge but actually we've made a very slow progress in this um and I'm just going to talk a little bit about human computer interaction principles so we're not just going to talk about labeling which is what V7 as a company is most known for but also the active people teaching these llms we're going to be talking about how humans are supposed to fix data issues when llms make mistakes which is quite often not not just talking about hallucinations but perhaps answers that are subpar and then we're going to be touching a little bit on multimodal human in the loop approaches so anything that spans cross modalities not just in language but in language plus vision to give uh and maybe to to summarize this all the question that we wish to ask ourselves is is this enough we've seen apps be developed everywhere in which the responses of a model are a thumbs up and a thumbs down and I think we will look back at this time and cringe at the huge untapped potential that that we we have in improving these systems that are sometimes deployed in production and sometimes handling really important information and we're treating them really uh like at the very beginning of the machine learning implementations with just a a thumb up or a thumb down critique I see that the slides are coming through very late in uh in the presentation I hope it's not it's not confusing for you all at home um so to give you a little bit about of an intro to myself I founded um a company called B7 we're a training data platform and because of that we handle the grand truth of hundreds of AI companies and through that we're able to learn what exactly does good knowledge look like uh to be fed into neural networks with llms this has changed significantly and continues to change because we're moving further and further away from over supervising our data we come from a world in Industry specifically in which we need generally lesser amounts of data that are very well labeled into a world where we are using enormous amounts of data that are really poorly labeled um and we have an interesting Vantage points because within V7 we actually have enormous amounts of of data that we use in research uh we're talking about petabytes of training data that is also really well labeled and does that actually matter for use in Industry the big question of of um human in the loop processes specifically within lens is rlms necessary to solve industry problems do we actually need something that can write Shakespeare as well as it can tell you ice cream recipes or do you need something that's a bit more restricted one other very important point when it comes to human computer interaction is that we like to think of llms as co-pilots but in reality so this thing that it's continuously supporting your actions continuously aware of that stream of a task and a task in the case of for example a flight is taking off somewhere and Landing somewhere else but realistically the atomic unit of a task in most machine learning software is much shorter and we're actually using a lens in this very same way just like we're treating this um this cute elaborate over here where asking it to retrieve some information to us the Dow comes back we're happy and then we start off another task and send it back to them so the reality was we're we're still scratching the surface of what we should be using in our lives in production for today and the majority of production usages that at least we're seeing from our perspective Stilton to be relatively simplistic and uh even within our own product the use of LMS tends to be still using it as a glorified zero shot model in the case for example of using it in computer vision they're generally used to manipulate other models since um as as multimodal models large models tends to be still very unreliable they're still generally used as a glorified command k and this is potentially okay but there's still a lot for us to explore within this Paradigm so in this specific case we're saying Hey I want to label bees so pull up the B model or a model that knows the b class run it and then maybe do some very basic transformation on this data so what we ask ourselves day in and day out uh as product designers is how do we make an experience where this thing actually learns over time and unfortunately this is much harder than we initially thought within our product we have something called Auto label which is effectively a large model that given a small prompt such as segmenting out one of these airplanes it goes off and starts to segment all the other airplanes that it sees in the picture so truly a multimodal co-pilot that is able to understand your language instructions such as well an airplane I know that it's supposed to be a Qantas airplane only in this class to understanding the vision side the problem that we tend to see at least within the the labeling space and automating labeling beyond the point where we're at is that most of the time if your user which is an expert label on the other side cannot automate uh cannot um can be you know fully automated by a model in this case then probably you shouldn't be labeling that piece of data and if your user is an outer distribution person or a true expert an engineer a radiologist then it's very very hard to automate them because by Design they're always introducing an outer distribution piece of knowledge to your training set and uh and so this makes the job of developing uh human in the loop experience is quite difficult and there's a few challenges that we've encountered by now and the first one that we see in industry is that automation is often overrated and most of the time it takes quite a while for a an end-to-end automation system or even a co-pilot system that assists someone by making them just do QA to actually find its way into prod um and with an alums it's even harder because we're using these things that are very impressive they can convince us that they're very intelligent by by their means of speech but they're actually that not that better in both NLP and in multimodal approaches than something that is just fine-tuned with a smaller amount of data um the the challenge with getting these into prod within for example computer vision is that most use cases with Envision don't have any undo they involve atoms you can't undo the picking of an apple or The Cutting of a tree if you're doing it robotically um it uh in many use cases there's no room for error most industry use cases have defined outcomes and this is actually one problem for why large models are not finding its way into many industry use cases is that we actually have designed industry use cases to have very strictly defined discrete outcomes you're buying a stock or you're selling a stock you are pushing a daily accelerator you're not pushing the accelerator so all the reasoning and logic that can happen in that 55 000 token vocabulary of a large model kind of goes to waste when the actual problems that we're using ai4 are quite simple because we have designed simple systems so we're still in a transitionary period in in which these can find their way um and they they also bring a whole new set of challenges one of them is co-pilots versus SAS in reality we already have a lot of software that fulfills a particular um a particular profession for example Bloomberg will have their own Bloomberg terminal which is great for trading and it already has the buttons to actually be pushed to complete trades um as a result of that it doesn't really need uh an llm like interface in many cases it just needs to complete actions and these actions can actually be done without using a large model but by simply using a classical machine learning model or even just a regular deep learning model that's fine-tuned on bespoke data one minute women cool yeah cool the other problem is people are terrible teachers most of the time if you're giving people the ability to retrain a model they will usually give them incorrect information or information that is just not written in the way you would normally are on the chef the model and then finally there's a problem of information asymmetry most of the time the answer is not wrong it is just a wrong information given to the wrong person and these are still problems that within nlms are I would say largely unsolved in production systems um we've seen many implementations of these Adept has things that created a way that will navigate websites and and click around things for you but most of the time this is not just the only way in which you would use a um you know a piece of software to go and search for homes is just the way that works for now open AI has created a pretty simplistic interface that still works but it is not the way you would want to get house prices out of it and so many other software has done something similar Sana I think has one of the better ways of implementing uh visual feedback with the responses of nlm shout out also to glean an Enterprise search company for doing so um so 10 minutes going really fast but to keep it short um there's many challenges for us to implement the training of of new information within the lens hope you've enjoyed this talk and see you all in future talks within the the mlaps uh day and have a grocery day awesome thank you so much Alberto and make sure to check out the chat as well people can come with you there thank you thank you chat [Music]