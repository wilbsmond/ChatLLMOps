all right I mean this is what's kind of crazy for me to see is just like Greg has been seeing all of these developments coming from the lab right in the beginning and now everybody's trying to press all of these Technologies into either new products or to plug them in as new features and you're right there on the front lines trying to help people understand how to even do this productively so exactly I'm I I I am really enjoying this transition Greg thank you very much and arini how is it that people should be thinking about these things uh I think we should still be grounded uh with like you know good product principles uh the pro the problems that customers face are remaining the same it's just that we have another really powerful tool in our toolbox and I think um starting from the customer problem is going to be the key I think customer problem great uh do you have slides that you'd like to share yeah uh this talk is about uh the lm's value proposition for a business uh specifically when um you know llm itself isn't your product but uh you got to build llm features for your existing product so this is uh hopefully the the takea away from this talk would be you know some set of Frameworks that would be useful when you're um uh trying to build llm features for your um existing products um you as a product manager in AI feel like I generally box the large language models into three uh major categories one is uh user facing chat interface that is the type of product that we see uh most of the times out there you know as a customer service assistant as a some kind of an expert system um that you know is trained in some complex topic and then answers the customers uh questions and then you know it can summarize complex topics this is the kind of uh product that we see a lot starting from like open Ai and like anthropic and everything the other um type of uh bucket that I walkes into is uh still user facing uh but they are fine-tuned for specific tasks so it doesn't have to be like Q&A type of uh interface but it's like more like you know um natural language to some kind of query language right or natural language to some kind of domain specific structured output say for example if you're in cyber security you know um natural language to like shell commands um so the the third box which I'm going to concentrate probably more in the stock is uh nonuser facing um applications of LM where llm is just a layer in before your final uh product right so it can be used as a feature engineering um engine or like a label enhancer or uh more so you know used for turning unstructured uh data into tablet features which can be used for your uh traditional machine learning models and this particular use case I think it's not being talked about a lot but which can give you value pretty quickly right um again um as I said before when you're when you are the product manager for like um uh for your AI team and you know the leadership says you know okay now this is this cool tool how are you going to use it I think the very first thing that a lot of teams do is you know list out whatever projects they have and then say okay can we uh use llm for this particular project and I think that's uh kind of the uh opposite way of how we should look at it um because the customer problems are always the same right uh you already have like a set of customers who are facing up uh sort of problems and your uh product has a mission and a vision that solves that so keep loving the problem uh just keep just adapt Your solution right the customer problems Remains the Same the user Persona that your product is targeting Remains the Same so your solution still has to have you know good product sense still has to have robust data Mach and machine Learning Foundation uh llm is going to be that another powerful tool in your toolbox uh so this is another uh framework that I think a lot of product uh folks are familiar with you know it's the value versus complexity um grph uh here in the um uh x-axis you can see the um the the amount of effort that you need to put in terms of building a product versus in the y axis you have uh the value that it generates right in the older P name before llms you go with you know which has the uh lowest effort the highest value you start with that and then you go with which has the higher effort which becomes like the uh which goes into backlog and then you it's a long-term project but I think after llms post llms you you you can Target all those grunt work like know which has a lot of um uh human effort going in in terms of you know uh transfer like um um using on structured text and then converting that into like a structured uh features and then you know labeling all those um um High um which needs a lot of effort now you can uh use llms to Target that right um so here's another very um uh famous uh product frame uh framework um you know proposed by a Japanese researcher it's called Koo model I think a lot of product and Leadership folks would already be familiar with this uh to give you a quick background the x-axis is uh the the the features that you're implementing right the y- axxis is the user satisfaction so there are these basic features that you know it has to be there for a customer to be uh satisfied right and then there are these performance features where you know it linearly increases the uh user satisfaction if you you add more performance features the user would get more satisfied right but there are these delighter features where you putting very uh the customer would not be expecting that feature but if you implement that um uh they're going to be extremely um uh happy with that and that is the hook that you uh you hook the customer in and I think uh llms are that PL of features for example uh open AI right like how um the how accessible they made like a very uh complex technology to like um uh general population I think that's a uh great example and llm can be the delighter feature um in your product suit um coming from a cyber security background I thought okay let me go through the use cases that I can come up with which are not um chat based but which can give um uh immediate value right so uh one particular uh problem that has been uh plaguing the cyber security industry for a long time I joined the security industry in like 2017 and now it's like more than six years we talked about alert fatigue back then we are still talking about it um still all the Caesar in the company they are not satisfied with like any vendor that is attacking this problem you have hundreds of thousands of alerts per day and the the security alerts are not going uh not able to you know go through every single alert and that's been a huge problem right um um uh now think about llm as uh a tool to attempt this problem you know it can take in enormous amount of you know text Data like you know alerts and like log data sets and everything and it can solarize those it can uh bring structure to the the tons of unstructured data that you have right so um this this is a great example where llm itself would not be a user facing um uh product but it would uh tremend tremendously um help making your existing product uh really effective right like summarizing alerts like increasing the explainability and alerts now you don't have don't want to have like um really uh you know big cyber SEC experts going through all the alerts which is really expensive right so now you can have all these llm um expert systems and assistants who can who can um uh help you with that right and all these um uh pattern and context finding among alerts from like different sources right different vendors um another big uh problem in cyber security is labeling or the lack of labels right you you have tons of data you don't have um uh enough labels especially for uh malicious and attack data points right so uh that's another area where llms can be used you know for for simply going through all the um events and then um uh training them you know fine-tuning them on like specific trains of attacks and then they can start labeling um uh our data and and that would be uh an extremely useful um task when it go when the data goes into your um uh table or you know data sets and then gets feed uh fed into like uh traditional machine learning systems like exost um another use case is unstructured log data you know you have tons of logs in cyber security and uh the biggest use case is ton them into tabl dat um so I I think this is the probably the takeaway from this talk um you know going through all the use cases and all the the uh blog post from like the the current products that are using llms um I think I've come to the framework that you can you know uh uh do the check before uh starting an LM feature in your product right the f i call this the lumus framework and the first one is list Solutions what are the existing solutions that you have and then where does llm fit in right and then the second one is uh user impact how uh directly is your user going to be impacted if your llm featur is going to be um implemented and then the third uh one is measure you know can you once your LM features implemented can you measure the metrics can you measure the market feedback can you can you go back and then you know tune uh the model and then tune how your the ux and everything can you everything that's one uh another one is over deliver over deliver on Delight right the the L feature is the one that's going to give you that half Factor so uh make use of it and then um sustainable it's going to be is it going to be sustainable in terms of cost in terms of infrastructure in terms of scaling your uh uh entire pipeline um so yeah once you go through this uh list I think it's going to be useful to see whether you want to implement that llm feature and um yeah this is I think the biggest takeaway that I would want to have from the stock I think um so yeah that's about it awesome thank you very much arini this has been fascinating we have a couple of questions from the chat so let's see here we have Michael he's asking do you see llms for things like feature engineering as a production solution or mostly for prototyping brainstorming seems like it slower more expensive way to solve something it could otherwise be done with other methods um I I still believe in going from the least uh complex to you know slowly uh going over the graph so uh it could be expensive but I I definitely see it as a a good option for production feature engineering because especially in cyber security domain um the amount of data the the sheer scale of data you see is like tremendous and then uh I personally have seen very know projects get delayed so much because you don't simply don't have labels and then the the model metrics itself are not not so great because you cannot validate them so I think in those cases the return on investment uh uh should definitely uh be a lot more than how how much um you know cost and effort that you're putting in I think yeah we got one more uh from Lucas what are your thoughts on risk llms introduced in the cyber security context so for the non- chant use cases there are several where the llm being wrong could be incredibly costly to the customer and security company oh oh yeah that's uh where the llm being wrong could be incredibly costly to the customer and security company feels like a targeted ml model would be more interpretable and less risky uh that is very interesting and I think the risk is involved uh with llm in general in terms of all the security challenges you know the prompt injection and everything um I at least based on my research I think the risk is risk is more uh in chat based scenarios where you know you don't have like a god rails in terms of you know what you uh input and what you output um when you're having llm as a layer in your ml pipeline I think you can add in a lot more layers in terms of having the security controls you know um uh you can add another layer that is checking your labels like you don't have to like directly plug in your labels to you know a production model and I'm pretty sure you'll have uh more tests and uh which is more practical uh because it's not user facing you can you know iteratively add more uh uh security layers um I'm hoping as you it trate and as you experiment you uh you'll be able to get that optimal scenario um I definitely link this user to a blog post from um honeycomb.io blog I think I think the product leader is also speaking here today um uh there's a very cool blog on that and how they are uh basically solving the uh the problems that you you just talked about yeah on that note I see here Houston saying this is a good presentation exactly what we are working on especially around alert fatigue uh that's awesome I would really love to uh you know uh chat with that uh uh person yeah we still have a few more minutes any chance you could put up your slides again I have a question for you uh definitely yeah I just wanted to go a little bit deeper into that user Delight product slide uh uh yeah uh is this the one see here the Kan model yes the K model so give me one second over time delightful Innovation becomes another basic need and what does this say about kind of like the urgency with which people should be trying to adopt these new technologies because on one hand you do have this I mean you you have this added benefit that you're quick and that you are quick to delight and that could impress your your you know your customers and they can enjoy it um on the other hand if you run too quickly you might be introducing uh dissatisfying experence um no absolutely and uh this is one area that I've been uh reading up a lot uh in terms of what our current um you know uh uh companies doing and uh this is where I would again point out to uh the block post from um hi. um I forget the name of the person but he is given talk here as well they uh talk about uh having a one month timeline uh that they set for themselves to have a llm feature um basically to take in natural language and then convert that into uh honeycom K right so they have like a llm assistant uh it was interesting because they have uh they had set up a very small like a month uh timeline and I think it made sense because the more you wait the more uh you know models come out the more um uh uh better models come out and then you would keep waiting I think uh so if if you see uh a fit a product Market fit in terms of you know your customer is going to get uh uh get use from like a specific feature that you think about right now and then you have thought about the sustainability in terms of cost and then if you have calculated all those stuff um and and they talk about you know using GPD 3.5 versus 4 GPD four uh using JB 3.5 cost them $100,000 per year versus it would cost them millions of dollars if you go for JB 4 so you know you do all the um fine tuning and then do a lot more fine tuning than you would do for gb4 so considering all those you know um optimization of costs and time and effort I think uh the the sooner you re uh once you realize something is going to be useful for the customer I think um um having a a product ready um uh would get would get you uh quicker feedback as well so I think the biggest uh lesson from that blog post was you know the feedback that they got from their users you know what's working what's not working and they could easily uh fix very easily solvable um problems that increase their ACC accuracy from like you know 78% to like 92% which is um accuracy of the llm uh query uh generator which is I think awesome yeah one of the things that's always attractive me to AI is that it it feels like because it is pushing on the frontier of intelligence it gets us to constantly sort of reexamine what it means to be human in so far as you define your Humanity to be at all te to your intelligence well now you got some competition right and so it fores us to reevaluate and it feels to me like there's a similar thing going on with business like you could very quickly just jump on the band bandwagon and start like indexing on this technology and try to to roll it out in a relatively unrig sort of way or you could just be Tethered to your customers and then say actually need from me what problem am I actually solving right and like you're saying to fall in love with the solution it feels to me like AI can sort of force us to better understand our own problems and the problems of our users more effectively no absolutely you're absolutely right I think uh always falling back to you know already we solving the customer problem I think that's good the differentiation between you know a good product and a great product I think we got a couple of things here um how can companies build trust in llm Solutions and products any any tips on that uh that's an interesting question um I think it again goes back to product like growth you know the more uh you you put your product uh out and then you iterate and then you get to a better and better solution when you see and you see and you saw that with you know we see that with ch GPD you know how they have hooked at customer or you know now if another company is going to come up with the same uh type of product I would not immediately jump unless there's like a big uh different feature so um I think uh the product itself the product let growth you know the product itself would uh keep speaking to the customer if you have that hook and in terms of uh uh creating that trust um I think there there are two ways one uh if if I see differently from whether it's uh a business user versus um U inducer um uh I I think for a business user um you start talking to the team and you start evangelizing your product and you talk transparently about what are the challenges um I I think uh the customer would uh be hooked to that even though there are bugs and even though there are challenges I think you you you'll still have the customer hooked um if there's transparency and if there's a a a good communication and if it's like an end user like you know how you're using um um chpt you know every other person is using um I I think simply the customer experience uh people forget a lot a lot of times people forget about uh ux like uh user experience um in data products um uh giving a lot of thought on on on on that area and then making sure you know you're um uh transparent and then if there are any like data related issues being very transparent on the product I think would uh keep the customers hooked I think thank you very much uh we're going to have a fireside chat on stage one it should start out in just a minute I think there's also one more question here that Lucas asks which is a follow-up question uh if the answer is involved you guys could take it offline maybe on slack I will read it at least for the benefit of everybody followup question from Lucas I was thinking less about prompt injection and more about things like hallucination so what if the L assigns a quote benign label to a malicious alert and now the customer doesn't know to stop an ongoing attack because the llm said the behavior is was observed as normal uh so that's a commin issue in other models as well but those are purpose buil classifiers and not next word predictors being repurposed for classification uh uh no that's an interesting uh question and a very uh practical scenario uh again I think going back to the point I would not probably have at least in the beginning where say I'm the product manager we are we are releasing um a feature for having llm as a labeler right um as a first uh iteration I'll probably not have just the the llm labeler and then directly going to production model I will have uh maybe an example of models another model that would be a check on another model that would give a a confidence score uh of some way and then you can I think have a threshold of you know give me the accept the labels only which has like a conference score of more than 90% or whatever so I think uh um tuning with those and then understanding you know um you can go back to the feedback and then understand you know where the llm is you know um having a wrong label and then going back and then figuring out what's the false negative what's the false false positive what is uh causing that and everything so uh I I think in initial iteration now definitely not have just the llm model as um you know um a labeler but have more uh God rails you know how you're choosing that label but but still it would not give like a 100% uh guarantee just like you know if you didn't have that labeler you you might as well still have that false negative because you didn't have that lab before um so yeah I think it's um uh comparing and then uh optimizing for what's the um uh the final result thank you very [Music] much