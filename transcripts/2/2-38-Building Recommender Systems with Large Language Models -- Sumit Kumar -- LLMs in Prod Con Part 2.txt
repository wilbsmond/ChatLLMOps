you see it is out and I've got cement coming onto the stage there he is what's up dude endometrios love the T-shirt thanks man so you are one of the few people that I hear talking about recommender systems or just recommendation engines with llms and I am so excited by this topic because again going back to this llm in production report in the use cases section when we ask people what are they using the llms for recommendations were actually one of the strong use cases so it is I I would say in my mind at least uh the work that I see you sharing you are at the Forefront of this and I love that you are here and you're going to school us on a little bit of it I want to put 10 minutes on the clock I'll be back and I will see you soon man yep thank you so much um I hope you can see my screen um yeah awesome so hello everyone um llms have emerged as these powerful tools for a wide range of NLP tasks and recently there has been a significant interest in the recommendation systems community on um using these llms to enhance various aspects of recommendation systems um today I'll briefly highlight how large language models are being used in recommendation systems why should they be used in the first place and what are some of the associated challenges so before we begin a little about myself my name is Sumit Kumar I work as a senior research engineer a senior machine learning engineer now at meta and I mainly work with content recommendation platforms um previously I worked as a recommendation systems Emily at Tick Tock um NLP research scientist at Amazon and a speech recognition engineer for Samsung um so one of the big motivations for using llms for recommendations is that elements encode a massive amount of external knowledge that can supplement the user Behavior data that we commonly use in recommenders so for example because of its web scale knowledge and llm can recommend a user to buy turkeys when it is Thanksgiving but traditional recommended system may not be able to do that if there is no log The Click behavior that relates turkeys with with Thanksgiving and llms have shown a strong zero shorten Q shot capabilities which can help a lot in recommender systems where we often deal with challenges like data sparsity and goal starts and uh we can also utilize the high quality actual feature representations from llms to more effectively model the X data that we handled in recommendation systems such as user profiles and item descriptions and so on so one way to understand or look at the current state of this line of work is to categorize it into a discriminative and generative approaches for recommendation in the discriminative Paradigm the language models have mainly been used to provide embeddings for the downstream tasks uh bird series of models usually fall in this category which are rather smaller language models and they can be further classified into fine tuning and prone tuning in fine tuning the pre-trained language model is tuned with data specific to the downstream task for recommendations this data usually contains user item interactions item descriptions user profiles and other contextual information in prompt tuning the tuning objective of the downstream task is aligned with the pre-training loss so for this presentation our Focus will be on the generative Paradigm which can be further categorized into non-tuning and tuning methods um non-keating work includes prompting methods which where the researchers assume that the llms already have the recommendation capabilities and they try to trigger these capabilities by introducing specific prompts um in in context learning these terms also include some demonstrative examples um tuning work includes prompt tuning and instruction tuning although the delineation between the two is not very clear but some of the literature calls it uh prompt tuning when the uh when the parameters of the llms are being fine-tuned on a specific task um and instruction tuning when they're tuned on multiple tasks with different type of instructions um this is an example prompt from this research paper from Alibaba where they um evaluated the chat tpts zero shot and few short recommendation capabilities um in this prompting method the problem consists of task description that describes the recommendation task in natural language a behavior injection component that injects user item interaction information into the prompt and an output format indicator the same paper further added some demonstrative examples um uh into the prompt to get these recommendations from a chat GPT in a few short settings um and this study and a few others have shown that uh zero shorten few short recommendations can beat random guessing but um this or maybe some carefully designed heuristics as well but they still cannot surpass the performance of a traditional recommendation model there is training specifically for a given task and task specific data so to overcome these shortcomings several researchers have proposed Frameworks to find you large language models with recommendation data these Frameworks use user item interactions to create instructions that are then used to fine-tune the llms um there are also several Frameworks that take a foundational model approach such as this P5 model then extensively pre-trained their model on a on a number of recommendation tasks with the same language modeling objective and everything is under text to text paradigm zooming out a bit in the recommendation space llms have been used for data augmentation um for encoding text features they have been used for this they'll be news as a conversational tool that also decides whether to continue talking to the user or to call the backend API to further refine the current set of candidates some researchers have also used them as the relankers alongside the traditional retrieval model and in many papers they have also been used directly for generating recommendation outputs um so why should you use an llm for recommendations well um llm says external World Knowledge can supplement the um the behavior data and recommendations and in few short settings we can adapt to new information without having to retrain or change the model architecture their zero shot performance can help in mitigating some of the data sparsity and gold star tissues that are very common in recommended systems and through a chat based interface users can now directly interact with the recommender system confident and they can also use natural language and they can do all of this uh when you compare with the traditional recommended system they only are passively involved through implicit feedback and as a byproduct of Chain of Thought reasoning llms can justify specific recommendations in natural language which can increase the transparency of the recommendation algorithms and using llms can also simplify some complex feature engineering steps like some of the feature pre-processing and the embedding methods and I I believe it's equally important to be aware of some of the problems with this theme as well um llms May recommend items that are not present in the candidate set and they can be highly sensitive to the design of the input prompt um they may give you an answer that is in incorrect format or very verbose where you simply ask for I guess or no question or a rating on a scale of one to five they can also be highly uh sensitive like I mentioned to the input prompts and deciding how many demonstrations to include in the prompt um what kind of demonstration to be include is also an open program right now and IDs um have been ID like features have been very successful in the traditional recommendation models but incorporating them into problems can be really challenging and there have been lots of research papers on that theme as well and online recommender systems are real-time services and they are extremely time time sensitive as well but these prompt generation and llm inference steps they have significant amount of time costs as well um there can be a huge gap between the universal knowledge that's encoded within the parameters of llm and the specificity of the user Behavior patterns that we see in the private domain data and of course data security is another related concern um limited context lens with some of these llms um can make it really hard to incorporate a substantial amount of behavior information or the sequences into the prompts um some studies are also uh shown that in um if there are some popular items for example best-selling books um that might appear more frequently in child cpt's pre-training Corpus they are also more likely to be ranked higher when chat GPT was used for uh ranking tasks um some elements have also been shown to have position bias where changing the order of the input items significantly change the llm's ranking output as well so that that sort of makes them sub-optimal for re-ranking um and some of these elements have been shown to generate harmful content the reinforce social biases and exhibit unfairness to sensitive attributes like gender race and so on and of course there are already a lot of research work on how to potentially mitigate some of these problems and um using LMS for recommended systems has been a very active reason um research area and there has been lots of exciting stuff happening um but that's all from my side for today if you'd like to reach out you can find me on my social session here I also write a blog and a newsletter on various information ritual topics um thank you for listening and thank you with your house for inviting me dude you're too kind man how could I not have you on here it is my honor it's so cool to see this and ah I love it so I'm gonna be in San Francisco in two weeks and I hope to see you in person and for now I'm going to kick you off the stage because it is super late where I am and I'm trying to finish uh at a decent hour I appreciate this to it we'll be in touch man thanks so much thank you so much [Music]