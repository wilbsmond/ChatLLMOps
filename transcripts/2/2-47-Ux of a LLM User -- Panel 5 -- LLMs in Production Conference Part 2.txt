all right our next panel um is an awesome group we have Misty from Jasper AI we have Davis from Innovation Endeavors we have Dina from Adobe Firefly and artem the CTO of Verdine um and they're all coming together to chat about ux of llm users so without further Ado let's bring them up to the stage hello Davis hello Misty hello artem and last but not least Dina all right thank you guys so much for joining us yeah thank you Willie uh are we good to get started yep go ahead all right uh hi everyone I'm the moderator for this uh pale today um today we're going to focus on ux and llms which is a really interesting space and so maybe to start Misty artem Dina maybe we can go around quickly one by one and you can each briefly introduce yourself and in particular talk about some of the recent LM features you've worked on and I'll dive into some more universities okay Missy you want to go first yeah so I'm Misty I'm a product manager at Jasper um and Jasper is really focused on supercharging and content marketers especially and um content marketing teams with their content creation so a feature that we recently rolled out and I actually just got off of a webinar introducing it to to customers is Jasper campaigns so um we've introduced that ability with just one set of context with your selective brand voice to create all of the assets that you need for a campaign instantly and be able to add anything really quickly with that um so that's been a big thing that we've been really focused on at Jasper that and just in general making content creation as easy and seamless and not a headache for users as possible awesome our time you want to go next sure thanks Davis I'm artem I'm a co-founder of CTO at bardine AI um we're a platform for uh creating web web browser-based automations with a heavy use of um AI across the board um the so literally today we uh with the launch that we did was we launched our chat GPT plugin um and basically what it does it allows to uh build automations uh using natural language and this is kind of built on top of the feature that we have inside the product which we're called Magic Box where you just type what you want to do uh and we create an automation uh for you uh on the Fly Austin and Dina hi I'm Dina our product manager Adobe working on fire flights a family of genital bi models for creatives it does text to image text to fonts um I mean it's a model it has its own website where you can uh you know generate different pictures but we also recently integrated Firefly into different Flagship products with Adobe so it's now powering things like Adobe Photoshop generative feel um it's on illustrator gender delivery color and then it's also an adobe Express and hopefully more products so so yeah excited to be on this panel uh disclaimer not a ux designer so you know they're probably better people to talk about ux design so I'll I'll try my best and also yeah just representing mainly my experience working on this both inside outside Adobe so not representing any product not talking about any product roadmap just my own views awesome um and so maybe to start I thought it'd be good if you could each go one by one and talk about what's the single biggest ux challenge that you face in kind of building the product that you just described and maybe you could talk through kind of the different things you've tried and ultimately what you had to figure out in order to kind of solve that uxp so the product you've built and so Misty why don't we start with you on that yeah yeah so um like I talked about at Jasper we're really trying to solve um especially the content creation pain point for marketers um and we are extending outside of that into more of the research and the ideation that happens before content and then more of the publishing and distribution that happens after but just within that content creation piece we're seeing and I'm sure everyone is feeling this the fatigue of so many tools coming out and so many different ways of using Ai and you can do anything from using chat to using like an extension like error PRM to get a prompt and so there's so many different paths and I think everybody went through this phase of being so excited and enthusiastic to try anything and everything um and now people are starting to feel more and more of that fatigue and so um a big challenge that we have is is continuing to to try and deliver the most efficient delightful way for people to solve those content creation problems while balancing that fatigue of another new thing that I have to try um and so is that something that that we're always working on and always making sure that our any new features that we do are really well validated with our existing customers and with the market in general um to make sure there's an appetite for it and that we're not just further contributing to that burnout of new features our time what about you um I think kind of unpredictability and non-determinism of uh llms uh is a is a ux is that is definitely a challenge for users um in terms of experience because uh you pretty much never know what you're going to get sometimes very simple things do not work and then you know very sophisticated things work surprisingly well um so in terms of a challenge we um um and I I mean I I very much uh kind of want to Echo what Mr said in terms of fatigue and hype uh you know around this so I think at this point users expect a thing that would work and so for us the challenge was to embed this new amazing kind of capability that llms provide into the into the flow of our product and make it seamless and make it so that it really makes the user experience better as opposed to just you being there because everyone does that and because it's a cool thing to do um so for us the main challenge was to kind of you know design The Experience around the fact that um you know llms are not perfect and kind of come up with the modality come up with the way that would that like basically almost make it that so users don't notice it right and if you think about it a lot of amazing products early days had the same problem like Google uh you know with the very first versions you almost never got your results right and they even but I think the way they solved it is with the ux so when you search something they drop you on the page with the results but the search box is still on top and so like naturally if if what you're looking for was not there you would go and refine that search and later as the product matured they started doing a better job at it so we're now when I'm starting to type there are like five things at the drop down that I can click but it's essentially the same thing it's this kind of a play between uh you know your model and your user where like they they do this like sequence and I think that the biggest challenge just how to make this sequence seamless so it's like very natural to the human being who is in front of the computer using your product and we may have just lost DNA for a second and so maybe a quick follow-up on that um can you talk through some of the core design patterns that you built out that kind of helped you solve that problem so I think one thing you touched on for example is refinement workflows you know the llm produces an initial response you allow people to edit what are different things you've tried to make that work and like any learnings on what worked well when you're doing that and what didn't work well when you were doing that for sure yeah I think one thing that what I mean will literally did what Google is doing right so now when like if you go into our product and try to generate uh you know an automation from your description uh we will kind of drop you into the preview mode and we still have that that box on top so users naturally kind of you know know this like oh okay this is not exactly what I what I was looking for but let me go and refine that um the other thing I think is kind of like nudging users to to to to give them the right idea of like how to formulate their query so basically think of it as like a a drop down with um with um you know suggestions of like what might be relevant and I think it's the interesting challenge there is to kind of use existing like old school AI things like recommender systems uh you know collaborative filtering uh to kind of find the right things to suggest to the user that they can go and further like you use with an llm uh uh I mean it's a fascinating thing because if you think about it the effort to go from like nothing to a 30 40 working prototype is virtually zero like you can in an afternoon you can you can get something that get like and then you post it on Twitter you get excited you slap a waiting list on top and like you have your new startup but then you hit up this almost like a vertical wall of like you know if you want because that's not a product like you know if your product only works three out of ten times users are not happy with it they don't care if it's new technology so and then to make this improvements further and it becomes like really challenging and you have to find this new way like creative ways to uh to actually kind of overcome this and you know have other things help you help your users use the llm in the right way that makes a lot of sense um I think both of you touched a little bit on what I would describe as like the broader idea of interfaces right so natural language is obviously a more common interface with LMS in general even natural language there's different ways to express it from chat to maybe just a One-Shot language command and then a lot of teams are actually moving away from language at all and llms and you try to abstract it behind you know a button I'd be curious how you guys have thought about um interfaces for LM based products and how you've learned or thought through like what is the right interface for these different types of features maybe Misty we can start with you yeah and yeah I can definitely relate to that like overnight we have so many Engineers all the time that will build a POC and we all get really excited like wow you could do that in the night um but yeah then you hit that vertical Cliff so um yes we uh have kind of been all over the map in Jasper and have had a lot of internal debates and have done a lot of testing over whether the chat interface I'm like leaving it totally free form is better or um we actually just this morning um obscured our Command bar which our Command bar was like a very loved very cool thing where within a document editor you had a bar where you could type in commands and generate outputs and uh with one click add them to your document um and after a few months of use we realized that it was clunky and it was in the way so it's something that we're always evolving and iterating on the product I talked about at the beginning of this Jasper campaigns that started off with a chat interface with just your typical bot interaction of tell me about what you're promoting um tell me about what your goals are and who's your target audience and we um after some feedback decided that that was even too difficult that having to read and to write so much in order to get to that path of content generation was too cumbersome um and therefore moved to more of that button interface um so uh it is something that we are going to be evolving and changing every day like we took out the command bar this morning maybe we'll bring it back today I don't know um but we will always get that feedback and um a lot of that feedback is coming through what we're seeing people actually use which we'll see by often What They're copying out of their outputs and taking someplace else um but yeah always changing do you have any I'm curious given you've tested so many things do you have any intuitive rubrics or rules for when you think oh this type of problem space this type of feature lends itself more towards this type of interface or is one of your learnings that in a lot of these cases you just need to test them all and see and it's hard to know operatory what's going to be the best yeah it's really hard to know what's going to work best in any situation um something that we are seeing consistent really positive feedback about right now is a totally introduced a few weeks ago called Dynamic templates um and the follow-up to that was something we've called remix so um Dynamic templates have given users the ability to just in a free-form field tell us exactly what you're trying to do so like I am an SEO specialist and I have some set of keywords that I'm trying to Target and I'm trying to create Google ads um and then from that we will dynamically generate a template where we have an input field for the keywords that you mentioned you want to give us and we have an input field for more context and then we will output the ads that you've asked us to Output um and that has been something that was kind of that because it was something where like yeah it takes a lot of upfront work but people pretty consistently have loved it and have just found it to be really powerful um so that is something where we are taking that power and trying to implement that elsewhere in the app um interesting um and so Dina welcome back um I think maybe um and so maybe we can go to you for a second and I I think I know one thing that we discussed a little bit over email before this call was that prompting was something that you guys have thought a lot about at Firefly and how do you help users know how to craft prompts create prompts how do you maybe avoid the need for them to do prompt engineering um well maybe we'd love to talk a little bit how you thought about that at Firefly and I think it relates to this question of interfaces how often do you even want to expose a a prompt at all to the user yeah yeah I think uh being able to The Prompt is right now right because we do text to image that's the main thing that you you use to uh generate the image of your that you're imagining so uh most people I mean this is a pretty new technology like prompting is basically the new Googling right most people might not know how to prompt it properly so if you look at some of the data we're seeing like an expert right somebody who has spent a lot of time perfecting their prompt engineering skills going to get so much better results uh like 90 percentile results versus somebody who just says give me a picture of a dog right you have to add much more details on top of that and I know we've been saying that prompt Engineering in the future might go away you know it'll be much much much easier to to do prompt engineering but from what I'm seeing is that you really do need to put in um a good prompt to get a good result so I think uh there are many ways to do it is you could autofill a prompt so when you when you get a prompt uh you can essentially use eiml there to essentially predict what people want and you might have your own data to essentially have an idea so instead of typing the whole thing and having a whole sentence prompt you actually help the user and then I think what we do on the Fire firefly website is that after prompting um I think it's really good to have predefined styles so we have predefined styles it's essentially in a form way so you'd select a resolution you select is it going to be classical style do you want an anime style right maybe that's something you don't want to put into your prompt because it kind of like takes up your space right so if you look at me Journey prompts are very long they're like photorealistic uh 3D extreme resolution and then you keep adding v5b things sorry so I think that Adventure will go away and this is something we're still working on it's like how do you make it very easy just put what you really want in the prompt and then maybe have some type of canvas predefined Styles drop select right combination of all these things to really help users to generate what they actually want and then I I also really like generating variations so then you learn from these things and you can map it back and you make your prompt suggestion better so I think uh we're still at the very early stage where I'm not sure what would be the the right combination of tools but I think um as we keep learning as we keep as collecting these feedback we'll we'll have a better idea on how to really Empower um you know users to generate what they want artem I know you mentioned prompting uh earlier in both uh you also talked about like AI suggestions for prompts I don't know if you guys also do like templatize prompt configurations similar to what Dina's mentioning or some of the other things like that I'm curious any insights you've had on how to abstract or handle prompting from the user's perspective on your end especially because you have a very uh bardine is very complex task I can create these are arbitrary automation so in some ways it's a more complex design space from a prompting angle yeah um I think uh the the context is important here so for for instance for to creating designing automations we want to be uh we want to have as few restrictions as possible uh and then just let the user tell whatever they want and like some users are very chatty and some users are very kind of you know concise and so we've kind of compensate by just trying to do as much of habit lifting as possible on our end um and just you know because again the surface area to cover there is so big that it's like very hard to cope with something template now when it comes to kind of other aspects in the product so again we're an automation platform and we but if you want to say like okay I want to create some let's say Outreach workflows for myself so the task here is much more defined here I want to generate text and I think what uh Dina said uh you know makes a lot of sense it's in our context as well where you basically uh there's a spectrum like one spectrum is like you just it's a box where you have to put your entire prompt yourself that the end of the spectrum is just one button is just like generate Outreach email for me and I think what we have in the middle is that sort of template or like the the the the kind of the drop down selection where we guide the user through like okay you're trying to create an Outreach email now that we know the task we know the dimensions across which we need specialization or we need your input and so we let them Peak those Dimensions but then what we have at the end we have actually we have researchers who that were basically constantly evaluating um a lot of different prompts different combinations how to like call out the model how sensitive is the model to different changes that we make and we we do like you know formal evaluation so we try to get a few kind of input points from the user but then what happens in the back end is we basically construct the pro like construct the actual prompt that we want to send to the model on the on the Fly so yeah I mean you know tldr just thinking about u-axis at large is um you wouldn't fly a fighter jet with like a text message right like you need like the interface there is very kind of detailed overwhelming for someone who's not a specialist and um but but I mean at the same time you don't want to put like a fighter jet like you know like really really complex UI in front of in front of the the person so I think what we try to do is like as quickly as possible to try to figure out intent and then once we know the intent just have a kind of Highly specialized highly kind of tuned something that would be like put user into a familiar place like because like users know how to click through with Wizards like for 20 years they have been like primed to go through this like very classic ux and then I think you know the the secret is that there is no magic bullet you have to kind of think about your domain and make something that that is familiar to the user but at the same time kind of leverages all the you know kind of magic behind the scenes it makes a lot of sense um so maybe let's move on to the topic of accuracy and I think we all know that hallucinations are big issues with large language models and it's also hard to set user expectations around when will this be right and when might it be wrong you need to check it so maybe Misty we can start with you would love to get a sense of how you guys think about constraining the output of these models making sure they're accurate or helping users understand when it might be inaccurate and they're going to need to deal with that on their own their own yeah so um that is something that again we're going to continue to improve on but right now um the best way that we're ensuring accuracy with Jasper is with this toggle that we have in Jasper chat you can actually enable Google search so that is something that we're seeing a lot of users use when they're not only wanting to creatively write content and generate content but they're also wanting to have that fact checked against some resources from the web um and we will even including some prompts or we'll see users including some prompts um to include URLs to the references um and those URLs well from what I've seen for the most part they are real URLs but there are still cases of those hallucinations where it's like factcheck.com and and it's not um or sorry that probably isn't really URL don't go to that but um it will be something made up um and so um we are still recommending that people fact check anything that is stated I mean out like just as a workshop we've done like right the legal defense of robot marriage and like Jasper did an amazing job writing a legal defense and defending with all these historical Supreme Court cases that obviously never happened um so yeah it will be something where we're continuing to to add um potentially like accuracy scores in the UI that's not something that we have today but um but the capability is growing to be able to score accuracy and display that to a user so something we'll be thinking about and implementing in the future and maybe Dina would love to get your take on the same space I mean I think you have a more creative product so maybe there's less issues about fact checking per se at the same time I assume you still may have issues with the model being uh probabilistic and maybe not doing exactly what I expect as a user so have you guys had to deal with problems like that and how have you approached it at Firefly yeah definitely that's a big problem uh especially when you're generating images it's it's about the like uh we do have on the web web UI like thumbs up thumbs down and we do ask a lot of feedback so first is like is that what you really actually wanted right that's the information we want and then the accuracy is this quality good because it's possibility right we'll generate something that's poor quality that's you know corrupted also it's also content moderation I think that's a big part and it's FW we want to make sure we're keeping our users safe and not accidentally generating something that is not uh safe and so we let them kind of report these issues and we save that and bizarre like when we're developing our foundation model like it really relies on the data like the causes of all these inaccuracies like goes back to the data and so we have to improve our model based on these results or also improve based on the prompt side based on the you know like the post-generation side so there's a lot of things we do um to essentially interact with c that it's safe and I think it's going to be a big field going forward for LMS because uh frankly right like you you have to now do it yourself essentially so so very excited for you know different people to work on business of w filters classifiers models gen AI content moderation type tools to sort of make that process easier because that's where the kind of like that's the last mile uh type problem that becomes really relevant when you go to production and Arta maybe would love to get your take on uh maybe two of the things Tina mentioned so one is this trust and safety layer is that an issue for you guys that you've had to think about and then number two I think Dina brought up the idea of um measuring uh performance and getting feedback and using that to improve the model over time how do you guys think about what signals to collect and how to quantify performance over time just throwing in a quick two minute warning thank you um yeah I mean for sure it's an issue because like you would be surprised at things that people want to uh automate um you know um you know in terms of accuracy I think we kind of we knew it was going to be a challenge so we kind of went overboard so we basically designed a language a DSL a domain-specific language for defining automation that has been built properties that make it easy for us to verify the accuracy and then we also again for us it's we're we're not trying to take humans out of the loop so for us is the automation is like we want to show that we want to like human is the people are the best kind of verifiers of accuracy and so we show it to them and say like hey is this your intent and then along the way like uh dinner was mentioning we collect a lot of telemetry data like thumbs up thumbs down uh how many attempts does it take them to get to the automation they want are they happy with it how often do they use it afterwards and then of course all this data were feeding back to our kind of you know creation cycle so we continuously keep improving on that got it that's interesting uh and let's see we may have one minute left maybe we can do a lightning round and one last question I do financially on the ux side uh latency and performance can be a huge deal for LM applications that massively affect ux and iteration speed of the user maybe really quickly would love to talk to each of you guys maybe starting with Misty then Dina then artem on has it been an issue for you and have you done anything interesting technically to improve latency yes um latency and error spikes um have been an issue so uh for more context Jasper is an application layer that sits on top of these models and so a lot of the time that latency and those error rates are sort of out of our control um and we have built um data monitoring and Reporting using datadox so we have really good insight into anytime those spikes are happening where wait times are becoming especially long or um or error rights are becoming especially High we're then able to post um messages in the dashboard if there's something especially problematic like hey Jasper's running into some snacks please be patient we're working on it um and then we are also like probably more importantly we have them funded fallback strategies anywhere where that's been identified as an issue um so we're able to quickly switch over to a different model or different provider in order to hopefully deliver better performance and get people responses as often as possible and not the highest quality possible yeah uh I would say we deal with the everyday scaling it's obviously a good problem to have when you're when your expectation was exceeded by so much that now you have to scale and change computer like stop something to send compute there so definitely a problem um but uh but yeah I I think are excited to see uh especially on the serving side how do you serve but I think if you look at our website our latency is pretty good because we've been serving these ml based features on top of Photoshop and different products so building on previous generation of architecture but also like exploring new things to make it better um I mean we kind of there are some things where we can just use traditional boring solution to the latency which is caching um and so we we heavily do that so if like you wanted to create an automation it's going to be and you describe it the same words as I I don't need to run through llm to get you so um uh we do that um and then uh I think I'm super excited about small models model because then we will be able to run them on the edge on device and I think that's the solution to the to the to the latency problem which is like highly specialized my smaller models that that we can distribute uh so are you running any models in the browser today or not yet I know you're in Chrome extensions yes we are we are we have a very intensive like it's it's amazingly it's so good with like you don't first you have don't have to pay for it then it's so much faster so yeah awesome uh well I think we're probably a little over time um I don't know if the moderator needs to come on but thank you all so much for uh doing this yeah thanks for inviting me great chat bye thanks for having us this is awesome thank you so much Davis Misty artem Dina especially Davis for guiding the conversation it's not an easy feat with like a couple people so that was awesome definitely um yeah all these talks will be recorded and then we're also I guess there were no slides for this one so I will not be sharing slides but thank you all so much for joining us this was awesome well all right so long