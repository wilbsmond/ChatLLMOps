hi everyone my name is fie so I'm the CEO of commy called Bas Ron so Bas Ron is a testing and avability platform for um apps um before I start Bas Ron I was at a company called Cruz so a lot of people from us might be familiar Cruz is a soft driving car company uh and my job there is building ml ml op tools or at Cru U St I would like to share a little bit learning from you know building self-driving cars and how does that experience apply to building a applications um Al first uh the output is not battery so similar with a this is kind of like a one to webuild internally at a Cru as you can see the to explain how a performance uh perform is actually very complex this two called the webw you can see there are a lot lighter lighter reader sensor we had and how to visualize the data and this is really similar to LM today as we processing a lot of uh data is not the same as before we can have like a simple like unit test and banner saying pass and fell and a lot of times large language model output need more deep analysis and the tooling around it is getting a lot more complex um the other part is changing the model is not that easy so uh Cruz is about to launch uh this car origin this year and this car has no steer wheel uh in a car and this car took us about like even three years ago when I work at a cruise we start to work on this like research paper around how to uh switch in from the boat that model of car to this new model of cars and similar with large language models a lot of people start with gbt and over the time they might want to use llama index but often times when you switch the model you need to re-evaluate your whole app of performance end to end um human work creative U this is a very interesting news on on online and cruise car uh whenever we see a safety stop we we have to stop and so there's some people start to trick the car by putting uh like a traffic or on top of the car the car will stop right there and similar with people building with the LM today so you know your user might try to jailbreak your user might to trick the AI to share certain information is they are not supposed to share so this is something we need to watch for as we building um features um feedback the key uh this is the image uh when Cruz is trying to expand our service uh into Austin and in Austin is a very interesting situation um that the police sometimes ride a horse uh that's something we never saw at uh San Francisco so when the cruise car expand to the new city uh the car kind of got fre can out because they don't know how to identify this object uh this is very common these days when we building with large lry model and a lot of use case we don't really know exactly how end user will interact with our application so often time the best way we can do is the collecting the feedback as we shipping improving our product and itating on the feature over time um user experience matters a lot uh this is one of my my favorite app called clay uh as you can see this particular feature I'm trying to ask um is a personal CM I'm trying to ask a question if I want to host a dinner who should I invite from my network and you can see this animation very similar with how Ser works and roughly we all know LM can takes time and sometimes U we I saw a lot of developer do is really focus on performance focus on latency and cost but all what we actually deliver is end to end user features and in this way this particular app they trying to use very beautiful design animation to uh you know help us focus on on other perspective of the app and focus on the latency and so or the experience turns out to better so this is something give us some Remer end of day we are trying to build a feature for the users and how there's a lot of way work around out and feature uh instead of like being limited by the latency cost all the challenges it come with uh it's all about quick iteration cyes this is a from one of the Cru block so very simil as large language models we are trying to collect data and use that uh through the monitor faces and then bring that data go back to prioritize the feature requirement analysis inset and use that data go back for testing and iteration uh this is where true with large language models as well well as we building features it is a continuous development uh life cycle uh is a continuous cycle for iteration and last one is brain Team Al uh so uh at Cruise a lot of times what we do is we have the car running around on the road then we have a release team and QA team they are trying to review all the data com in as we uh recorded all the events and they are the team actually on the front line uh and analysis all the data uh summarize them to insets before they surface the insets to the engineer lead then engineer lead work with the engine team figure out a solution um I saw this trend um became more and more common uh with our users a lot of team has pm and engineer work together and the PM or the operational role are the role actually doing the monitoring day by day there are the people read all the user interaction summarize them and then um bring them back to full iteration and in certain cases we saw PM also jump into the prompt iteration faes they might write the prom themselves and they do a lot of testing as well so this give us some reminder uh if we could bring the D expert into our development cycle overall we can uh you know produce better results so after all this what I want to just end with something actionable you can take away as you are thinking about developing um features uh first is the testing at different stage so this is some learning at cruise I do think it directly apply with building large langage models so I see a lot of developers starting really starting with really focus on particular Alum cost but over over time we see people's workflow get a lot more complex uh these days we see developer building agent or building complex workflow they normally need to chain multiple Al calls together with third part API costs with customer functions so one way to think about testing you can structure test as three phase uh one one is a unit test so here is the phase you are trying to test if a particular Alum call perform as expected and then you can have a subsystem testing phase so basically um you can have a particular Stu workflow if it's a little bit you know separate from the rest uh application you can test that particular workflow first to make sure workflow output is you know accurate as expected before you uh pass into the next phase and then after you might want to end to and test which the goal is trying to measure the end to endend user Journey um as we doing all this different test bases is also important to create a Topline metrix that reflects and user experience um so at Cru When we working soft driving cars we want to make sure the car is very comfort for the customer we want to make sure the car is very safe and we also want to make sure the car can drive autonomously so we have a metric called take over rate so that's the metrics we use throughout the development cycle I think that's very true to our uh LM feature as well so thinking about these days we see a lot of developer really focus on cost and latency but end of the day if that delay is not g to impact your customer experience or certain way you measure metrics it has directly you know like a direct memory experience you might want to create a sub Matrix correlated with the nend experience the nend experience might be you know if user click some up some down to a particular interaction or maybe user was able to achieve a particular task use that type of metrix product Matrix as a product as Topline Matrix as you developing the feature and then break down that uh Topline mat into sub Matrix as different testing phases so or the team has a a very clear goal setting as you're going through different develop set develop faces and also uh it's clear for the product owner all the developers understand where we are where app performance is uh so create more alignments um creating like shared goals uh another part is the closer Loop so as I mentioned earlier around we need to use the feedback to continue iterating so no matter what your tag stack look like which to are using right now uh even you use like a different point solution for monitoring for analysis think about how do you bridge the gap to make that data pipeline is more Streamlight so as you have the data more integrated together over time you can make iteration a lot faster uh the last one is make it collaborative earlier I mentioned there a lot of operational product are more involed in the day byday uh development process now so how do you make your to collaborated bring in the non-technical user um give them a ability to you know annotate annotating all the monitor results uh testing result review the test result and also give them to to empower them to directly impact the prompt maybe do AB testing or give them to have them like fun the model uh down the road so that's overall will helps the team move more efficient um that's all uh if you have any question uh feel free to check out our website at vr. uh all email us directly [Music] and