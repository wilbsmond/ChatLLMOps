and next up we have Jared with a beard that I think can compete with one of our speakers yesterday I don't know if you were if you saw yesterday our speaker um oh my gosh I'm just basically his name Chris brousseau I'll take yeah I'll take the competition with her that sounds okay yeah not only did he have a beard that could almost compete with yours he also tied in a metaphor for the beard in his talk so I don't know we'll have to send that to you later but now I'm still unprepared yeah I know you're gonna be great okay so I don't want to eat into your time without further Ado let me pull up your slides whoops all right thanks so much no thank you uh hey everyone uh thanks for coming to this I'm talking a little bit about uh what local llms and LMS and production means for Missions and defense and in public spaces so uh without further Ado uh just a quick intro I'm a unicorn engineer at a company called defense unicorns where we work on very critical missions for uh defense and in other Arenas so I'm an open source developer I've done a little bit of founding startups and currently I work on building generative AI for for Critical Defense submissions so let's talk about a little bit of what that means and we're going to start off with the fact that regulated environments are incredibly challenging to work in so the past few months weeks has been a shell shock for these environments where just yesterday it was revealed that a massive Global Cyber attack happened data was exfiltrated from multiple States most multiple financial institutions multiple industrial components as well as the US government and this is a story that has played out multiple times in the past couple years as the amount of data the amount of gravity towards these systems and the importance of the system grows so that's led to a very interesting question of what does generative AI what do large language models mean for Federal defense and sorts of missions so we're talking about from one side we're talking about like a lot of Regulation coming from some of the largest creators of AI current and LMS out there but also Declarations of from from a government side of how do we figure this out how do we acquire this how do we manage the risk of it and going down to having industry experts and other other people come in and talk about these uh in in the in in spaces because I think there's a recognition that solving this is critical and we'll talk a little bit about why that is but we can just ignore this problem from these environments so let's start a little bit what is a regular environment right like we should Define this term because that could mean that that could be easily be a weasel word it could mean nothing it can mean a lot the way we look at them at defense unicorns is their first and foremost very Mission purposed environments they are suited out to Define and and achieve a set of goals that is widely applicable or narrowly applicable to to some other domain right and often these are very restricted regulated otherwise isolated we'll talk a little bit more about that but uh since in some way these environments are restricted to who can access them why how who can you can develop on them they're often very egress and Ingress controlled and it's easy to say air gap but often these can be completely air gapped these can be completely on the edge in in various theaters or they just may have a lot of controls and restrictions around them and so that that often even has a fine meaning in and of itself I think the one of the most important things though that these are often very high value targets as we see with the cyber security issues up to a nation-state level from an attacker and a defense perspective so in that we're often talking about areas like Finance we're talking about health care Healthcare data and access to health care data and leaks of that is very critical as a financial financial data we're talking about civilian government data and we're also talking about defense data that goes up into very sensitive information that creates very serious security issues for nation states if that were to leave so what's the problem with just going and using these apis the these tools in these environments well first off there's often a perceived resistance to Innovation and whether it's not true or not is not part of this talk but if you were to ask uh often I find in conversations these spaces are are so heavily burdened by that regulation they just don't want to innovate they're living 20 years behind I find that often not true but sometimes that's in the eye of the beholder what is what is absolutely true is there's very high requirements for deployment and operation in these environments and we'll talk a little bit about authorization to operate we'll talk about some of the data needs we'll talk about iron bank but there are steps you can't just deploy you have to actually go through steps in order for this to go run even at a very granular level and that can often differ who you speak to the processes that you need to go through with that alongside that you need to go through a lot of artifact control requirements and uh most recently people have been dealing with that with containers but if you look at large language models and other generative AI model weights as an artifact those control requirements will continue to become more and more important as well now a lot of this may look like okay well well we just won't innovate there and I would pause it not only can The Innovation not stop in this Arena that it is a a critical issue if we do start to challenge the fact that Innovation does need to happen in these spaces and I really want to focus in on this thought that Innovation and the availabilities models does not change anything and pushing for that Innovation especially in these regulated environments in these defense missions is very critical uh as part as of a partnership with open source spaces and and space is relevant to the talk that I'm talking about here today so I'm going to refer over to a talk that that Mark Andreessen put out just recently about why AI will save the world and it has it's a very long Treatise around the a lot of the fear and certainty and doubt around the regulation of smaller entities and smaller models and innovation in the in the large language model and generative AI space and one that one that stands out and uh is the the real effects for stifling innovation in an arena where others will continue to move forward with that Innovation and in fact have their own views on it and I won't read this quote out it's worth reading this blog post too to go and and form your own opinions but the the reality is that AI is a very competitive environment that often has a and and right now we believe that AI is at a very critical inflection point if you look at all the Innovations daily it's almost a full-time job just to keep out up with what's going on in in open source in the industry much less the needs that are being created in real time from all that demand and all that Supply so one thing I would I would pause it in that article is that power projection in AI is real and so what does power projection mean well power and how does it apply to generative AI well power projection in that General AI space is really about changing the relative cost of conflicts fought across domains so what were what the real benefit of generative AI in these missions is an opportunity to make conflict domains far less expensive for these environments to work in and incarcer a far higher resource cost to adversary actors initiating and engaging in conflict and if you look at that across domains we're not just talking about connect domains but cyber attacks we're talking about every domain in which nationally States and others interact with each other and not taking advantage of that is creates an imbalance that that we're working against so how do we start to enable this sort of innovation what what's what's our next steps to get there right and we're looking at it as we need to actually be in a community space so local generative AI Solutions are are critical for this and one thing I really love from the modular talk at the last LMS in production part one was seeing that small local LMS can really excel at specific tasks and I'm speaking to the Stanford I believe was a three billion model that that really outperformed at the time others on Health Care uh q a questions right we're now in an environment we're looking at new LMS or generative models a day I think right now I'm working with wizard 40b for code that that's really trying to like build out uh on it and two days before that I was looking at starcoder Pro so the rate of change in llms is massive and the tools need to be as accessible as the rate of release of these models themselves not only that there was a problem early on where okay where do I get all the the chat and instruction tuned uh tune uh data for these models right and so we're starting to see these big corpuses of Open Source chat instruction tuned uh find data and recently I think in the past couple days uh just saw an entire fine-tuning that was based off of effectively what open ai's new function tune modeling is doing so this is continuing to grow it's not stopping right from that perspective then it's critical to be part of the community let's not build two classes of tools that nobody else uses let's enhance that while also getting the benefits uh in both directions so okay how do we get to that Innovation well we want to build open source tools designed for Mission oriented environments highly regulated environments that needs to be a multimodal and the important part about there is not about just llms but speech to text image image text image all of these provide value in different ways and the availability of those is critically important to be able to create a complete solution and we'll share some demos I'll show some Demos in a few uh demonstrating that and then having ml Ops tooling around there so I'm talking about the tooling to go fine-tune to go observe to go deploy and deploy in a variety of environments benefits everyone working in in the open source as well as these environments that have these restrictions but I believe they have to have parity to existing open source tooling as well as proprietary apis so being able to go drop in llama index Lane chain uh guard rails Microsoft's guidance tool I think I believe that is critically important to be able to drive adoption there with small LMS and being able to drop that right in ready to go be whoever's API is backing that so today I am I guess introducing formally for the first talk but we've been open source for a little while uh something that difference unicorns has been working on called LeapFrog AI and what LeapFrog AI is and open source open contribution Suite of apis and tools for everything from deploying running performing day two operations on everything you need in one package to do generative Ai and these very adverse highly regulated environments so out of the gates we designed LeapFrog to be ready for egress Limited in Ingress limited environments so anything air gaps are highly controlled um regulated so these these areas the complete ownership of their data they can't put that data into other places sensitive in the sense that access to the apis and the data itself is very limited both from and and maybe different for who is developing who's creating the tools and who is using the tools and secure so we were coming out of the gates ready to go with uh very hardened containers we're looking towards authorization to operate so that uh that various Arenas can go pick them up and go use them and and and that is kind of built into the core of what LeapFrog is doing so where are we at today uh we are sitting with an open area compatible API I'll show that in a few minutes um we have llm support so actually building models out is the as is really just creating new grpc backends which we've built a harness and tool to be able to do uh and I'll show a little bit about about that uh and we have a community space that can do that so we support both grpc and HTTP for backends for these models um and speaking of HCG models we have speech and tech support so that's where we're using whisper uh large V2 in that example we have support for embeddings and embeddings models so at text-to-back support uh this is then really out of the gates to run a distributed environment so so every model that we have up there right now supports GPU and CPU uh and actually uh NPS the metal shaders for that matter and so uh when I say distributed our default deployment instructions go over kubernetes they're assuming that you have a cluster of machines instead of often tools we'll expect you to have a big monolith that you're running one thing at a time you're loading in and out in this uh you can actually go start to scale LeapFrog from day one and right now we're shipping with VBA from a vector database perspective because we wanted people to really get started with being able to add in Vector embeddings into these prompts very quickly so I'm going to take a quick look as I switch over to I'm going to take a quick look at questions will I switch over to My Demo environment uh okay I don't see any for the moment so I'm going to switch my screen share and go over to let's see here first off let's do a terminal based demo and I'm just going to uh throw up let me make it a little bit bigger for the purposes of this the slideshow and I'm going to go import open AI and we wanted this experience right out of the gates we wanted to be able to do that with hug and face and as part of that caching models in the model zoo and browser we'll talk about that but if we just set the opening eye um dot base your or API base uh and we put in a key right out of the gate so we can we can start to look and list models that are out there available if I were to choose the right API base so this is the cursor light demos so we'll go to a model list and now we have our list of models so we have stable m3b tuned here we have um text embedding 802 this is actually stable um sorry mini LM uh uh uh it's it's in the repo I can I can demonstrate that but or so all at many album l6v2 and we have whisper so if I were to come in here I can go create a completion and this is federating out so it's hitting the front end AP API server and from there this completion goes over grpc is able to stream back to another back end and so ready out of the box is very critical for us that these Community tools just work um and so we have a response we've got the tokens so that's one that's one way to use it uh and out of the gates as well we have an an embeddings response endpoint so for people working with our Vector database they can go get vectors just ready to go so I'm going to switch over to one more set of demos here um and then get back to the slides wow let's see here so we actually hosted a a internal hackathon once this was starting to get released and uh we were wanting to use it internally and so other unicorns might some of my colleagues actually went out and build applications over the past couple days uh this was Thursday Friday demonstrating all the things you could do with this and so one of them built Doug is is the defense unicorn's mascot uh so we actually built out a they built out a Doug TransLink tool so if we drop in a translation and this is the speech from Yuri gargan launching the soyuz we can do that translation and it's even multimodal to where you can hit summarize with it the uh is interesting in the translations but that's that's why we wanted to be able to have a zoo and a propagation of model availability so it takes about 100 or 10 seconds per minute of audio so it should return back here in a few seconds um and so we have that that that translation we'll skip the summaries for now but that goes back and hit stable lm3b for that and then one more thing we did was with the code model be able to go in and ask plot air quality data on June 6 2022. so this was actually able to generate out that plot get that data for us and and be able to perform that and this is really represented a lot of the real things going on in these environments and the things that they work on so I'm gonna go back to my slides now uh bear with me here we go so to look at the roadmap real quick and Lily on your end is the do those show back up okay I'm gonna go with no yes for for that uh what we're looking at from a roadmap oops there we go my page was unresponsive so back from a roadmap perspective um so let me make sure that didn't drop me I seem to have Frozen okay we're back uh so from a roadmap perspective we're working on ggml and corporate quantized model support we want to be able to support more models in more places uh we want to be able to do a model zoo and a registry uh and then enable apis for fine-tuning and Performing model availability for these missions we get a lot of questions and requests to be able to take a model fine-tune it and continue to use it um proper apis for document management and ingest and really just adding more models in so with that I wanted to thank everyone for coming to this talk I really appreciate the time and and everyone's spent to come listen to this and uh I guess I'll turn it over to questions q a um but also talk about like how to come contribute so we're open source open contribution this uh we're working with various open source foundations for to find a home for this uh the repos available there we have a Discord Community um and then come check us out at defense unicorns and uh one thing is is all of this would not be part possible without a tool called zarf uh that allows us to really quickly another defense unicorns project it allows us to very quickly deploy and get uh tools like this into production and air gapped environments I feel like sometimes with the virtual conferences you don't get the kind of like applause that you do in an in-person so I want to try and try and replicate it thank you thank you that's a thunderous Applause for for one so thank you yeah all yours all yours you don't have to share it with anybody um thank you so much let's give it a moment there's a bit of a delay so I want to give people a chance to drop questions in the chat if they have them um and also highlight the weeviate shout out the MLF Community is actually partnering with webe to do a couple um hackathons we have one in uh Berlin happening tomorrow so it's cool to see that you've used weeviate and have found it to be useful yeah we we interact with them uh we've had a lot of success with we V8 I I can't recommend them enough uh if I'm doing local work I'll use chroma but for for us for weba they also just announced multi-tenant support which is really important for us uh in these environments so being able to fully bifurcate all of the collections at a system level critical for that type of work awesome that's great to hear um all right people put your questions in the chat um and I think what we're gonna do on this stage once we let Jared go is we're gonna have a dance break uh Jared you should tune into that after this Demetrios has a dance break for everybody to move a little bit so maybe I'll send you to the chat maybe you can share some links there and answer any questions um for folks and yeah this was awesome thank you so much yeah no problem and actually to follow up on that I'm in the ml Ops Community slack um I'm in this chat and uh we have our Discord as well for longer term questions and then again open community so people can come open issues so available in lots of areas for follow-ups awesome I love to hear that that's that's cool all right well have a wonderful rest of the day we appreciate it so much thank you all right