all right hello you disappeared but now you're back I had any issue with the system oh okay cool well it's so nice to see you how you doing fine thanks for asking yeah okay so I'm gonna pull up your slides um and I think if you can just let me know when to move to the next one I'll make it out of it can you see them yes I can see them so okay thank you so you have to uh be a clicker for me today so thank you as well so right so thank you for having me today my name is Manoj I am a CEO and CEO of AI Shield AI Shield is in a Corporate Center of Bosch and what I'm going to talk today is about how to transform the AI Safety and Security and I'm going to talk you through with a very specific uh a slight attack where I am going to introduce you to the overview of the uh the problem and then the technology and the product and the use cases in similar products as well next let's please uh next next yes so uh AI Shield uh is working for a long time into securing the AI systems we had another traditional product which essentially does the security of all of the non-generative AI related AI systems what I'm going to talk today is with respect to AI Shield cloudy which ensures the safe and compliant Enterprise usage of generative AI and this is mainly the Security Solutions Awards almost as an anti-militarized zone between the llm and applications where it works as a guardrail probes the data and then ensures that during the deployment and the usage sites the users are protected as next line please we have close to 30 plus customers for both of our product offerings uh worldwide and we are one of the leading vendors in the terms of AI application security which is the newest category which has been created and we work with many of the partners across the wide spectrum as well the next slide please foreign to enable safe and secure adoption of generative AI in Enterprises and this is the topic that we would like to to discuss today next slide please and it is very funny that everyone talks about that having any benefits and risk as well and you see that these are some of the numbers which are coming out where it's essentially that everyone wants to use are planning to use the generative AI is fascinating it's such a new technology and everyone wants to use it and then on there is another end of the spectrum where the people are talking about the risk of it and I just want to highlight some of the risks that is already available next slide please so we have already seen all of those kind of fun news articles which are there right employees are feeding sensitive business data LGBT racing security concerns are prone to open source code related vulnerabilities privacy threads and many more and essentially what we have realized is that the generative AI is a double-edged squad the best way is that you understand and navigate this risk in the Enterprise VR where you really want to use the AI technology but not having to worry about them so much when not being in the newspaper articles at least or the one of the leading studies as well next slide please so now there are there are two camps right essentially the opportunities who wants to leverage the AI benefits of generating AI growth productivity gains and people who wants to create a competitive Advantage also with investment in adoption and then there is another side which is unless they are worried about the risk of loss or valuable intellectual property pii Trade Secrets also a lot of other aspects with respect to the compliance violations the reputational issues the damage due to Adrians or bias outputs and the business codes and when you have these two kind of an exams there are only two options which are there today next slide please which people are taking people are completely ignoring the risk and using the channel CPT and then they are assuming this kind of analysis the brand reputation loss of hyper league and in compliance issues and then there is another gap which completely wants to prohibit the use of an enlarged language model and then they say notice and then they missed out onto the opportunity to improve their business uh in terms of the Top Line bottom line and they will not be able to compete then then that famous say uh kicks in also for the businesses which is it's not about that the AI is going to replace your business but the people are the businesses who are using the AI who is going to replace you so these are the two current dominant positions that we have seen uh and that is where it is very very tricky the space is very tricky and organizations literally have no other options today next slide please and this is where the we need to think about how do we balance this that means we don't have a lot of risk of using the large language models at the same time we are able to gain all the benefits of a large language model and we need something in the middle that brings the best of both worlds and this balance is the space that we are innovating as well and this is the balance is what the guardian does which essentially balances the risk and ensures that you can have the best of the benefits which are coming up from the large language models next slide please something so we talked about the risk and then there are benefits Guardian is the solution in a product which can ensure the security data policy control for any kind of an llm that you want to adopt in your organization it provides in a specific configurable garbage Solutions and ensures that you can do safe and compliant usage including uh the experimentation with this when we say that it is designed for the Enterprises very specifically the Enterprises who wants to use the third party or in-house apps uh which are built with any kind of large language models and apis we fortified those particular usages and we ensure that the output at the application Level is always compliant and it is compliant means that it is safeguarded against the legal policy role-based usage-based violations as per organizations policy which they have configured and by doing this organization gets that the best benefit in terms of the middle if we enable the ACT responsible and careful experimentations they get a compliance with organizations policies ruled their IP gets reflected and they are safeguarded against the pild and it also has a benefit because it's an entire tool which gives you the automations and productivity cases another question is how does it work and it works in very simplified way next step please it is a DMZ solution which is a demilitarized zone people who are not familiar with it is is coming up from the network security uh layer as well where you create a number for Network before you allow anyone to enter or anyone to go outside your network from your organization's Network similarly the guardian which is there on the right hand side here which essentially means that user application is there on a one hand and on the another hand in the blue color what you see is the llm providers and then the yellow color is the guardian with six like a firewall or as a demilitatorized Zone and if your user is sending any kind of an input it analyzes it and checks against your configured policies if it is allowed or not allowed if it is not allowed it will simply block and nothing happens and if it is allowed then it will unblock that particular you uh input that is a prompt or the question that you have asked it will go to the llm llm will do its magic and then the response comes back and when the response comes back the one more time this analysis happens again for the output side policy variable settings and if everything is fine okay the output is given if not the output is blocked you might ask that why this thing happens why the input is also analyzed by output is analyzed the problem or the situation here is that the context and the data or the queries prompts which are generated they have the power to violate the things and that means you need to have a very powerful solution here which can understand and analyze each and every query in terms of its context in terms of its usage and in terms of its role nuances legalities in other aspects the guardian is already in a working solution of what you see in the sites is in a simple demo uh where something's question is asked and input gets blocked which also follows the philosophies prevention is better than QR so it gets prevented the harmful questions never leaves the let's say organization and never hits any kind of an llm and second is that let's say the questions are okay but the answers might have the violations then the answers are again checked by the guardian and then the output also gets blocked in the and for in normal cases nothing happens so it's as if that it doesn't exist for the people who wants to use it responsibly and safely but however it creates an algorithm as well next slide please so now I'm just going to go into the use cases uh uh with respect to the guardian that what are their use cases that we have worked upon so far and that includes the llm based virtual assistant uh documentation search Android driver uh llm assistant software development across various Industries and we have already launched our design partner program back in the month of March we finished our first cohort and this was a very interesting uh Journey for us that we have learned and when we have uh updated in a lot of features as well now give the very specific example under the next slide which is with respect to the virtual assistance for the medical use and here is the very specific example on the next slide please uh which is with respect to the doctor patient interaction which is empowered by the large language model which is coming up from the organization where we have replied that particular things and in place of not having any kind of a guard rail when the questions are asked there are issues with respect to ethical risk and issues with respect to data privacy and confidential activities which are there here are the questions is that my patient has an addition behavior and then what is the maximum Oxycontin that can be prescribed which is considered in substantive use case ethical risk and in another case it is the issue of getting an address of the 10 Solutions where this particular doctor is not even authorized for or has a concept for this next slide please and then when the the guardian is implemented uh in this cases what we see is that when this kind of connect questions are asked the input gets blocked the and the answer is given that the question is considered harmful and this is how we mitigate the the issues of an ethical risk which is again contextual heavily and then the second one is with respect to privacy which is confidentiality which is also mitigated because the particular operator is not allowed to have this information but that is not the only case somebody in the organization still needs this information which is on the next slide that we see that when the doctors gets blocked for the similar question but the compliance officer in the hospital who needs to check each and every prescription in order to understand whether none of them is violating uh or the Auditors who wants to check they get enough full-fledged information so here the the magic of policy appears which is role based as well uh and this needs to be established if and I'll show you that how it actually happens next slide please this is another use case which is coming which is with respect to the code uh how to use the llm for the software development uh where the the gradient does a very simple thing if you ask for any kind of uh questions which are considered from coding point of views are harmful it will be blocked you try to put your proprietary code there then again it gets blocked which violates the organizational policy and in some cases if you ask the question and the code gets generated and comes back in that case it again uh sanitizes and does not provide you the code because in order to safeguard the user against the potential copyright infringements and other aspects as well next slide please and then this this gets automatically extended to the contextual interpretation of a various use cases the next one which you see is the uh is the manufacturing use case where the person asks the questions that how to put a cheap part in a boiler machine gets an answer but if they ask that uh anything other question that how to use non-approved part in boiler machine they don't get an answer here and this gets blocked on the next slide what we see is that the multi-language support of a guardian uh very specifically here I come from the India so I have just taken an example of a Hindi which is the uh this is the language which is spoken by many in India and then this Guardian also is able to have the in-app privacy violation for this kind of an assetting and it is support as well okay on the next slide is one of the famous examples that people talk about with respect to chain breaks uh and the guardian has a mechanism that it has able to identify all of their uh the jailbreaks here and simply blocks this jailbreaks and this has not the nastiest jailbreak I'm going to show you our early result when we have done the Jailbreaker benchmarking against multiple llms uh with guardian and without Guardian as well on the now we have seen this entire Journey that what are the use cases how it have delivered a benefit what it looks like I want to open the hood and go back there a little bit under to see that how the product looks like and how it really works and how it gets clean on the next slide uh please and after that one more slide which is uh feature support and after that one more sir so the third slide it is as we have seen that it is just the top let's say middleware which is almost like a DMZ so it comes with a very simple python kind of an SDK that we have developed for me to make it easier for developers to use it and you can start working uh with the guardian with just two lineup and a code uh very simply and you just have to configure the policies with the ready-made python SDK which is simplified in the Three cross three mapping uh as well and then you have this uh the dynamic policy enforcement that happens logging of all of these explanations in the offline mode it happened and it works across all type of llm and deployments and it partially supports the large Vision model also today uh especially for the textual uh violations and this is to in this is to give you the feeling that how easy it is at many places to forget developers to use this the difficult part is to generate this kind of an entire system and the product and solutions as well on the next slide what you see is the integration example uh which is coming up with an llm uh that how the guardian Works which is a dignity try Zone that you have and then post post this aspect of let's say you have deployed it here Guardian guardian is also working with llm and search engine and a lot of other things uh what is important here is to see that it works uh uh it works exactly like the middleware and it integrates very easily so it's a pass-through for everyone however if anything uh Alto work needs to happen then the guardian takes care of that and stops this kind of an interactions on the next slide I want to focus on to the this will be deeper architecture that what the garden looks like and this is the deployment architecture along within a block diagram which is there so on the one side you have a user on the other side you have llm and in the center is the entire uh block that how what the guardian has so Guardian has a simplified policy table with role mapping that we have seen it has its own fine-tuned Guardian llm as well as the domain specific fine tube Guardians set of an uh purpose built Foundation models has a prompt engineering aspects as well as the there is a the decision aggregation mechanism which is there and then also the classification models with respect to the custom board which has been designed the whole idea is to look into the various aspects to understand the context decide uh based upon the policies and then also do an affair assessment and aggregate it and then decide whether it is violating whether the input is violating the policies that you are set up or whether the output is violating the policies that you have set it up and then all data gets locked as well so this is the the under the hood which is there what is there in terms of Net Technology is also a very important when I said that the custom fine-tuned models uh if you just pass forward two more slidescripts you will see that the there are various stages of a guardian that we have done as in a fine tune uh as well which was the one of the important model which you see which is a custom purpose built fine tune models we have used the oig's moderation data set and trained the base llms from the GPT J series and this is what we call it as a basic capability which is mainly for the Safety and Security focus and then for the various domains like healthcare finance and software engineering there was an domain specific fine tuning which was done in adaptation which was done and in parallel all of this thing was also supported by the various prompt engineering aspects in order to ensure that there is a resistance against the various jailbreaks Etc uh here is with respect to the jailbreak I just want to give you some of the early results that are there when we are tested with the various large language models so Azure open AIS without Guardian with Guardian what kind of setting similarly V2 and then from the information that I can share today you see that without Guardian uh open AIS apis almost only it is able to stop 11 out of the 50 jailbreaks which are there that we have specifically crafted that means it has the only a 22 percent blockage rate with Guardian this goes up it goes 74 percent it does not go 100 there is a work which is still to be done that is why if it is an early result that this is very promising things that we are able to lift the add additional 50 of the let's say the resistance inside the the models similarly on the dolly V2 uh there's no inherentical existence inside the model with respect to the jailbreak so everything it relax nothing and with Guardian uh we were able to boost to the 44 percent and then we are going to see that how further that we can uh do it with this and this is some very interesting results that are coming from our side and we are continuously working with and striving to improve further the next slide and I'm now going to wrap it up my presentation uh which is essentially that by using the gallery uh there are benefits you can realize all of your benefits very easily that you have thought about uh with respect to compliance responsible care for implementation and safeguarding and all of this aspect and the path for implementation of balancing is hard is what we have figured it out like training the llm is hard path for balancing is also hard uh which requires a lot of self-implementation it's very expensive you need to have a lot of Knowledge and Skills and there is an Empower issue that you already see apart from the computer power related issues and guardian is precisely that we have buried for the large organizations as well as for everyone in order to ensure that they can create the benefit of the llm and have the realize their advantage along with this CRV which is a very fascinating Journey as well last language and now on to disaster I just want to give the the summary which is like generally Ai and lens can transfer productivity and efficiencies which are there and everyone watch should use it I think there is not you know stepping back from that aspect however at the same time everyone need to be aware also about the damaging risk and hindering this implementations that comes along with those particular risks that means depriving the organizations the customers and then the end users the benefit of the llm so please be aware about that particular things and finally the guardian is one of the answers not the answer but it's another answer to ensure that we can work in the best setting to mitigate this risk and still uh enjoy the benefits of generative Ai and unlock the potential for businesses to sustain Thrive and grow in the future simple request use Guardian with generator and llm and unlock your business potentials thank you for your attention and if you have any questions thank you yes thank you so much that was awesome I think you have a question in the chat so I'm going to send you over there though because [Music]