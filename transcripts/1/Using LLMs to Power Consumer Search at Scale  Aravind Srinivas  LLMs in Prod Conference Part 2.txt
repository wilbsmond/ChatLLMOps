foreign [Music] people for this day of talks where you at Arvin there he is the CEO of perplexity AI so many people were so excited that you were giving a talk today man and I am one of them thank you you're welcome happy to be here to tell you all about perplexity cool man well I am going to hand it over to you no stress on the screen share we can see it's working now and you should be good yep good go so I'll be back in like 20 minutes 25 minutes all right uh can I get started yeah go for it okay great awesome um hello everyone um great to meet you all in this conference and uh I'm Arvin I'm the co-founder and CEO for black City uh perplexity is a conversational search engine uh that basically ends is the fastest way to get answers to any question and fastest way to like do all of your web browsing on the internet and uh we are four people co-founders myself Dennis yarrats he's formerly from meta Cora and Bing NYU Johnny ho like our uh he he was actually world number one at programming at one point and Andy from DW he he's one of the data bricks co-founders and also from UC Berkeley um so our mission is to be the world's most knowledge centered company um I think this is sort of borrowed from Amazon uh when Jeff Bezos says Amazon so Earth's most customer-centric company and like that's sort of what made them what it is right now customer Obsession and um our mission is to be obsessed with knowledge and productivity and we want to be the best conversational answer engine and provide the best surgical Pilots for you and um uh the place where people want to be when they want to discover and share knowledge and I think if we deliver on this we're going to give people back a lot of their time and make everyone smarter every day and I think that's good for the world and do it in a transparent way where truth is a first party characteristic of all the answers um in the form of citations so we are backed by great investors Nat uh Jeff Dean Bob muglia elad Andrea Yan um and so many more amjad Susan so like if for those of you who don't know about our product like you can ask any question like think like literally the deepest questions um if you didn't understand relativity you could ask about the theory of relativity and like ask it about the differences special special Theory and the general theory and how they've shaped your understanding like you know and before you can ask about uh demand and economics basically anything that you don't know about but you're curious about and you wish you had access to amazing knowledgeable friends um always available to you right so usually the smartest we have more you know like pretty busy like this happens when in college right when we are in college uh the best programmer is the one you kind of go to for putting a coding time and uh the problem with this with always going to them is like they're not always available they're probably gonna try to like do something on their own um and imagine you have the power of um having access to the best programmer the most knowledgeable person about economics the most natural person about physics uh all of them in like one service one search bar and always ready to answer any question that you may have and like dig deeper deeper deeper and like go bread first or step research about anything that's perplexity for you and uh you know I'm sure all of you would love to have such a friend always at your demand in your mobile phone anytime right so that's that's basically what we made it happen now and uh all of you are pretty familiar with like the auto GPT and search agents um you know like there's a lot of hype around it um but everyone's been asking for like a product that takes those ideas and like prioritizes it in a way that can be used reliably and that's sort of what we've done with our surgical pilot um put human agency at the premium of the product uh let humans control the search experience even though AI is at humans Mercy they kind of like doing it's in service pilot do you notice yeah it asks you clarifying questions after you analyzes the information it finds summarized answer it's a lot better than going Google technically finds the best flights hotels and must-see spots tailored just for you and the whole trip planning thing is customized perfectly suited to your or maybe you want to learn how to ski this winter let co-pilot take care of the research for you it delivers easy to understand steps and the highest rated instructional videos right at your fingertips co-pilot curates the best learning resources so you can focus on learning at your own pace share what you've discovered with others not only can they view the questions you've asked but they can also engage by liking them or even asking follow-up questions with co-pilot your discoveries transform into shareable knowledge perplexity ask anything this is a part of the motivation to let people Fork someone else's threat and ask follow-ups on top of that is sort of like we're all sort of prompt engineering right now like the whole uh and I mean you can consider this as the new kind of programming your programming in natural language and so um like it's sort of made programming a lot more fun and simple that uh you you know you you can take someone else's prom thread and you can learn from it and then you can ask follow-ups and learn more about it and you can share it with other people and so it's almost like building a GitHub of English um where expanding the knowledge capital of the planet by doing that and making it publicly available and sharing it a lot right and so that's the idea co-pilot it's awfully autonomous as you can see the llms will come back to you with clarifying questions and then the search queries initially that you ask are potentially highly ambiguous and have hyperplexity and then you can uh clarify and reduce the ambiguity and help improve the answers so in some sense you're guiding the llms to the right parts of the web and as I said you're putting human agency in the premium of the product it's sort of like a fundamental principle of our our products in general um and then we took a step further there and built a co-pilot that's personalized to you and we built something called the AI profile uh which we're pretty excited about and uh your interests your hobbies you name it next let's set your location and language preferences as you build your profile perplexity will present you with Dynamic clarifying questions these personalized prompts are designed to understand you better creating a useful conversation between you and AI just like that you've created a profile that's uniquely you and your search experience is now tailored to match all of this information is private and will only be used to make your interactions with the AI more useful and enjoyable you're in control of your information and can edit or delete it at any time perplexity AI profiles the power of AI personalized for you start shaping your perplexity experience today perplexity ask anything so here you're you're kind of prompt engineering for personalization this is very different from the way personalization has been done in the Web 2.0 era where um we we used to pick topics that are of interest to us and we used to pick um you know like domains that we want to see search results from and so on and that's just like a very primitive way to profile any person right so prompt engineering has sort of the future of how you want to personalize yourself for the AI in some senses like that for the AI to come and like sort of learn more about you just like how and and reduce the burden of future prompt engineering on your end like you don't have to keep repeating like you know what you want um we all don't want to keep on typing like code monkeys right when we use these chat bots so um so you kind of tell the AI what project web you're interested in like more about you and um and then like you you sort of like guide level them again to the right parts of the web by doing that and again like you put human agency in the premium product and uh so so amjad the founder of replit calls this presentation away prompting and then like people on our Discord are like talking about this how like you know they they're trying to get something to work um and then like a lot of the times what happens is perplexity is like if you don't give it enough instructions uh you get some undesirable Behavior like for example you ask a question in Dutch and you get the output in English and you don't want that uh so you don't want to append that as a suffix for every search uh query that you might have so if you just sort of give that as a global instruction and that's going to work for any question right so it's just pre-loaded as a prompt and uh I think this is gonna make our whole experience with all these AIS a lot better just like I said right you know we're all becoming programmers right now like um because we can all code in English um you know how python made a lot more developers on the planet um now we're all coding in English and so uh it's a little bit like sharing a template right you're you're like building these macros and then uh controlling these AI is to work for you um so that's kind of how you should feel about these so these are co-pilots that are in your service and you're like writing code for them and like uh in natural language and you can share uh and Fork from other people and um expand your own productivity and knowledge that way and also help other people expand it so uh it's good for the world to do that and uh we're also like doing things like tool use a word from Alpha where you know like we combined llms with scientific layers like gold frame that has a lot of people learn math and much faster way like I when I was you know in school it took me a little bit of time to wrap my head around like local Minima and Global minimum app and uh you know I I wish I had like this coming out and much better than like going to war from calculator using all the widgets that they have uh because natural language is a lot super easy you can ask a lot of follow-up questions that you've already asked before and uh and would like to switch rendering with integrals latex blocks it just makes the whole experience of like you know learning calculus or anything that's like you know advanced math or understanding planetary positions a lot more fun and uh this is just the beginning right like there's so many more tools to integrate with llms and so that brings us to like why do you want to use tools um and like Oreo when you asked the VP of research had deepmind he he he he gets this pretty correctly when we release like a Twitter search tool called bird sequel like back in December uh the end game is not to predict the next word at a time the uh the real end game is to connect llms with a lot of other tools like search engines python interpreters um and like Leverage the tools power and robustness and like basically harness the reasoning Power of Elements too and build something that was just impossible to build with just pure LMS and um I mean no need to say more like Sundar pichai the Google CEO comes and tweets of improvement of a Bard where um they they have like an implicit code interpreter on the back end and that helps them get 30 of the queries on word and math problems better and um so this is why you got to use tools like llms are great reasoning engines Wolfram and databases and search indexes are sort of like knowledge engines or knowledge bases knowledge graphs and Magic happens when you combine the two together and in some sense like leave aside even Wolfram the basic perplexity product itself is the probably the most functional and well-executed version of like retrieval augmented generation or people refer to it as rag where you combine the LOL with the search index and then make sure that it can always be updated with the live information there's no knowledge cut off but it also retains the conversational and reasoning and referential natural language capabilities of the llm the knowledge that's already in the parameters of the llm but can plug into all these like indexes and databases and tools and so on and like create magical experiences for Learning and knowledge and research for you and uh this is just the beginning there's a lot more to do API use um nx1 so I'm pretty excited about like tool use and uh so that brings into like you know when you're using a bunch of tools you're almost like you're you're playing an orchestra now right so so that's that that's kind of yeah I'm gonna call it like orchestration um where we are orchestrating an llm to use many tools together in order to achieve like um amazing things that would just have been impossible to achieve without um the tools and just sell them alone and um so so what what is what are the challenges in orchestration like your your latency is like pretty high uh if you're gonna use many tools together and the llms also and like your your problems are going to get a lot bigger and so on so in the beginning we when we first wrote out our product we are our product had like five to six second latency per query and in fact like one of our investor friends uh Dan Daniel gross he used to test the product at the beginning and he even joked saying like you you guys should not call it submit a query but you should call it submit a job like it's it's that slow like it used to take six to seven seconds and now it's like incredibly fast like uh the first thing anybody comes and tells me about perplexity is like how do you guys make it so fast and I think that's the part of like doing end-to-end engineering um when you're controlling all parts of the stack yourself you can make it really really fast so as a company we we do not use these high level uh tool libraries like um or Lang chain or dust we don't make use of all these things uh we just do the whole engineering ourselves and I I kind of recommend that for anybody or anybody else like uh there's just so many uh latency optimizations you'll miss out on um if you rely on these uh tooling libraries and then um hallucinations so when you're using many tools uh there are so many ways in which it can fail when you're chaining things together um you know that's all this joke of how like many pieces together um that you if just one part has to go wrong and everything breaks so uh we can only fix this by learning from Human feedback a lot of prompt engineering updates good discipline on prompt version controlling um benchmarking for AI quality benchmarking for model quality and things like that uh and like prom migrations when you're trying to migrate from one model to another there's all sorts of engineering challenges there and uh Integrations like so when you're when you're when you're doing orchestration you're like trying to like integrate with existing tools like search indexes Wolfram uh rendering libraries um trying to like make sure that the image rendering works well um database plugins and so on right so all that's like a lot of Challenge and I think um that's sort of why you know like building a product is not just an llm wrapper uh many people think of us as an llm rapper and um that's fair use the term because you know like we we rely a lot on opening eyes models um but training your own model is just one part of the whole thing like like building a product like ours has so much so many layers of software uh engineering and llm orchestration work to be done there that um we we shouldn't be called an llm wrapper company so for example here uh you look at the screenshot uh there's this question about the Reddit CEO pushing against the blackout Reddit and the bottom you look at the related questions uh which are which is actually one of the most favorite features of like our users is they don't even have to type in the follow-ups they can just click on it and it automatically contextualizes it in the the context of the previous query and gives you a good follow-up answer and how do we generate these follow-up questions so that's another llm that's doing the job and then that's another llm that we would train ourselves um and and similarly like every query needs to be classified whether what type of query it is so that's another llm and then um every query needs to be reformulated into a bunch of other uh sub queries here like for example in this query I'm asking please explain to me the paper augmenting language models with long-term memory uh this is a question that you know if some of that doesn't know much about uh llm so they're trying to read about papers uh they would ask these questions right and then uh that gets reformulated into like three or four follow-up queries and and then a search runs for all these follow-up queries and pulls up all these results like and then uh the co-pilot looks at like 16 results which would not have been possible with just like one single query right um so that expands the diversity of pages of the co-pilot sees um and creates a very high recall content for the llm now that pulls up the highest order bits in the summary and all these like our uh things of the query formulation query categorization uh follow-up query suggestions and like um needs like separate llms then you need to orchestrate the whole thing um into like one single piece uh that's that's sort of managing all of these workers right so so that's like a separate layer of software engineering to be done there or or like AI engineering you may call it that way and uh this kind of sort of reminds me of this you know Steve Jobs movie uh I don't know if many of you have seen this from 2015 um I think um they're like many Steve Jobs movies but this is like a pretty good one where uh there's a scene here where Wozniak comes and asked like you know I'm the guy who can write all the code and like I I write all the nuts and bols uh like you don't do it like what do you do and then uh Stephen says I I play the orchestra right and then so that's really what's going on here like we don't train our models at least not all the the major heavy lifting is still done with openai but like then what do we do um and the answer is we play the orchestra so we orchestrate the whole thing together into one functional working piece that just works seamlessly reliably at scale for like tens of hundreds of thousands of users every minute and that's really hard and uh and sort of like that's the major takeaway I feel like you should take away from stock is like elements it's not just about creating the model but also like building the whole orchestration suit around it and doing this really well like is sort of got a lot of organic traction like Jack Dorsey and our Friedman have all three great things about us and uh New York Times Fortune uh has covered Us in this like code red articles and uh you know like Fast Company fortune and so on Bloomberg uh you can obviously even if you don't want to stop using Google you can just use this as a Chrome extension uh pin it to your Chrome and then just click on it and ask any question that you otherwise would have asked Google and kind of like put stuff with their ads um you can you you can stop using Wikipedia like Wikipedia is like one uh Frozen fixed version for all the internet we don't need that like knowledge should be personalized and like consumption should be personalized at whatever levels of granularity you want to go dig deep into any topic so uh perplexity is sort of like a rabbit hole for people who used to earlier enjoy like Wikipedia rabbit holes perplexities of black hole in that case uh said by a LinkedIn user and um and there's a sort of like what what motivates us like a lot of people in our company are kind of nerds and like you know we we want to build a nerds Paradise uh for like those who want to come and enjoy and learning more um it's a different ethos for the company compared to like um you know the traditional social media platforms that I've always tried to optimize for the the average person enjoying like entertainment on the internet um for us like knowledge is entertainment and then you know like Cora used to try to do that uh the difference between core on perplexity is you don't have to wait for Jimmy Wales or like some knowledgeable person to come and answer your question uh after like two three days you get the answer in a few seconds equal quality and any number of questions and like that's the power of like basically you're experiencing the power of the smartest humans on the planet on steroids and like that's pretty amazing you know from for your own like you know knowledge of grades and productivity and we're also available on on iOS like you can go to the App Store and use it on your phone uh for people who feel a lot of friction when they're on their phones going to Chrome and opening a separate tab so that's another you know useful too we're built and we intend to keep building better mobile experiences and uh we every all this is only possible because we we have a great engineering team um and uh I'm super thankful to be working with them um you know one thing that everybody asked me is how do we execute so much with just so few people and uh it's because these people are so awesome um and uh it's also we we want to be proof to the world that um you can do a lot with less in fact you can probably only do a lot with less and that's my belief like if we scaled up today to like um 50 people will be a lot slower and so um I'm very proud of working with all of them and um they're all very highly responsible for all the success we've had and we are hiring for many positions including a research engineer um so like please you know apply on this link or reach out to me directly or any of us directly and uh we recently announced our Pro uh subscription plan that gives you like a lot of co-pilot uses per day and GPT 4 users per day and uh you know we're actively shipping new features so you're going to get all of them for free uh if you get it now and uh I highly recommend you check it out and that's that's it from me I'm here to take any questions awesome man there are some incredible questions coming through the chat and I will say that I love the energy that these people are saying in the chat first one that gave me a little chuckle is from delone and the loan reached out to me for this funny one I don't think it was serious but I might as well ask it to you can I ask perplexity how perplexity speeds up tool calls uh so so perplexity only takes the information from the internet right like we haven't made that public yet so um I guess you can't but I mean you can you can definitely ask but you might not get a great answer okay there so I mean along that theme there are being able to ask anything to do a chat bot or to perplexity it just has a lot of complications I would imagine with hallucinations and not knowing the catastrophic forgetting that they say and all that stuff that happens behind the scenes that we've been talking about for the past two days how do you all deal with that to make sure that what you output is quality so the question is how do we ensure quality in the answers yeah yeah so we run a lot of evals and you know we have this amazing 14 year old intern who came and set up like AI evals for us and so anytime we change the prompts or anytime we change the search index um we run it through all these rigorous evals and then Benchmark it and uh we are big dog photos of our own product like you know that's necessary when you're when you're building a search product like I don't use Google anymore um even even if something is not working well with our our thing I kind of go through and try to like flag it and dig deeper into why it's not working so that helps a lot and you might be surprised like many anecdotal um complaints from people uh teach us a lot about like how to fix some things and then that ends up fixing a lot of things so um I would just say like I mean it's kind of like a joke but um it's tested on production and then see how it goes that's all that's what we're going with that should be a shirt tested in production and you'll be good so that's awesome I love that uh Willem is asking a question any recommendations and I love how you were talking about you're the orchestrator and you you make the symphony make that beautiful music so along those lines willem's asking any recommendation on how to choose the correct foundational model based on the question step in the orchestration process so so right now I feel like I mean all this should be desired based on evals um and right now the evals indicate 3.5 turbo or four are like just insanely good um I think anything to do with reasoning and logic you would go for um I think for most summarization tasks or irregular language pre-processing tasks you go with 3.5 Claude instant is also pretty good compared to 3.5 but not on coding and uh so that's sort of my mental roadmap right now and I don't think the other models on the market are there the leagues of GPT and Claude so I would kind of stick to these two for now and so you're not doing anything with smaller we do use like small mods like MPT fine tuning and yeah um there are some other models on the market and like Falcon is out and we are testing it but I think it's going to be a gonna take a while to match the capability and the speed of these proprietary models and uh so I would kind of stick to it for now before before like trying to be adventurous here yeah yeah yeah makes makes total sense so uh I think we kind of answered that one as far as like this so Nathaniel's asking hey this seems like a cooler or not asking but just saying more this seems like a similar but cooler idea to the new Microsoft Windows copilot they're looking to release in addition to Bing and uh oh so do you have anything that you can tell us on the technology stack that perplexities building I mean you said open AI you said Claude what about other stuff what other stuff are you using I mean we don't use anything else like um I guess we yeah we we use um kubernetes and all you know all that react next JS um and uh you know I iOS is in Swift UI and Android is in Native so I think that's kind of like I don't I don't know if that's really informative but uh it's it's all like a lot of work on back end that keeps the product working as well it does now and um so I'm not sure what the question was specifically aimed at but I would imagine it's it's probably around the machine learning engineering life cycle like yeah if you're doing anything with um if you're using any kind of guard rails or if you're using any Vector database to augment yeah okay okay got it got it yeah but you do use Vector databases and so we use elastic we I mean that's not a vector DB but we use elastic and also um quadrant and we haven't ventured into Pine clone or vv8 yet but so we've stuck with quadrant and um embeddings I think we don't use openai we we train our own embeddings now that that's turned out to be pretty good for us I don't think they have the market lead on embeddings as they have for llms I think that's basically it um so here's here's an interesting one which is actually it gets a little bit ethical in a way shiv is asking do you think that a villager in India can use perplexity for their medical needs and then they don't have to access doctors uh so the way I think about it is like from I mean I don't I don't think it matters whether it's India or America or something um like I I use it for medical queries for my own body like um like I recently I was on a trip and I you know I was trying to do a hike in a cave and then I hit myself on the wall of the cave and started bleeding a little bit and then I I was I was freaking out and I needed to know very urgently before going to the uh Medical Center that was nearby it was like 30 45 minute drive from there I had to know something right I was freaking out and so um I asked perplexity and like it gave me all the detailed explanation of what it means for my symptoms and uh so I would say that immediate first few minutes of like pandemonium you have like we can really help but um you would ideally consult a practitioner and make sure it's perfect just don't go blind faith of like what perplexity is saying and like don't you know like just act on it but those few moments of panic you can definitely like rely on us um you know it might be the negative way too like it might raise alarm bells in case you might really need to take action and like go and take action so I'm happy with the way I'm using it and I think the same I would apply to the Villager in India too um and we support other languages that they can ask in their native language so I hope they use it I think it'll be great so the um anyone who has Googled uh what their symptoms mean no that is the fastest way to get very depressed very very bad I definitely have had that happen to me before I have a stomachache and next thing you know it must be an ulcer or it must be stomach cancer or whatever and so so hopefully perplexity doesn't go down that Rabbit Hole uh it doesn't because you you can be more precise you can just say hey this is what it is and like what can I do like you know pretty actionably and so yeah yeah it's it's a better option also like it depends on how how obsessed people are about their health and so on like for example some people are like they get a rash on their skin and they're like so scared it's like something blue skin cancer and some people like yeah whatever it's just gonna be fine in a few days I'm more of the second kind but so uh Goku is asking about latency and yeah you're saying uh curious if perplexity is taking a toll on computational costs since I believe a lot is happening in parallel and results might just be thrown away based on some other signal yeah yeah we do do a lot of things in parallel and and uh so the question is like sorry I I don't quite get the question but um is it is perplexity taking a toll on computational cost um I think it's kind of fine like we the major computational cost was actually the llm more than the search index and once you've built a good Vector DP things are actually pretty fast and you can do a lot of things in parallel and the embedding dimensions of the vector DBS are not that big that you know you you could keep all the CPUs also fine yes that's awesome well dude this has been incredible I am super thankful that you were able to come on here in the chat yeah thank you thank you for having me yeah and show us about perplexity I'm gonna start using it I want to start playing around with it more and I uh I also know there's a ton of people that are asking questions in the chat so if you get a minute I'll drop the link to the chat and then you can answer the other questions that are coming through there and thank you so much Armand thank you I'll talk to you later man team [Music]