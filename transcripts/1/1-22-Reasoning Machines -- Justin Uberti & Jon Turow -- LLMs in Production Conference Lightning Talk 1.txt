good morning well hi folks here's going to uh Justin Bieber really really excited to talk about reasoning machines and how you can build citing and useful and differentiated apps with llms by thinking through the the stack how you can do that from an ml Ops perspective so next page please Justin and one more please as I mentioned I'm John turo I'm a partner with Madrona Venture group or early stage investors and Ai and data I previously spent a long time at Amazon AWS and I'm Justin Liberty a co-founder and CTO of fixie a platform for building interactive applications with large nineless models before starting fixi I worked at Google for a long time and have been around the internet industry at Fairmount John next page please so you know so much excitement about building apps with llms and it's Justified your apps can be super powerful they can do things that if you think about it right maybe you've uh maybe no one's ever seen before but you know when you talk to Founders and and anyone who wants to build apps on top of the group on top of the stack that this community operates there's going to be a real question how can I build a differentiated app that's going to be different from what everyone else can build on top of the same models we're going to talk about that today next page please Justin to do that let's just talk about exactly what llms are we'll take a step back to ancient history some six months ago with to a paper from Stanford about emerging capabilities you know these these large language models made it possible to take so much data and so much compute that all of a sudden AIS can reason they can do complex reasoning with multiple steps they can reason outside the domain they were trained on they could they can do new tasks like generalization and summarization okay that's what these models are at their core and if you go to the next page that lets us draw a link that for all the facts in these models even though they they know things like who is the president of the United States the best way to use llms is as reasoning machines not fact machines but wait a second if we want to build great apps we need both facts and reasons and reasoning we need to put those two things together otherwise it's you know this guy John lamb uh who's thought a lot about these topics has said on Twitter that asking an llm to do something without the data that it really needs of course it's going to hallucinate that's just like leaving a person in an empty room with no tools he's going to hallucinate to so what we're going to talk about here is how you can use the stack to actually inject the Right facts into your model to make more useful and differentiated apps okay next page please Justin we're going to talk really briefly about three different ways to get facts into your model and then we're going to dive into one specifically the first and the most famous is to train your model itself and and this is you know if we're starting from a model from scratch this is what everybody would have had to do but in the world of models that are so sophisticated and so uh and increasing their capabilities at such a rapid Pace the reasons to do this now are because you want to push the technical envelope or you want to restrict you want to respect structures or concepts in your model that are so radically different from what other models are capable of um and so you know this is for very sophisticated very sophisticated use cases and teams the next thing that we talk about all the time is fine-tuning where you can actually take an existing model off the shelf and do editing of the model of the model ways and that allows these the existing model to become more familiar with your data and depending on how much data you have you can be more surgical or more profound to the impact you have 50 to 50 000 rows two thousand to two million tokens which brings me brings me to the third technique that we'll spend the most time talking about today in prompt engineering and with prompt engineering you really don't actually interact with the guts of the model at all instead you use the stack to inject information on demand into the prompt of the model along with the whatever is the ad hoc input from the user you retrieve data on demand from whatever data store or API you'd like to use and when you do prompt engineering for data that lets you have Dynamic control over model output it lets you reason about specific facts that you can rely on not being hallucinated or sort of confidently wrong and you can do this on top of any llm that you might like to use so we're going to spend the rest of this lightning talk talking about prompt engineering and show some examples of how you can use the stack to inject data into your models in real time on demand on the Fly and build more useful and differentiated apps take it away Justin all right thanks John for that lead up so we're going to talk about as John said you know how can you use prompt engineering to use an existing model but then differentiate your application by allowing it to connect to existing data sources and apis and you know I'm not the idea of you know differentiating your application especially when using an LM because then you can differentiate while you differentiate right so let's Dive In so I'm gonna do some demos here and what we got was going to talk about um you know how exactly prompt engineering works and how do we actually do this process of connecting llms uh to to existing data sources so as John mentioned you know LMS have a lot of facts that they've been trained on and you know those facts you know some of them are readily accessible to the LM because they don't change they're kind of static uh they're well known it's unlikely to be it'll lead to a hallucination but you know Justin I can only see the uh the right hand of your window oh okay the text at the left let's see if I can resize the window here great okay so back to prompt engineering yes so with primary engineering we're going to define a format for queries and responses and then ask the element the reason about that provided query and so some queries are pretty simple and work pretty well like if we ask who the president is Elon has seen this in its training data and it's able to answer this question accurately and authoritatively but if we take some other queries that aren't encoded in the llm's knowledge like for example a dynamic query like what time is it the LM is going to struggle here and give us like basically a random a random answer uh it looks plausible you know like it's the right format for the answer but it's the wrong fact in some of these things you know this is where we can really get into trouble is that it's not always totally obvious when the LM is making something up if we ask a more in-depth question like who the speakers of this conference are from VC firms well we get a lot of like really reasonable answers I think these are all my actual uh VC firms and probably actually people but poor John gets snubbed here and not even being mentioned in the results and it's just like how would the Alum know as John sorter mentioned it's just a person locked in a room it has no ability to understand anything that's outside it's training set so to address this we can use prompt engineering to supply factual information to the llm and then the LM can then use the information we Supply to generalize using its Rich World model that is built up so here you say you're in Seattle and we say here's what time it currently is and now I asked it what time is it well it's no real surprise that if we just hold of something you can repeat that fact back to us but the part that's really interesting then is we say okay you know we've asked what time is it in Seattle but now if we ask what time is it in New York City wow okay is generalized to understand that well New York City is somewhere else in Seattle it's in a different time zone it's an Eastern Daylight time that's three hours away from where Seattle is so therefore if it's 9 10 in Seattle it must be 12 10 in New York so that's a pretty powerful concept where we haven't really asked the LM to give us a fact we've given it the facts but we're asking the LM for its knowledge of reasoning based on the world model so mainly supplying the information like this it doesn't scale but we can give the element tools to retrieve necessary data from data stores and so I'm going to do another demo where we point the uh unlimited web page and ask it to read the web page and think about it before responding and so the question that I had before I asked the LM who's speaking at the conference from a VC firm well now the llm can go and read the document which is basically the web page for the from the conference site look through that convert it to a form that Ellen can understand figure out who are speakers uh you know at the conference and then use this world model of like what is a VC firm and you know which of these names are BC firms to know that oh John from a drone is speaking and we've also got Diego from Factory and speaking at the conference as well so you know this is a pretty powerful example of how we can actually use external data to make the and the recently power bill around to come up with pretty interesting answers to complicated questions so we'll do one more demo here that uh we can take this even a step further of coming up with a um a general set of tools that an llm can use where anytime it knows that it's being asked for information that it doesn't have in its existing World model it can go and consult those tools to get the information that's necessary to answer the query authoritatively factually without hallucination and so in this particular example we have here we're asking the this tool this is fixie here uh to go and find out who are the contributors to the Transformers repo on GitHub find out their contribution counts and then plot them as a bar graph using an external chart API and so we've got a bunch of different pieces involved here where we've asked it to find out information about uh you know GitHub it knows it needs to go consult GitHub get this information and then bring that information back in a format that can be given to an external API that's capable of doing charted and so we're cranking away here and uh let's see where we end up all right so we've got the information of the commit counts it's now going Consulting the API for building a chart and boom that's a lot of code being cranked out by a lot of great llm engineers so I hope this all gives a good picture of how we can connect apis and data sources to allow differentiation of like your llm based app and just sort of to sum up I can remember how to actually uh make this Tool Work you see it now just yeah okay perfect so summing up you know LM should be used as reasoning engines not fact-based engines you know but we can basically build differentiate applications by using that reasoning engine and connecting it with external data we can you know train models we can fine-tune models and we can prompt engineer and there's good reasons for each one of those things that we might do but prompt engineering is the most flexible and programmable way for us to go and extend and differentiate applications because it works with existing LMS it works with existing data sources and apis and it's you know something that is available just through straight up you know writing software rather than having to go and do a lot of you know training step so uh we're pretty excited about you know the opportunities that are available here and uh we're looking forward to answering your questions thank you foreign