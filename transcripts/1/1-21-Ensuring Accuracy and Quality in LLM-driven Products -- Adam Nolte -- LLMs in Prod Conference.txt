hey everybody I'm super excited to talk to you all today about ensuring accuracy and quality and llm driven products I'm going to walk through a couple examples of how you might use llms in your products a more simple example as well as a more advanced one and hopefully leave you with some questions and thoughts on how you might be able that you can bring into your your own products a quick introduction on myself so I'm the CCO and co-founder at Autobox we're building debugging and monitoring tools for companies that are building llm-driven products before autoblocks I was a software engineering consultant at Westwind row and also spent time on the engineering teams at project 44 in front both platforms dealing with large amounts of unstructured data so we'll kick things off by just defining what is an llm driven product so of course I went to chat gbt gpt4 manasse and said an llm-driven product refers to a product or service that is powered or significantly enhanced by a large language model like gpt4 of course from openai large language models are artificial Advanced artificial intelligence systems that excel at understanding and generating human-like text based on the context and input provided which makes sense and I'm sure you're all really familiar with and it also gave a handful of examples like virtual assistants content generation translation sentiment analysis text summarization coding customer support Educational Tools I'm sure you're all familiar with a lot of a lot of text space I mean there's more and more use cases emerging as well and behind the scenes you'll actually look at an example of of one of those and you've probably seen some across all of the talks today a lot of folks are really thinking about where do we Where Do We Go From Here past just the regular text box so first what we'll look at is a product support chat bot so a simple question and answer you probably have this hosted people can come in ask questions they'll look over your knowledge base and help your users out and also save save time for your support folks so someone comes in they say how do I set up a workflow chat buses I'm sorry workflows not a feature that we support they asked how did I do so very simple you've probably seen this a thousand times thumbs up thumbs down you know give me feedback this is really the basic way of incorporating feedback you know whenever users do thumbs down you can start to look at similarities on those inputs when they are having negative interactions and you know start to dig in and understand how you might be able to improve thumbs up you know you can start to use our like chef and reinforce um and go from there but you know a lot of times especially if you're like myself sometimes you may not even use a thumbs up thumbs down so it can be pretty basic and not always super reliable so we'll come back to this example towards the end and think a little bit about how we might be able to improve um the quality here and incorporating feedback next we'll jump into an example where you might have a large language model working behind the scenes and it's not going to be so obvious to the end user so in this example we're a ticketing software Think Like A jira or a linear that you're all familiar with in this example we probably have and say we've added a bunch of AI capabilities so our AI can help us auto-complete the title and description as we type it out it can also Auto assign so here you can see if this is assigned to Wade so it can use what you've typed in the description and title and then look at all the historical context and pick the right assignee for you so you don't even have to think about it it could also add a label for you in this example here you can see that it's labeled as engineering so it can take a look use all this context historical context Auto label for you Auto label for you and really just make you more efficient because it's always a pain trying to figure out what you need to label all your tickets as and keeping everything organized then last which is really cool it can also assign a due date for you so it knows how long it usually takes way to work on these kind of features and it can suggest a due date of next week for you and so what we want to do you know we've added all these features in and we want to really understand like how well are they performing how can we improve them how can we get better well if we take the chat example we would just paste a bunch of thumbs up thumbs down everywhere which obviously is ridiculous and would lead to a pretty poor user experience we wouldn't want to do this and I mean it wouldn't you know frankly it would be really difficult to understand like okay the thumbs up thumbs down different parts like how that work so obviously we need to think a little bit about how we might how can we understand and improve in these examples another way would be maybe just one thumbs up thumbs down with a user can input feedback directly but then you have to manually go through and read and look at all this feedback yourself and it's not going to be super insightful so we really need to start thinking about is kind of back to more product analytics type questions so we need to ask ourselves you know what what questions um so what do we really want to know we want to know did they update the title or the description after we did an autocomplete if so what did they update to is it close to what we provided is it very different um you know those are all really important questions that we need to understand for the assignee we need to understand did they update the assignee did they update it to who did the person they updated it to actually end up working on it or maybe a week later it got switched back you know if we started retraining our large language model and all the context based on who they updated in the moment we may actually you know update it incorrectly if it's always going back to wait maybe later on and there's some other user training we might need to do same thing with engineering with the label so do they update the label if so is a new label similar maybe there's too many similar labels and we can actually assist the user in using our product better and consolidating their labels you know if we start asking these kind of questions you know even when they do update it we can start to provide a really a better user experience and also improve the quality of our models the same with the due date you know how much do they update it by how accurate was the due date uh maybe they updated it and then our original due date actually was correct um and so we don't want to take into account that they changed it uh we want to actually just know when it moved to the done state was our original due date correct so these are all like questions we should be asking and start thinking about as we're building these LM driven products if we Circle back to that chat example that I showed early on what we actually really want to know is that they actually solved their issue um do we actually not support workflows maybe that was a hallucination what did the user do next you know think with me for example if I came in here I said how do I set up a workflow and the chatbot spit out a list of steps and if you're actually able to measure in our product did the user complete those steps like we intended and was that a successful experience for the user that's going to give us way more information than just a thumbs up thumbs down which brings me to to truly ensure accuracy and quality in your llm-driven products you need to understand human behavior beyond the thumbs up thumbs down so how do you do this well like I said before you need to sit and think deeply about the failure modes that can occur in your product what's most likely to cause a negative user experience what are the positive outcomes and once you have all this information you can add to a link to like measure those human outcomes and how users are using it then use that to optimize your ammo AI models so you end up in this feedback loop of presenting the AI features to the user collecting analytics and continuing to optimize and you want to make this feedback loop as tight as possible um so Autobox we're here to help so you can sign up for a private beta at our website here um we're thinking deeply about these problems and how we can help you understand the entire user journey through your app and then incorporate that back into your AI Futures and optimization and things like that so we'd love to chat with you if you're building llm driven products or even just thinking about it like I mentioned feel free to sign up for our private beta at our website or shoot me an email directly I'd love to chat so really appreciate all your time today and I look forward to chatting awesome thank you so much Adam I think that was like the best timed presentation I'm glad to hear I practiced it a few times with a timer uh so I was pretty I'm glad it ended up working out also on the right time that was great all right well thank you so much for joining us today we really really appreciate it yeah I think silly [Music]