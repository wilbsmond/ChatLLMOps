okay great well let's get started we have about uh only 10 minutes here so um I'm gonna try to hit the high points uh so this talk today is entitled Slim Fast unleashing speech intelligence through domain-specific language models my name is Andrew uh VP of research at Deep gram I would be remiss if I don't first tell you a little bit about deep gram where uh Speech to Text startup or mid-stage founded in 2015 where a series B company 85 million uh total dollars raised so far so far um so we have uh what what we believe to be the best you know most accurate and fastest speech to text API on the market um so far in deep Graham's existence we've processed over one trillion uh minutes of uh of audio we have a lot of customers who we have delighted and uh so I'm going to tell you about some things that are that we're working on and we're interested in today so some of the things that that motivate us uh here's some of our fundamental beliefs the first one is that uh language is the universal interface to AI so we believe that language is the primary way that uh we interact and carries the most amount of information and will be the universal interface that will unlock the full potential of AI and that is starting to happen now um so businesses are going to be able to realize the power of language AI but we think that businesses need adapted AI to make it useful so if I'm going to start off here by first making some predictions related to language AI over the next two years many businesses will start to derive tremendous value from language AI products and in the short term the most impactful products that people are going to build are going to combine existing Technologies in a multi-model pipeline so what does that mean well this pipeline is going to have three stages in it there's going to be a perception layer which is going to be fundamentally ASR something that takes audio and turns it into text so speech recognition system probably complemented by A diarization system that predicts from that audio who is speaking when and allows you to format that transcript in a nice way to separate out the speaker turns there's going to be an understanding layer that will take the output of that transcript and apply probably a large language model or perhaps a medium-sized language model or a small language model some kind of language model that will understand what's said in that transcript and will produce some kind of distilled useful output like a summarization of the transcript or a detection of the topics or the sentiment finally you'll have an interaction layer which will take say the output of an llm which is generating say a response to the uh to the audio input and then we'll make that we'll turn that into audio using say text to speech right so we have this language AI model pipeline so we think that businesses are going to derive maximum benefit from language AI products that are cost effective reliable and accurate those three things together you need all three um and this the purpose of this talk is to argue that this is going to require the use of uh small fast domain specific language models as opposed to large foundational language models right so that's my thesis we're going to argue this point in the context of a specific application call centers so what is a call center well it's a centralized officer facility used by companies to handle very large volumes of income incoming and outgoing telephone calls call centers are staffed with agents who are trained specifically to handle the customer inquiries that will be coming in the complaints that might be coming in and they're trained to provide technical support or sales or perform sales related tasks and their training will be specific to the business that this call center is supporting so there's a number of uh AI products that are going to be built for the call center some of them are already being built and you know in their initial stages um these will be products that will help both the customer experience on the left to the employee experience like the agent on the right a couple of important ones would be voice Bots or real-time agent assist systems other importance would be important ones would be audio intelligence features so basically taking the output of many phone calls and summarizing them or predicting the topics for them or predicting the sentiment of the customer in those calls so you might say why not use a prompted foundational language model large language model to build language AI products for a call center the first reason I would argue against this is the scale of large language models they're ridiculous 100 billion plus parameters if you measure it in terms of how much resources it would require higher to launch this model with uh with a 5000 gpus it would require dozens of them they're very small or they're very slow uh inferencing on the order of you know 100 milliseconds per token so you know along generating a long response might take many seconds so just based on the scale and the inefficiency alone you could argue against it um looking a little bit more in detail at large language models and what they can do they have broad general knowledge um and they can be aligned to do many tasks without explicit training they do many many things however conversational text generated by a call center has a high degree of specificity it covers narrowly distributed topics the People speaking have unique speech patterns associated with where they are in the world and there's going to be a long tale of rare words that the foundational language model probably has never seen before to get an idea of the task specificity that's involved we could look at say the top 15 tasks that a call center agent would perform they're very highly specific and yet complex tasks that require language understanding another point we can make is that domain-specific conversational text is generally out of distribution for foundational llms we can get an idea of this by asking chat GPT to continue a call center conversation so if we give it a a brief prompt right with an intro by an agent and then we have a customer who's starting to speak and we look at the transcript that gets generated we see that uh it's very unrealistic the speech is way too clean as if it were written and that output tends to follow a predictable script of a greeting customer describes an issue agent takes an action customer accepts the action and the call ends very unrealistic if we look at real examples we see that they feature things like crosstalk people trying to talk over each other makes transcripts very difficult to read and interpret it uh real transcripts have things like disfluencies where people are basically stuttering and stumbling while they're speaking using filler words that also makes transcripts hard to read so we argue that we should shoot for domain adapted language models for call centers and that these models can be small um to prove this point we took a small language model 500 million parameters and that was trained on general internet data and then we transfer learned it on uh an in-domain data set of call center transcripts we found that the model improved dramatically in all metrics uh next token prediction loss and perplexity and when we use it we find that we can continue a call center conversation a prompted call center conversation and it generates very realistic text and then we have gone further and used that to train a summarization model which I'll demo to you now in this Jupiter notebook so we're going to make three calls here we're going to first make a call that uh so we're going to call a function that hits the Deep gram API um transcribes an audio a phone call Audio diarizes the transcript and then sends the transcript to it to our slm to perform summarization you see that that call took 8.4 seconds we're going to print the transcript that we got back from ASR and diarized we see that it's highly accurate and we're going to print the summary that we got back and we see a very nice human readable summary that uh is actually quite accurate describing what happened in this call and that's what I have for you folks today