all right so excited to introduce our next guest will Rojas from co-active AI hey Will how's it going hey King uh is the audio okay yep you look you're a little fuzzy but your audio is great okay okay awesome all right let me down before we start I think you're good all right here are your slides looking forward to the talk awesome thanks Lily so oh is it good yeah yeah I took you away by accident which was not oh all right so all good awesome okay it looks good for mine so hey everyone uh so uh just want to introduce myself my name is one of the co-founders of proactive AI today I want to talk to you about essentially bringing structure to unstructured data and really what this talk is about is some of the lessons that we learned in designing an AI first system so I think part of the reason why we're all today is that really the nature of data is changing right go back in time about 10 years ago right the way we thought about data was mostly from the tablet perspective right on the table a row in this case chicken G is one of my favorite restaurants so you know hey I'm gonna give it five stars right that's kind of what we were thinking about uh sort of around the Big Data movement but today unstructured data dominates a lot of data that we see right I'm really moving away from data to content such as a rich text description or a rich visual image of the actual delicious chicken sandwich that uh you know I love to go to and so this kind of goes back to uh Bill Gates's sport of 1996 of around content being King and really that his main takeaway was that those are actually controller content are going to be the real winners in the internet Revolution and if content is a king well not like you said the king's already here right so 80 of worldwide data is actually expected to be on structure by 2025. nearly 80 of people say that a lot of this instructor used to generate a Content impacts real decisions and generative AI is expected to surprise for human workers being produced by 2030. so this is a massive explosion of just construction company generated that we need to make sense of and the key to all this is actually AI right what are we're talking about ah say uh symptom analysis of a sentence or we're talking about object detection an image AI is actually you know our little motto is it AI is a new Queen and AI is really going to be the key to unlocking a lot of the value from this content the main thing that I want to talk about today is that marrying the AI and data systems are doing AI scale in particular is actually quite challenging on the right here you see kind of like what we generally see in most organizations we have a lot of data being generated not of a structure it's not a semic structure and that has a very clear path to how it gets consumed in traditional systems but for instructional data it's it's kind of it's kind of a mixed bag right we generally see people archive it stored what they want to do after which is all over the place uh there's supposed to actually do nothing with the data because it's really difficult to tackle see a lot of people throw human label and add it some people do AI power apis and then one of the arguments that we want to make is that we want to move towards a world where we're actually thinking about not just AI as a one-off thing but AI is a natural system that can be done at scale and this is actually our main focus of what we've been doing at Collective AI we were building uh reliable scalable and adaptable system in particular we do it for unstructured Content individual domain but what I really want to talk to you about to you about today is some of the lessons that we learned in designing in such a system for three plus years of user research and two procedures are building uh this thing and really three lessons but the first one I want to just say to just kind of set the stage is that actually despite all the AI hype what we learn more and more is we talk to a lot of companies is that a few companies do actually a little more than just archive their instructor data this however is changing very rapidly in a as an AI adoption is growing really fast especially within the context of text but we see that lagging another modalities of data um the two other lessons are going to be what this presentation really is about is essentially kind of walk into the main pitfalls that we see people do when they try to tackle on structured data one of them being that logical data models actually matter a lot more than you think and a different way to look at embedness not necessarily as a semantic means of understanding but as a way to actually cast compute and be cost effective and do an AIS scale so that's it let's get started so logical data models more than anything but you know I think probably a lot of people are wondering well what the hell's the data is this logical data model right so let me explain so if you think of it AI as this kind of monolith that generates metadata right you generally have the data stored in some sort of plot store it gets fed to some sort of foundation model that the AIT team owns and then the output of it gets stored somewhere else and it gets consumed by product folks bi folks Etc right but what's missing here is that this handoff between the data folks or the data engineering team and the AI folks tends to be hugely important uh in particular the pitfall is to just think about hey just use what we stored right because in the storage layer the physical data model that we use is generally one of the key values so which is a comment.json and then some value of text right but it turns out that these AI models are actually very finicky about how they think about the inputs right so the inputs are data specific so it's effects is it audio is it image is it video right and they also tend to be task specific right if it's text am I doing sentiment analysis this am I doing summarization am I doing some other tasks right and so essentially this combinatorics of data and task makes it such there's a large number of logical data models that all right but and what we generally see happen is that there's an impedance mismatch between the way it's stored and the way it gets consumed and usually no one explicitly owns this the data team ends up building a system that doesn't actually capture the needs of the AI team and the AI team is building up a scope system to kind of fix this and fitness mismatch because you know someone has to do it and overall we find that the solution then is one such that instant bottleneck in the entire AI pipeline so uh to kind of go a little bit over the hitting complexity here uh is that insects for example let's say you're stored it as a again a Json file with some text about your review of this chicken sandwich that's awesome right and let's say your task is just memorization right in this case there's no real mismatched right you can just there's no transform needed you can just feed it to us to the summarization task but if you have more accomplished tasks my station like say a language detection you might think of something really simple like a random selection of a sentence or in in steady sentiment analysis you might actually want to do something more complex like a key phase a key phrase extraction but the main point here is that that fiscal data model is actually different from The Logical data model which is not just a key and so value there's actually some sort of pieces of metadata or even substances are irrelevant here this becomes more obvious as you go through multimodal approaches where you may have say a social media post that has a comment a background uh if it's right uh maybe a maybe uh background song a video and an image right and if you send this to a multimodal model the way you actually might want to think about it logically is almost as opposed to being a single entity that contains multiple of these modalities of data and so the main takeaway here is that to order in order to overcome this impedance mismatch we really had to focus on that so you're building logical models at scale uh in particular when we see this works best this one folks realize that there's a mismatch here and we can create data plus AI hybrid teams that actually work in solve this is AI mismatch and what ends up happening is that not only do you resolve the AI bottleneck but all of a sudden you have to realize what this pathway is for optimization to give an example an industry process is something where we saw this is there's an image uh you know this chicken sandwich image everyone's doing the same data transform pipeline to fit into a fight Source model and so you're doing an exam on compute three times but rather if you if you have actually the data folks in the in the AI folks sit down and look at this it becomes very obvious with this room for optimization in which like the AI folks can just consume that pre-computed pre-transform um image and that's what we're all leading to a lot of really awesome consequences such as hey you can you should utilize your gpus more effectively so that's kind of lesson one in lesson two I want to just have a different view of embeddance particularly for the standpoint of cost Effectiveness so once you actually start doing a lot of this work this is how it starts right you start just generally with a One Foundation model and very quickly what you see happen in our experiences that hey folks work with a foundation model for a specific task maybe that's not the instrument is really popular so there's a second task and one test sent to five and all of a sudden you have a lot about you know a lot of compute and you know maybe your building departments comes and knocks at your door and tells you hey what's going on with this belt and what this will happen is that AI cause quickly grew out of control and bottlenecks feature Foundation model applications and I think the pitfall here is that you really have to break up that model if you understand what's happening and uh something that you can do and actually leverage abundance here is that you know it's an oversip it's a vast oversimplification but if you think of these Foundation models as just computation graphs you can actually you know a key takeaway here is that you know the majority of the computer is happening in the future extractor piece and actually folks are generally want to do in task specific uh things they're generally just changing the last outfit layer so if you go back and you actually have this perspective of breaking up the monolith not thinking it as just one computational block you see very quickly that hey I want the exact same I own computers happening up until this point in time and this is insane because that means I'm doing the same computer like a mini number of times which is very very expensive so if you actually just have an approach where you actually run your data through the foundation models if you catch that uh those amendments you can now actually serve this through all the task and all of a sudden you can do uh you can use this Foundation model as a scale because this intercept this ends up being not only reducing latency and cost but it launches the new bandwidth capacity because all of a sudden it doesn't cost a small fortune to run multiple Foundation models in parallel so again semantics this is the or you can do semantic embed is super powerful but I want to have a different view here in which we can actually use the embeddance to do AI in a cost-effective fashion so some part and thoughts uh that I want to just highlight especially within the context of this conference is I think really we're moving from not no longer data likes but to data Outlets because unstructured data it is huge right so give an example to illustrate this right imagine you have to have a lot of data of just some bytes right 10 million rows of these fights uh 10 million rows if you say flow 32s are going to be about 40 megabytes in size so if we equate that to some sort of area for comparison let's say that's Lake Tahoe right when we jump to text 10 million documents now some Spirit was the magnitude in size to about 40 gigabytes and if we were to compare that to say uh Lake Tahoe you know this is now roughly the size of the cast can see so now we've gone to the largest lake in the world right and something to you know to kind of preview what we do a collective is once you go from text to uh video this is this you know you go from uh from 40 gigabytes to something the order now terabytes and no longer are you talking about Crossing Lake Tahoe you're talking about across the Pacific Ocean so we need to develop these tools that hey not only help us tackle text but also help us tackle visual data not only I don't only have a few minutes so I'm just going to say really quickly what we do here at proactive is we unlocked it value of emission video data really focused on essentially a data Centric approach to doing this and bringing really unstructured data to the world of structured data something that's exciting would love to talk to you would love to connect and we are hiring so if these are kind of the challenges that you'd like to take uh you know feel free to shoot me an email shoot me a message or you know apply on ah thank you everyone really appreciate your time awesome thank you so much well yeah I can definitely say the collective team is is great I'm a big fan of Cody as well um no thanks thanks for that chat I think we were supposed to meet a while ago actually well and I I missed the opportunity so I'm glad we we have this chance oh man Lily we gotta do it after this yeah no again a huge thank you to Demetrios you Lily to the entire Milos Community this is this is just an awesome event I'm super excited to go back and see all the recordings too yeah definitely there's some good good talks lined up um all right well have a wonderful rest of your day I appreciated the the Speedy talking I was like nervous to give you a whack like I don't think he can talk any faster oh sorry this is my my hackers might have my timer over here all right awesome thank you I'm well thanks so much