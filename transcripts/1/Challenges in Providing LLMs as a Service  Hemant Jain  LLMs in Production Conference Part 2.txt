until it was the moment so oh there he is okay sorry I missed you for a second how you doing good uh thanks for having me yeah yeah all of them have been pretty great so far I'm just confirming if you can still see it all right great uh hi uh I work at coher I'm a software engineer focusing on ML inference I'm going to talk to you about some challenges that we've faced while productionizing and providing language models as services to give you some context go here has apis that allow people to integrate NLP into their Solutions and these apis come in different flavors but at the cross to bed they're all powered by some language model or the other so to dive directly into the challenges and some possible solutions I'm going to break them down into three categories these are certain limitations inherent through language models or general models um steps for model optimization and lastly something really important the data privacy and responsibility part of these language models and offering them as a service in terms of limitations of language models the first thing I like to call out is the model footprint and here you can think of not just the resource footprint but the overall time and investment that goes into the actual model not only are these models really large in terms of their memory and compute requirements they also have limitations in the case of the fact that a single AI accelerator isn't always enough to serve them so you have to split them across multiple accelerators and now you have to deal with an entire new realm of problems uh I try to think of this as a communication versus computation trade-off and you need to find ways to cope with that the modeling teams have actually trained these models and build the architecture for these models need to take into account the inference characteristics of these models uh for example what kind of tokenizers are using what kind of attention mechanism are you using and so on and then use that to inform that decisions down the line as they go and optimize these models for influence it's not something that can be an afterthought anymore the other really interesting part that I like to call out is the fact that like the popular accelerators are in short supply you should plan ahead and diversify if you are making sure your models run very well on a very very specific kind of Hardware it's very likely you'll run into problems down the road so you want to invest in that early rather than later the second part that becomes really important when customers are using your findings to actually solve real problems is the fact that many Enterprises and customers they want to fine-tune these models for specific use cases and not only is fine-tuning the entire model slow it's also not always needed and is sometimes wasteful uh you should only fine tune when necessary but also choose the right fine tuning strategy and you want to find the fine tuning strategy that is efficient not just a fine tune but also to serve when I'll come uh deeper into that in a bit but what that means is you can't always find you in the entire model you want to fine-tune sub sections of the model and as a bonus you can actually focus on fine tuning using an adapter Network kind of mechanism where you don't fine-tune the underlying weights of the model but you have additional weights that you fine tune that you can then use to serve these models now that does come with a qualitative trade-off but it's significantly faster to fine tune and uh it's it's kind of like a balance between do you really want the best quality fine tune that's expensive to maintain or do you want a more scalable form of iTunes you can actually serve apart from the overall steps here the other complexity with fine tuning comes from the fact that data privacy is generally a problem customers don't always want to say their data sets you might not always want to have some of the third party company have access to a very proprietary data set specifically if they're going to use it to create models that might compete with you the other part comes from the actual ownership of that fine tune a lot of folks don't want to have that specific set of Weights that they produced from the fine tuning be owned by the company that actually does that they want to be able to own it themselves and then be able to do that adapter networks give companies and um the companies building the service a trade-off where you can actually have the entire model partitioned into two parts so you own your fine tune part of the model but then another company owns the Baseline weights these are just some kind of the trade-offs that you have to make the next part comes about cost so now cost of language models as you already know is both prohibitively expensive for training but also for inference you generally do not want to be training from scratch you want to find a good Baseline model to train form it could be something from a third party company or it could be an open source model out there that's already been pre-trained and exposed publicly you want to take an inference framework that supports model parallelism and I and I stress this because of the fact that when you're dealing with really large models you're not going to be able to fit them on a single AI accelerator being able to have a framework that efficiently splits the model across multiple AI accelerators and takes advantage of our parallelism in the right way uh it can be a break or make moment another really important part that I wanna uh talk a little bit more about is the inference stage requires you to have some kind of intelligent batching where you can dynamically batch requests from multiple users or even multiple requests from the same user into a more efficient form so that your influence throughput is high um specifically for generative models because of the dimensionality variance between the requests a smaller batching policy can make all the difference these models themselves are really large in the uh tens or hundreds of gigabytes and because of that serving them requires you to have some kind of quantization you may quantize to the level that you are comfortable with in terms of the accuracy to Quality trade-off sorry accuracy the performance trade-off uh but that's a decision that you need to make based on a use case it's not a one size fits all in fact some training strategies have been found to be quantization friendly especially at scale there's an interesting paper from uh Folks at cohere and cohere for AI that talks about the Intriguing properties of quantizational scale that I recommend you to have a read on one more thing that's important about cost is the fact that you can't keep vertically scaling and you can't be be with large amounts of traffic so you want to start investing into the ability to horizontally scale but all the systems that go around it so it isn't just like a one point solution you now have an entire orchestration layer that you need to be concerned about model optimization itself is one of the other challenges in large language models and I and I can stress this in a different way it's not just the model that you're optimizing it's a very multi-dimensional problem in the sense of the fact that you have to optimize for multiple things the latency the throughput the cost and the quality but also the availability especially if you're offering this as a service and I'd like to think of quality as not just the measured accuracy of your model in an offline scenario but the actual utility or usability of these models as assessed by the customer for their use case as I said no size fits all so you should assess what your priority is and give people the knobs to turn to be able to get uh the right qualitative performance or quantitative performance through these you could batch pattern and have a higher throughput but you would be sacrificing on latency you can try to find ways to scale better and configure an architecture that allows you to do that but it might come at cost that you have to exponentially have more and more services around it to be able to orchestrate that you could sacrifice and cost and build a very lean solution but would that really be reliable would that really be able to scale to large amounts of traffic and be tolerant to different uh problems I want to spend some more time on this just to drive this hole through uh data privacy and responsibility is one of the most interesting and most profound challenges when it comes to these models we've seen the open source Community make strides in improving the model optimization we've seen a lot of companies out there share architectures and designs to make the overall limitations that I described in the earlier stages easier but some of the things that don't get enough attention and some of the things that make it specifically hard to make these language models a service is the ability for you to have privacy as a part of your design you should have the ability for users to opt out of their data being used to retrain other models specifically the comparative models one way that cohere does this is we allow customers to deploy our models in a self-managed container through Sage maker which ensures data privacy and this is by Design so there are steps and considerations you need to make to be able to make the deployment of your models secure for your customers beyond that there's also the concept of data security you want to make sure that you don't leak data this isn't just the data coming in from your customers or the data that comes in to your model for training it's also the underlying data that goes into your overall evaluation of the model you want to make sure you have very clean evaluation systems in place and that you'd evaluate on a range of benchmarks not just a specific kind of Benchmark and and biasm order to be good at only one thing Vex the data that goes into your model and I know really well what goes on because garbage and garbage out one of the last Parts comes from the fact that there's a tremendous amount of responsibility when it comes to not just building but exposing these systems not only do you have to make sure your systems are reliable and scalable and dealing to user traffic with low slos for latency and high availability but you also want to make sure that they are tolerant to misuse and they are able to handle attacks such as prompt uh injection one of the ways to do this is consider achieving stress testing your model and finding ways for third parties to come and try to attack your model to be able to misuse it for certain um well nefarious purposes uh that's all I have for you today I'm leaving a link here so you can go join our Discord community and learn more about coher our language models now you can use them to build your own thank you awesome thank you so much and Nathaniel in the chat says really informative talk so thank you great to hear Nathaniel and Nathaniel message me and we'll hook you up with some swag so yeah all right so hello everyone thank you for joining thank you all right [Music]