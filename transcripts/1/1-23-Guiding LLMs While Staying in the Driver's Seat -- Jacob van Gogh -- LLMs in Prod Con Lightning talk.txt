again my talk is about staying in the driver's seat while you have an llm or you know guiding llms well while you're still in the driver's seat um as a little bit of an intro for what Adept AI is all about we can go ahead and go to the next slide let me see if I can fix this video issue really quickly okay can we see if we reload if that works now cool can we try playing this video so what Aditya is building is a natural language software collaborator if we could try full screening this video Maybe um so what we can see here is that someone has entered in a natural language request to our model and our model is now controlling the mouse and keyboard to sort of execute this task on Airbnb the person here was trying to find like a weekend getaway in San Luis Obispo California uh we're training our model to use a variety of software tools so here we're also doing something on Salesforce and really the goal is for everyone to be able to have Adept carryout software tasks for them by describing things the same way you might describe them to an assistant so we want you to feel like you have this Universal software tool expert as your personal assistant or collaborator and it's as if you were looking over their shoulder as a debt performed these tasks for you and we can go ahead and go on to the next slide so in terms of like how we're achieving this it's not anything revolutionary and we can sort of Step through this a little bit we start by training this Foundation model so something that has this General understanding of language or increasingly more inputs than that and then fine-tuning the model to learn specifically how to do software tool actions and ultimately this means that our product is powered by large language models and so it faces a lot of the same challenges that you know other products are facing such as not knowing when to abstain our model being a little bit overconfident or having hallucinations in terms of inventing actions that maybe weren't appropriate given the context of the software tool and you know all the other problems that people have brought up today the difference is maybe though that the sticks are a little higher because you know the model is taking actions for you so we can go ahead and go to the the next slide so imagine a scenario where you were on Amazon doing a little bit of shopping maybe you wanted to buy a couple of books and imagine you were on this page and you requested that Adept you know add to cart um now you'll have to take my word for this but this seems like a pretty straightforward thing for our model to get right there's this clear button that says add to cards we can probably see how our model would would map this request to that particular action really well but if we maybe were to go to the next slide and imagine that you used our model to navigate to this other book and you sort of gave it the same request add to cart maybe before realizing that at cart is not a part of this page and now this is problematic right because um our model you know in an ideal world would sort of maybe ask you for a clarifying question because add to cart doesn't seem to be relevant to this page um but at the same time as we all know machine learning models can get things wrong and there are now you know a number of wrong actions that it could take here but one in particular is especially painful because where there used to be an add to cart button there is now a buy with one click button and semantically those are even sort of similar right you could imagine that adds a cart and buy now with one click maybe have similar sentence embeddings or however you want to think about it the difference though is that in addition to buy now with one click not being the intended action of this request it's a much more serious action it has much more serious consequences it's purchasing the book and that is not what the user intended and so how do we try and prevent these failures from being so painful to our users again in this world where large language models have this huge failure space due to the nature of its incredibly versatile output space we can go ahead and go to the next slide so again we're not doing anything revolutionary here but the issue lies with the fact that we're sort of sending our user requests and without any sort of safety checks just taking the actions from the llms as being given so one of the things that we're sort of exploring or we think is a good idea if we could go to the next slide is sort of surrounding our large language model with this guiding system so this is like a number of checks that we can perform such as checking action reversibility or maybe a Content filter to add a little bit more color to the output of our large language model and the key Insight I think is that these are not necessarily large language model or ml based checks that we can do you know we could do simple word filters to start with and by doing simple things that are not dependent on our large language model we gain the ability to iterate really quickly because we don't have to incorporate that into our model to begin with it gives us the ability to iterate on what the product might feel like if we had these sort of checks in place and to make sure that we're moving in the right direction before we spend a lot of time up leveling the ability of our model and so you know by doing these things we could maybe say that if the model is trying to do an action that we deem sort of irreversible maybe we should also ask the user for confirmation before we do that and ultimately the goal is to use all this to feed into our large language model and ultimately improve its capabilities so yeah now's a good time to go to the next slide Adept cares very deeply about our data engine hopefully data engines are also not a novel concept but the idea is that we have some model that we can deploy into our product and we use that to gain user feedback and we use that user feedback to then inform our data collection strategies such that we're always collecting the data that is most impactful in terms of improving our model and improving the experience that our users are having when using our product that is driven by this model some things that we care about in particular if we go to the next option so we really value fast cycles and adapt at a depth we strive for 24-Hour cycles for internal builds so what this means is that every day we're building a new model deploying it to the product that we use internally and gaining you know user feedback on that model that day and potentially updating our data collection strategy that day in these short Cycles ensure that we're getting fresh user feedback imagine interacting with a model that was maybe two weeks old the user feedback is is old and so what that means is that any insights that you're gaining might not be relevant because maybe a model that you train today would not have those problems anymore it also enforces a high standard of internal tooling we care about our workflow reliability and our visibility and instrumentation that we need for fast insights you know that we were able to inform our data collection strategy every day and it requires this really tight integration between engineering and data collection we're always chasing that that best data point that we could get to improve our model in the most impactful way and so if we go to the next slide there's sort of like three things that we've learned early on when building a product that's powered by llms that's taking actions for you you know they can fail in many ways and you really want to focus on those which are most painful to your users again these actions that are maybe irreversible or have high consequences if you get them wrong I don't think we should shy away from non-ml checks on llm outputs we don't need to throw out all of the the types of Technologies and strategies that we've used in the past for controlling um you know these automated decision making systems that we've been building and keeping a tight integration between data collection and product and Engineering efforts I think really makes the data collection efforts that you have more optimal and more efficient and so we really value that as well so those are sort of like the takeaways I you know thank you for for listening and if you know Adept here in depth we think that we're working on really difficult problems and so if these sorts of problems excite you in any way you know feel free to give our our careers page a look you know we'd love to chat awesome thank you so much and a couple people said that um I don't I didn't see the notebook I can't see the notebook was that on one of the slides it might have been the previous talk well maybe it was okay and then someone asked how would you integrate with something like mac automator Mac automator um well I don't know if I could speak to that explicitly I'm not super familiar with that Tech but if if I could you know imagine what it might look like um so we spend a lot of time sort of trying to collect data that really Maps um a user request into these sort of like action space that you would need to do to execute that so in the browser it's like given a user request what sorts of like things do we click or key down in order to achieve that task so I imagine in Mac automator there might be like a similar thing that we would try and map to if we wanted to leverage that technology right now we're doing everything in the browser but we think that the idea in general extends to the things that like sort of take control and execute tasks for you awesome well thank you so much Jacob this was wonderful and it was a great note to end tracked you on so thank you so much again thanks for having me [Music]