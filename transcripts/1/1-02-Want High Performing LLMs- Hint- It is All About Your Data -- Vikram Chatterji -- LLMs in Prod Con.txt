ah hey yo we got big drum joining us so what's up dude hey Dimitris good to see you again you weren't you weren't ready for that intro on there we're expecting cows were you but I loved it it's the only way oh man dude so it's been a while since we chatted I love what you all are doing at Galileo and we're gonna give a huge shout out to Galileo if anyone wants to try it we're gonna drop all kinds of links you're gonna show us all about what you all have been working on and I gotta say thank you so much because you all decided to sponsor this event and that is huge it means a ton it keeps us in business it means that I can do these things and I can dedicate more time to it so thank you so much Vikram thank you so much and there are Galileo socks as well oh no way all right I didn't realize that I'm gonna be giving them away then anybody in the chat Let's uh oh my God Lou just wrote in the chat that that last video was moving and that is how you get some yourself some Galileo socks all right let's do it so Vikram I'm gonna share your screen right now and yeah man jump into it I'll see you in like 25 minutes and for anyone that is watching along feel free to ask questions in the chat and we'll get to them at the end sounds good thanks Demetrius yeah and I'll try keeping about five minutes in the end for for any questions um just a quick introduction uh about me so I'm the co-founder CEO of Galileo um the the company itself and the product is completely geared towards your your data and how you can figure out what the right data is to work with I just heard about just before this we're talking about the terrible experience debugging and uh when you're but they're working with recommendation systems or whether you're working with NLP models or Now with nlms uh but the whole reason we started the company was because before starting Galileo I was heading up the product management team at Google AI and while building out models there we face this problem on a daily basis like literally days and days of just working with exercise sheets and Python scripts to debug the model and figure out where the failure points decide we used to call this data detective work so a lot of scars from that and that's kind of what I also wanted to talk about over here but uh all the chatter about llms now which is uh to what Alex was mentioning before it seems like this is the new phrase that we've all uh anchored around and it used to be Foundation models just like literally a second ago and John stands for learning based uh Transformers before that so it's interesting how the how fast the entire industry is moving but what's interesting also is that the first principle is still stay true and that's what I wanted to discuss the first principles are that with ever since machine learning ever came about for those of us like me who've been in this space for the last decade and more it's it's always been about the data right uh and it that doesn't change but what I think changes is what does that mean in the context of llms and the context of generative AI for people who are trying to work with GPT or any of the other wonderful open source models that are out there so obviously unless everyone's or someone's living under a rock we all know that AI in general is having quite the mainstream moment right now powered by this hugely been model development essentially like just having being able to train uh bottles on a lot more data huge Corpus a lot of other pieces here that have come in and to making this happen today but almost every day you see things like you know why combinator having a good almost more than one third of their entire class or one-fourth of their class being a generative AI apps we're seeing these other accelerators as well uh hearing about how this could be transformative for the Enterprise we're also starting to see a lot of worry and repetition in the market and you know how do you navigate generative AI for customer service is it a bubble uh their think tanks talking about this uh it's a it's overall just a really interesting time in space and the interesting thing is that all of these different kinds of headlines are have come in just the last three or four months right like little rewind to December and a lot of this wasn't even in the Zeitgeist which is ridiculous so uh of course like we are all having this huge moment now where AI is gone mainstream and uh everyone in the street just kind of knows about GPT and it's kind of brought it out there however I think the piece which I wanted to really flag is that it's for for those of us who've been in the industry for a long time which it seems from the chat and every every all the other talks that I've seen so far it's a lot of us so we kind of know that we've we've seen this movie play out before it's just now there is so much more hype and someone's done their marketing came really well because uh you know everyone's talking about it but essentially if you if you're rewind all the way back to uh 2012-ish uh because I think it was 13 September 20 2012 and there's this this CNN uh called alexnet which uh which came out and and won the won this imagenet Challenge and uh you know people were talking a lot about that and there was this article in the in the economist at the time which in my head is kind of when you're reaching mainstream uh where where where they talked about how suddenly people started to pay attention not just within the small AI Community but across the technology industry as a whole about what's going on here how can you classify these images in such an interesting way is it gonna uh have to be a huge breakthrough and that was of course on the heels of a lot of interesting developments in the GPU space and uh from compute and storage Etc but all of that's what led to that happening at that point in time you fast forward from there just a couple of more years and you get to um the uh the huge Transformer paper the attention is all you need which came out of a sister team of mine at Google and this was huge right and you know just that that's what led to uh our teams at Google creating Bert and then because Bert was open source and anybody could build on top of that it lead to increasingly these models becoming commoditized entities and uh we saw this huge explosion in terms of distilled word coming about Robert are coming about uh span bird and so many others uh and uh if we saw companies like PayPal coming up with what they called PayPal board if someone's thinking about GPT what's called plume GPT it's very similar right like PayPal basically said Bert is great but it's it's trained on the entire Wikipedia card but it's not good enough for us we're gonna fine tune this and to train this on specifically PayPal's data and that's what we need for our use cases to actually work out so awesome I'm gonna pick up bird just off the shelf it's super commoditized and but I'm gonna fine-tune that on this specific data that I have and that's going to work for me and my models and my users and my use cases uh similarly stock news sentiment analysis with Finn birth I came about so this whole entire explosion of models essentially led to the commoditization of these models as entities and so my team at Google essentially was also just picking up bird off the shelf and that was the job done we would experiment with maybe a couple of variations of bird but for the most part it was again what we called Data detective work where we figure out what's the right data for this for us to train with um once the models in production you could again kind of check for whether there are any data failure points for the bottle etc etc so it always comes down to that first principles and that's what happened there in uh this was I think back in 2017 to 2020 2021 um so that was like in my head the first wave of uh large language models because in back in 2018 I guess like bird was a very large language article so if you you know I guess now we're dealing with larger language models and that's the only difference uh and because of that it's much more powerful and because of that the stakes for in terms of what can go wrong are also much much higher right so that's why we have to be very careful but right after this we started to see this huge wave of what um data scientists kind of already knew when we're talking about but I think Andrew ning coined this really interesting phase phase of data Centric AI uh where uh it was it was interesting because when we uh when we talked to uh more and more data scientists they started to really gravitate towards this this phrase because they realized that already that when they're working with their with their importance those had become commoditized and good quality data and knowing what data to train with not quantities of data became the barrier as well as the mode because some companies just did not have enough data what do you do there some companies that did have propriety data that just becomes the board for their for that business it becomes a massive differentiator for themselves so the whole industry started gravitating towards this idea that great these models are commoditized now I'm going to start to focus more on the data fly field that I can create here and if I don't have enough data I can actually synthetically generate some of this data uh can I spend a lot of money on labeling the data can I yeah what do you do after that when the labels are incorrect how do I fix it all of this started to come under this umbrella of data Centric AI which I'm doing uh uh coined a couple of a couple of years ago um and this is also essentially been at the heart of what Galileo does it's essentially a very data Centric platform for uh for being able to build great machine learning models across the ml workflow whether you're starting from before you even label your data right after your label them in your trading and iterating on it over and over again we're in cahoots with the bottle and we tell you uh the calendar the product automatically tells you what the model failure points are so you're not spending weeks and weeks in data detective work that's the enemy for us and then once your artist in production again like telling you what's the right data to train with next uh and pick up next so uh very much in line with this entire uh this entire movement however um back to the present again what you're seeing now is a new Modern Wave of models that are emerging super exciting times of course like I think all of us are feeling that um and we've again increasingly seeing at a much faster Pace than what we saw in the last iteration of this a couple of years ago that the martyrs are becoming commoditized way faster right and you know uh GPD it feels like just came about a little while ago and then llama came about Google has its own um many applications built on top of that to further Market these different models um and then a whole host of different open source uh models coming up right on top of that but with this commoditization essentially uh what we've started to see is this is going mainstream again and so um Again The Economist about 10 years later after this first quote that came up in 2012. again there was this uh this this uh this quote about how Foundation models can do these magical things and that there's huge breakthroughs and this was in June 2022 so the economists had not caught on this new wave of it being called large language parties yet but they were calling it Foundation models similar to what Alex was mentioning before where you can call it either but I feel like it's good for the industry to gravitate towards uh one term but essentially at the heart they're kind of the same they are the basis of what you can build on top of um so it's really interesting how we've gone through the cyclical process in the first iteration where an interesting ml breakthrough happens people talk about it it gets uh it gets uh it gets uh a lot of attention gets into the mainstream and then gets commoditized very quickly and then again now we're getting into this phase where people are realizing that wait um these these models are great A lot of them are uh are are closed source so now how do I how do I use this for myself um and uh how do I figure out what to what to uh train my train my borders with um so a lot of these different kinds of uh open source models have been coming about recently and you know some of we've some of this has been mentioned in a few talks before but it's interesting how um you have data breaks coming up at Dottie for instance you have alpaca uh who's come out of Stanford uh which is super interesting to see uh you know they've basically been ordered trained with much less robots of data but lots smaller amounts of money as well but basically like fine-tuning the the larger bottle uh based off of data that's coming from a large language model uh Bloomberg GPT again like you know very similar to a couple of years ago PayPal bird came about and now you have Bloomberg GPD coming about where they've painted on their own financial data uh the model itself has a lot to be desired and if this is just the beginning I'm sure rev one and after this they're just going to keep iterating on it over and over again with better data and make sure that the problems are better as well um foreign and uh another example which I which I came across was eichel which is an instruction tune German llm family so it's it's uh it's interesting how every single uh use case there if your folks are trying to find data so that they can train their open source models within just hone this for themselves and that's going to be another proliferation very similar to what we saw with the bird era of doing things we're seeing that again with the GPD era of doing things that the difference is the board era started with open source for the most part versus now we're seeing this go from have a bifurcation between the closed source of apis versus the open source and uh both of that I feel like it's a healthy competition and healthy things will happen in the market but it is just going to be this huge um proliferation of Open Source models and because of that a lot of customers and companies especially in the Enterprise uh trying to trying to curate their own models for themselves so that they can have a differentiation and have that more to be built out um again what we're noticing here is uh yet again the good quality data is emerging as the as the big blocker and and uh and the big mode for for the industry uh so we this is by Greg Brockman this is an interesting uh quote which really hit home for me uh this is uh for those who knows the CTO of openai uh he was a co-founder of openai and who's the CTO of strike for and in fact not unfamiliar at all with this problem and uh we've been mentioning this before about how you know 80 to 90 percent of what a data scientist does today is basically just staring at the data trying to figure things out trying to fix it and then iterate on it over and over again right across the entire ml workflow it doesn't matter if you're just starting out you start out with the whole Corpus of data or if you're just iterating on the trading Cycles or if you're on the model production side of things you're just constantly iterating with data and it's a it's a from a lot of our customers and partners today got a little we've heard of this being referred to as the most soul-sucking part of the job but yet the most critical and pandatory part of the job and this this whole notion that this is the manual inspection of data has got to be they have the highest value to prestige ratio of any of the other activities is true it's a really really hard problem to solve and it's it's typically very very manual which is exactly what we're in uh trying to flip the narrative off it doesn't have to be manual we can automate a lot of this we can make this much much easier uh and the same thing the same principles go through even even today um so the other piece here is is that when you're building llms data becomes extremely critical and I think more and more people who are in the weeds of building out uh ml apps using you know whether it's the predictive models or generative models what have you you very quickly realize that you know the data is a very important piece and now with these generative Partners I guess what you're calling nlms um it becomes important for a couple of reasons so maybe touch upon that first like why it becomes really important and then I'll talk about um you know which aspects of the entire flow when you're creating these apps are where you should be really where we should all as a community really be thinking more about how we can invest in where there is where research needs to can be pushed in pushing the envelope on and uh where tools can be built out to actually help out developers in really turbocharging their their workflows and giving them superpowers so the first part is um what uh why this is really important um so as we all know that you know model High destination is a very real thing we actually saw that in the uh I noticed that in the uh prompt injection piece that we were doing were very quickly we were running into these bottle hallucinations and that happens all the time it's it's it reminds me of these uh of how fake news that's just spread across social media you just don't know what to believe anymore and so the model is kind of similar it's like I I don't know here's an answer and it's very confident about the answer but how do you know whether to believe in that or not and but with the right kind of data with the right kind of prompting that hello stations can produce it's just a matter of being very very cognizant about that so this is really important the obviously the the super popular story about this this the case study around this is Google's AI chatbot Bart that was making that made that factual um error in its first ever demo um they've been tweets by Sam aldwin and others about at GPD as well where it's like do not believe necessarily in everything it says Google Bing in its new um uh in this new release for its for its chat part also said that you know take this with take these results with a grain of salt so it started to uh the mitigations around hallucination has started to emerge in legal text in these applications but as app Builders ourselves we can go we can we can fix this by trying to be better about the inputs that are going into the the llm itself which I'll talk about just after this the other piece is you know becomes very critical when you are fine-tuning your uh your llms to your use cases again the I'll stand for alpaca was a great example of this we've seen a whole host of these to be honest koala came out of Berkeley recently it's a really interesting paper if those are not if you have not read it it's about a dialogue model for academic research specifically trained I believe on just a bunch of academic research papers um uh there's a Portuguese Portuguese fine-tuned instruction uh version of llama um there's a Chinese uh instruction following a version of that as well so there's the power of just providing an a model out there so that you can fine tune it is exactly this it leads to a huge explosion of very individualized kind of models for anybody else to use in the world and that's where Innovation can begin and now you can start to focus on your data on top of that so you can fine tune your llms and all of these folks who basically had some level of some Corpus of data which they could find you in their their model or top off um the uh the other and the third reason is uh to ensure the model responses are predictable and of the highest quality because at the end of the day especially when it comes to Enterprise use cases but we keep hearing from our uh from customers at Galileo and our partners is that I don't I can't launch a model unless it's unless I have trusted it and this whole notion of you know the uh what is it 10 or 20 of models reach model production it's it's not really about the lack of tooling at the way in fact I would argue there's too much tooling along the way to build great models it's more about how do you make sure that the model is of a very high performance um and that's the biggest part in that how do you get there and again for that data has become the biggest bottleneck to get the model to that high performance where a data science team can feel like I I can truly uh put this out there in production and then once it's out there in production uh can make sure that I can I have the verb without to be able to make sure that's always performing really well um there are a couple of things in which we can do to uh to be better when it comes to uh create doing uh more data Centric llm development uh going back to Ann tuning's coinage of the storm data Centric uh you know applying that here to uh llms it's it's there are many different ways to do this the way uh we've been thinking about this at Galileo has been um that it always comes down to the inputs right and before earlier when do you think of foundation models or Transformers the inputs used to be the border the code and the data and uh what we noticed was the code was minimal the model was commoditized the data becomes the 100 000 pound gorilla in the room that you have to fix right now what you're noticing is it's similar the model is commoditized the code is minimal but the big inputs now are the the data but also the products right and uh so I would I would my argument here has always been that we need to figure out how to how to uh balance between both you do need to find you and your your your models with a lot of data but again like that can be difficult because a lot of the Practical reality is sometimes you just don't have enough enough data uh and sometimes if you have a lot of data you don't know whether it's of high quality or not so you can also just use um uh prompting but two people to go that extra mile and be able to uh fix your make sure that the model output is good depends on the on the use cases that you're working with however uh it's really important to make sure that you're taking control of your inputs and what I mean by that is when you think of prompts itself right it's very critical to optimized for a few things if you keep that top of mind uh one is the structure of the product itself right so something which is really popular these days is just zero short prompting and and uh and uh and uh prompting the model that way but there there's a whole host of research that's being done around how we can do better about the structure of the prompts itself and I think this is somewhere where um you know a lot of the Premier Research Labs that we talk to and you know half of our team at Galileo is ml research that's constantly uh pushing the envelope on exactly this kind of stuff um we keep thinking about this like what it can we do which is better and one one paper which we read recently which is really really interesting which came out of my uh previous sister team at Google brain was uh this idea of Chain of Thought prompting uh which essentially it's a very simple concept it just means that instead of just saying that the in your prompt template input uh it's just saying the uh the example answer for uh for uh for a question like this where you're doing a almost a math calculation and saying hey the answer is 11 instead of that if you just reframe the the answer to actually tell the model the chain of thought that you used to came to come to the answer the model outputs can be much much better so that's a slightly different structure towards your prompts uh and it's a it's a really interesting paper where they tested this out against uh whole host of very large language models and they noticed that as compared to standard prompting it has it by orders of by an order of magnitude it does much much better so this is an example of where I would uh urge all of us to be a bit more cognizant about the structure that we're using in the prompts itself and look out and for better research and maybe share it across the community what the right kind of structures are um for these prompts so that we can all benefit from it holistically um the other piece is context and retrieval of course the more context you can give the model the better more examples you can give it the more retrieval you can get the better it is fine Cohen is an example uh this is certainly not the official logo of Pinecone but uh you know those who use retrieval mechanisms for their uh during prompting will know that it really helps in augmenting the the outputs of the model but again the question there becomes when you're when you are using a vector database or some kind of a repo of data for your examples and giving context for the to the model the question becomes is that the right kind of context if you're using a vector database the question becomes is there other kind of context that you could use which is maybe similar or close up close by in the embedding space that you could pick up how can you be better about that so that kind of think better about the context that you're providing and tweaking that and maybe even fine-tuning that over the course of many different prompts is super critical and the third one is just instruction uh for for these problems and just uh you know being able to give the right kind of examples and uh and tweak that over and over again um this is is super critical so there's a lot there it just prompts itself which is why perhaps there's this new term around prompt engineering that's that's coming about but the whole reason for that is because there's a lot here in terms of what you could do for uh for improving your your uh the output of the models and making that a little bit more predictable uh before you put it out there in the wide um apart from that you can uh of course just fine-tune with label data and while doing this it's number one extremely expensive for the most part to use a labeling tool or or uh and also very time intensive sometimes uh but at the same time it's extremely critical here when you're fine-tuning to identify whether you can you're seeing any performance regressions caused by uh caused by the fine tuning of the model um and especially now with llms right this is much more exacerbated because you're dealing these models have been have been trained with so much data and the like I think the Corpus of data is so much larger that when you fine tune it with certain kind of data the model performance that you see is not going to be that great so you have to keep doing it over and over again um uh to be able to get to the point where you can you can have a model that works really well for your use case whether it's Finance contact center or what have you um the second piece is of course incorrect ground truth no matter what products you use no matter if you have in-house labelers if you have humanism Loop if you're doing reinforcement learning if you're doing rlhf there will always be incorrect round truth information and that this becomes a hair on fire issue how can you automate this are there ways to do that how can you get faster about figuring out what the incorrect ground truth is a lot of this is um very similar again to what used to happen with the world of Transformers and still does for for uh predictive ML and those same principles and first principles still apply um the last piece is maintaining data freshness and repeated fine tuning because again the models in production that's not the end of the day it's not done and tested you can't go just move on to the next thing you have to keep monitoring it if you keep figuring out whether you need to fine tune again what's the right data to fine-tune it with that's again something which exists today with the world of foundation models as well and with Transformer Partners but it it is again super important as if you're building llm apps across the Enterprise there's a whole lot more of things that you have to do on the fine tuning side too so tldr here is when we think about being data Centric so to speak in the world of llms it's not just the fine tuning of your of your actual date label data but also looking at the prompts and analyzing that from multiple angles and making sure that you're good on both fronts um so I know I'm at time or maybe even Beyond um sorry Dimitri stuff I am but um essentially llms we all know are ushering this new wave of Baseline open source and flow Source models and the Enterprise is benefiting from this we all are uh so very exciting times so I would say like we should just get our data ready and have our first principles hat on and get to make sure that we are um making sure uh optimizing the the uh the different uh prompts that we're using as well as the the data that we constantly fine-tuning it with so I'll stop here uh I don't know if there are questions at all but I'm happy to take any there were a few questions that came through let me let me find them real fast because I thought it was really nice um so let us see there was one that I wanted to find and now I can't find it of course of course I'm also slack by the way so if anybody has any other questions feel free to reach out to me there too there we go there we go so uh we can continue this conversation in the community conferences Channel but I think there was um uh where there was some there were some really good ones and of course in the chat itself I struggle so in the meanwhile if anyone has any questions throw them in uh because there was so we had some people singing the Praises of Galileo uh then they have okay there was one person talking about how when they did fine-tuning of Bert in the past and then they saw the results they never thought we would get to this stage that we're at right now so oh man there was a good one but now I can't find it okay anyway for those people who have questions go into slack yes because I guess we're not gonna get it here I've failed you as the moderator I had one job man I had one job and then you're gonna see how good of a moderator I've been I mean um okay we got one coming through now that it's it's been a minute have you seen regression in prompt performance when updating models how do you manage that you do you do and it's a lot of experimentation to be honest right because you're constantly changing the kind of models you're using you are kind of you have to test and evaluate those those prompts um I think the way to manage this again gets back to force principles you have to have the right kind of metrics at your disposal you have to have the right kind of tools to be able to check for you know which model did I use here what was the what was the response from the prom for what input um and then be able to make decisions around that and that is something that we'll be hearing again and again from from industry practitioners that it's been really hard for them to manage um you know this entire like uh the the uh the uh the comparison between how you look at different problems because it gets into the hundreds very quickly and then the thousands and then you have multiple problems the multiple models The Matrix is just huge and so um it is Barclay a software engineering challenge I think which is exciting for uh you know the ml Ops Community uh but I also think it's a little bit of a research ml research Challenge and that's why we keep talking to the research Community because we need better metrics in my opinion to evaluate the prompts from a model perspective to know like which one is doing well and which one is not and honestly like right now I've been asking the the different research agencies my teams at Google before and there is very little like out there right now in terms of what what metrics you can use to evaluate these problems across the board so people are kind of defaulting to the usual like blue scores and other things like that but I think something new needs to come about and and help that but for now software engineering tools are are are the best bet dude well the big question that I have is do you feel like prompting is then stay like are we not going to just move past prompting eventually move past it um there's a big debate that Dimensions like I think you open up a can of worms that they'll literally amongst the people that we talk to uh there there's there's there's two different gaps there's some people who say that that's all you need you don't need to find unimporters anymore that like you know the bars have arrived throw any data into this we just need to do inference with prompts some folks say prompts are stupid you just have to always find inner model I believe like the reality of today is that you need to do a bit of both it depends on your use case if you're building a very um High uh high intensity app which has with the downside of getting something wrong is really high uh you need to do a lot of fine tuning to make sure that you can get to the the uh the 99 percentile or the 90 50 percentile but um I I think the hero now is prompting is very very important it is a it is a real part of the workflow so you pick out for it but I do think it's gonna stay for at least a while until models just get that good which is probably going to happen but again the market is changing so fast we have to kind of index on the year and now and I think at least for the next one to two years it's gonna be a thing but it's just gonna get better and better get better helping people do prompting faster and maybe it'll be automatic at some point here's the problem you should use them