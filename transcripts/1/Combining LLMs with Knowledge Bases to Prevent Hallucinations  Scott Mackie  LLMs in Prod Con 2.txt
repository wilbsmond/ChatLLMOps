she's been so awesome so without further Ado Scott nice to see you hello hello how's it going imagine people are getting tired from the day but hopefully solve a little bit more energy I'm doing really well I think just revved up from all the learning is how people are feeling well that's that's good to know that's great to hear yeah and where are you joining us from I'm actually based out of Vancouver Canada so out on the west coast it's our early afternoon for me you guys sent us I'm in the east coast of the US you guys sent us your Smoky Skies I think it's a little bit more Alberta but yeah I know you're definitely right it's been a bit of a crazy year uh just yeah it's been incredibly hot which for Vancouver is pretty nice because the you know it's it's summer now it's nice and warm we go hiking and see the mountains but yes not so great for anyone downwind of of this area but yeah yeah but good I hope you're getting some good hiking in that's that's awesome uh cool but well we will give the floor to you and I'll pull up your slides thank you so much for joining us of course thank you so much yeah all right all right well let's jump into it so all alums in production part two you'll see the the red theming here this is for the the company I work at and so um hello I'm Scott Mackey I I'm a founding engineer at mem and today we're going to talk about a very exciting topic something I'm very passionate about which is combining llms with knowledge bases to prevent hallucinations a little wordy but I think the topic itself is really really exciting and so wait and see here this is what we are building I want to say we I'm referring to the company I work at which is mem we're building a personalized AI knowledge assistant one way to think about this is like chat gbt but it has access to your email your calendar um it understands what you're working on and I like to to tell people I think of it as a personalized executive assistant right my EA you can ask them hey can you summarize those meeting notes that kind of thing um and the reason that I'm so excited about uh preventing hallucinations and work with knowledge bases is that the thing that matters the most to me at least when working with an assistant is that they're not going to lie to you they're going to tell you the truth they're going to go and prevent um anything weird from happening uh they're going to make sure that every piece of information they're sharing with you is accurate and factually true so what are we going to cover today are there three things that I'm going to walk through first thing is quick intro into what are hallucinations second thing why do we want to prevent them why do we even care about all this and then the third thing is we're actually going to walk through a real world scenario which is building a q a chat bot for Bevy which is a game making framework and the reason I chose Bevy is because it's actually something personal to me I've been trying to build a rust game on the side and something that's been really challenging has been trying to learn it when there's it's not a language I worked with before not frame when I worked before I've never done game development and I think it's a really great example of a scenario where a q a chat bot can be extremely useful but something like chat GT isn't good enough and so we'll go and do a deeper dive into that later but um that's going to be the bulk of the presentation is focusing on the real world scenario maybe one thing to add to this section is that I'd love for people to take away from today that this is something you can go and build yourself right it's not extremely challenging and you can actually use this set of slide decks in this presentation as a reference or guidebook for actually taking all of these you know different different learnings and applying them to your own work so what are hallucinations well now um hallucinates it's producing imagined output and so I think like a really obvious version of this is if you go and you ask it for some source and it gives you some link and the link is is just totally false right there's two main types so one of them is fabrication of facts and second is faulty reasoning so the first fabrication facts I have a little example here might be a little challenging for everyone to read but essentially what I've done is I've gone to chat DBT this is the 3.5 so GPT 3.5 turbo and this is the May 24 version and I ask it hey if you could recommend one behavioral economics paper to me which one would it be and can you give me its name and ID and it goes and responds with a name which is nudging individuals towards better financial decisions and it sounds like a real paper it sounds like Richard Taylor is famous like work on nudge um and it gives us this link right and when you actually go and take a look at that ID you'll realize that the citation is made up it's not the correct paper right this paper I can even find one that has the exact matching name online maybe it's somewhere but it's very like challenging to go and actually track down if it does exist and and you can just tell like the L Alm has just lied to me about this being a proper source another example of Hallucination is I really like this one here which is also the chat GP 3.5 model but this is an example of faulty reasoning so I go and ask it hey suppose I've got two pounds of feathers and one pounds of bricks which one weighs more right two pounds or one pound right two pounds should weigh more it should say yes the feather is way more but it goes it describes rationale and it says no the feathers are going to be lighter and you know they don't weigh more than bricks right which is just an example of faulty reasoning I think what's really interesting about this example is that judging before is able to get this one correct in some you know larger models they're able to do a much better job of reasoning and I think it hints that over time um this class of hallucination becoming less problematic I I think another one that's really interesting about this kind of like faulty reasoning hallucinations that there's lots of different strategies you can take to try and improve it and so you might have seen people are sharing prompts online where you're asking it to self-critique right hey does this make sense to you and the model might say oh I apologize right like that actually doesn't make sense and gets it right the second time and there's lots of different strategies you can use like tree of thought and all that that can help solve faulty reasoning but um what I really want to focus today on is this first kind of hallucination which is fabrication effects so why why does any of this matter we might have heard or seen some of these articles around uh uh it was publicized recently I'm sure there's lots of examples of this but this is one that kind of flew up a bit which was a lawyer went and cited some sources from chat GPT in a court case and they were made up they were hallucinated and I think like a lot of people look at this like oh you know why would someone go and not like double check and make sure that they're real but I think that lifeanged really interesting is that it's clear that this is a use case right this is something that's valuable to people is being able to go and use these tools for research purposes there's some utility there and I think it just highlights how important it is to start developing products where you can go and build for this use case right things like legal research but actually ground it in reality and make sure that anything you are citing is real and so that's what we're going to spend some time diving into two things I want to call it first is is kind of like what what's going to change in the future with llms right because there's gonna be strategies at least today right like some of these prompt optimization tools that you would expect to kind of go maybe a bit out of style as the reasoning gets better and other things that are going to stick around um one thing that I think we're going to see improve and and ironically it has recently is improved instruction following and so anyone that might have singing I think was a last day or two open at AI announced a few um new language models that had better instruction following capabilities and what's really useful about this is when you go and ask it to perform certain tasks so only respond with you know two words or respond in the Json scheme format that kind of thing they're becoming a lot better at doing that and so it's much easier to build products on top of tools that are going to follow the instructions that are provided in the prompts or system messages or however you're prompting it the other things that I think we're going to see improve reasoning so I talked a little bit about that and then larger context Windows we've already seen this with some models like pods uh like 100k token model and some that might even be large enough um this one's really interesting because it means that some things like compressing documents or having really good information retrieval systems where you're like getting the exact document that has the right data those are going to matter a little bit less because we'll be able to stuff more in the context you can build products that have like you know longer chat histories that kind of thing without having to go and do a bunch of extra engineering on top of it and so um really excited for that to be more common and then something I'm not going to spend too much time talking about today but I I just want to call out is that fine tuning is going to become a lot more simpler right there's lots of companies building the space trying to help people take maybe their thousands or tens of thousands of user feedback examples and fine-tune models for specific use cases like classification um I think that fine-tuning is really interesting for some things um but for generative text it's it it struggles in some areas specifically when you're trying to go and have something that's factual right like you need to be 100 true it's not great at that um what one kind of slide note through the presentation I've linked a couple like further reading notes and so I'd encourage people after if you're interested in any parts of it to go and read some of these papers I think that AI space is something that is very unique uh in that within the last two years there's been so so much new information that uh reading papers can be really valuable to understand what's Leading Edge what direction are things heading and so on and so one thing I encourage people to do yeah so improvements what's not going to improve I think the main thing that is not going to change is the fact that IR systems or information repeal systems are still going to be required right so LMS they won't have access to real-time data I think a really simple example this is I might go and say hey what's the score of the basketball game right now right that's like a piece of data that I'd probably want that to be down to like 30 seconds or maybe a minute delayed but more than that I'm going to be kind of unhappy LMS there's not really good capabilities now to go and get that data into the underlying like model weights right you actually need to get into context somehow and that's going to likely be with some kind of information retrieval system integrating with apis that kind of thing the other thing that the improvements won't solve is 100 trustworthiness and I think that we're going to get a lot closer than this so I can get you on goon has a really interesting presentation on like Auto wrestling models and some of their limits and I think that um it's clear that at the end of the day when a fact is produced you want to be able to point to one or more sources for that effect and something that the llms today struggle with is is being able to go and say oh well you know and just about this training data I'm not exactly sure where this came from whereas When You're Building Systems that are being a little bit more identic right you've gone you've gotten some documents you put them in the context it's much easier to say oh this fact came from here here here here are some sources right obvious examples are like you know Bing chat uh will go on site like which websites to build data from that kind of thing and and you know to to maybe reiterate that's a big part of this talking like why it's valuable is that this strategy and some of the things we talk about are going to continue to be useful in the future and when you're building these systems you're going to need to be thinking about this so real world scenario we're actually going to dive into it now um building a chat bot to teach us about a topic right a product whatever it is in this case I'm going to use Bevy which is a game making framework in Rust I'm not really familiar with rust I've worked in a number of languages but it's not one I've really been exposed to that much and um again like this this strategy could be used for many different systems where you're trying to do the same kind of thing so you can imagine a product where they have a help support center right with a bunch of different documents like some knowledge base that's going to be very similar to this if you're trying to go and build on some other tools for just like a bunch of facts that you want to query over right things like chat PDF right all of these strategies are going to be very similar um the reason I'm excited about Bevy again is because I've been trying to go and build a game and learn how to use better and one of the first things I did was I leaned for chat DBT and said hey right like I can use this great tool to help me learn what apis I should be using how do I go and renderers rights how do I go and make like the very performant so on the problem is that all of the data is out of date for the current versions of Debbie um intensity has data from 2021 and the Bevy framework has been updated like 100 times since then and lots of the apis have been broken and so every time I go and generate something I get some error and it can't help me with the errors because it doesn't know about the newer apis so it's been frustrating because it feels like there's this great tool but I can't really leverage it for for my purposes and so that's what inspired me to go and put this together um so the the main thing that that I want to make sure is happening is how do we avoid hallucinations and make sure that it's telling me truthful things that I can use when you're trying to build this kind of system the very first thing that you need to do is provide the chatbot access to some knowledge base right and so a knowledge base like it's it's kind of a vague word uh but I think generally it can refer to a bunch of information um in multiple formats right so it could be facts in a list it could be documentation it could be files it could be website SportsCenter that kind of thing and essentially what we're trying to do is I collect it into one spot so that a chatbot can reference it in this example I'm using data from three sources so there's web tutorials which is the webview website there's the docs and code examples and so when you actually go and take a look at Bevy they got lots of examples building like a Breakout game that kind of thing and then the GitHub FAQ um the GitHub application is really interesting because this is actually live data that is you know you could download a snapshot of it but ideally would you actually be able to use the GitHub apis interface with it and so um and kind of split them out into two strategies one is downloaded the web tutorials and docs and code examples so snapshot and time right in in this example as we're working through the chatbot this is actually some code that I've written I plan to share it later this week um just open source it if anyone wants to go and take a look at it and recently went and took a snapshot of four tutorials and docked the code and then the GitHub fq is actually integrated using an API um the second part all right so once we've got all the information from tampon reference second part is building guard rails so the chatbot is only responding with answers that are grounded in reality and what I mean by that is we want to make sure that whenever you're asking questions it's using data from the knowledge basis it's not pulling data from it's that it's encoded in its training weights right we actually want to be able to point to some Source I think an example that I like to think about as you can imagine um you know someone in uh they can't speak right now all they have access to is this knowledge base files all they can do to answer your questions is point at things I think that's a really good way of like mentally modeling this out is you want to go and build the system so that it's always pointing at something and then it's going to be grounded in reality it's not making something up um one example I want to highlight on these slides is the math example here so what is two plus two because it feels like why why would you not let the bot do this right like it's going to be able to now you know tattoo Boutique and do basic math right what does two plus two if the user wants to know that why are we going to deny that functionality from them why would we say like you know oh no you can't do this the reason is all about setting the right expectations for the user right so if you're thinking of user experience you're answering some math problems right two plus two two to the power of 9 right and then you ask it something like what's you know is one two three four five six a prime number um it's not going to be able to solve all of the math problems because that's not part of the knowledge base and it's been known to hallucinate these kinds of scenarios right and I think like Math's one example but there's other things like weather geography right in in this case like email here fix this code and send me an email right that's taking a an action it's using some capability that we don't have you know we don't give it access to and so a big part of Building Systems is how do you go and help educate views around what the capabilities are and kind of add some guard rails so they stay on the right path so what are the types of questions that it should answer um the ones that we're going to be focusing on are questions like this right can I build a 3D game with bebby that's really simple right one that I'm interested in is how do I add keyboard controls to my game I want to be able to like move some character around on the screen what code do I need to write to do that um I'm experiencing but those are the kind of questions that should be like our happy path style questions so this is going to want to encourage users to use now how do you actually know if the system is working right well when you're building software you don't really write tests um you went for the word evals thrown around a lot I think that is like a more advanced version of this essentially but um our goal is to be able to go and say given some inputs we're gonna validate the outputs um what's hard about working with llms is that there can be like a million different inputs right people can ask any questions but then also for certain inputs there can be many different valid outputs I mean if I go and ask it how do I handle keyboard info for my game there could be a ton of different valid answers and so something that's important when you're trying to evaluate the system is that if you're writing some tests you want to go and try and isolate what the important parts of the system that you want to validate are and so in this case there are two main things right when I'm asking this question I want to understand how do I handle key presses someone press key and how do I connect all this to the game state so it's all wired up so this year this is uh like the first screen here showing the example chat bot right this is just a CLI tool again I'm going to share some code if someone's curious obviously it's not very pretty but it's meant to try and simplify the system as much as possible and what you can see here is like I asked in some question how do I handle keyboard input from a game and it gives me a response with the eval should be looking at is certain pieces of it right and so here I'm saying oh you know this here ad system keyboard input system right that's the Handler it's registering Handler and then the key press Handler right so key code left that's saying oh you know this is how I go and set up key codes and key commands that are going to work with systems um so if you're actually like writing a test for this kind of thing you want to try and match it and it's going to be a bit of a fuzzy match not gonna be perfect hearing your test might be a little tiny bit before I keep it I think that's okay because the main goal of the eval systems is to go and evaluate improvements over time right if you're adding new capabilities if you're changing towards the system you're changing prompts is it becoming more or less accurate as you have more and more evals it's going to matter less about like one specific one during one test run it's more just helping you build in a specific Direction yeah another example is the unhappy paths and so what is the capital of Canada right this is a question that Chad TPT would be able to answer um but we explicitly want to make sure it's not answering this because again we want to go and reinforce that we're not a geography bot we're not going to answer like you know weird questions about geography so we're not going to answer any questions about geography we're going to be focused on tasks and like the workflows that we could find and what we'd like to have happen is like it responds with something like hey sorry I'm not able to answer that question but if you have any questions about Bevy let me know that's the kind of thing that we would like it to to do maybe one thing to highlight here is that you don't want to end up in a situation similar to Alexa or somebody said like voice activated um assistance where you ask it to do something and it says sorry I can't do that and then you're just stuck right you don't necessarily understand system capabilities you want the system to help the user along and point them in the right direction and so it's always a balance of like you want some guard rails but you don't want to be too hard you want to kind of like shove the user back you know towards the the right direction um sorry I know we're coming up on time but um I'm gonna like continue plugging through but let me know if uh I need to pause for any moment so um so evals all right last point I need else is that they should cover five main cases the first case is hero use cases so again this is what I defined at the beginning right like what are the kinds of questions that we want to be able to answer the second case system capabilities and so as you're building this right you can imagine I had one source was GitHub One Source was these explicit files that went embedded and so on and um making sure that we're testing all the different capabilities of the system right like this might be refer to as white box testing you want to go and hit every code path edge cases missing or conflicting data um user-driven use cases so if you're building a tool right like a product that you want lots of users to use I think immediately you're going to even see lots of users try specific use cases either good or bad and you want to make sure you're turning those in evals so that as you're building the future you're preventing regressions but then you're also helping codify it so that if you're working with teammates um they're going to understand like what should the key facilities of the system be and then last thing is the non-workflow scenarios so this was things like the Canada geography example so finally at the chatbot itself right a basic chatbot this is if you've looked at any story online like this is the very simple like get started with the API example right a user makes some query we have something I'm referring to it as an agent here that's purposeful because an agent and someone can take like multiple actions depending on you know different inputs and and we'll expand upon that um the agent turns around to things like chat GPT or some other llm you know pipes data along it responds and we'll see here right in in my little example I've only written 20 evals for this little chat bot ideally if you have a larger system you're probably looking at like a couple hundred maybe more than that but this is just trying to keep it simple um and what you'll see here is I ask a question what is the key code for the spacebar button the key code for today button is 32. um this is just like input output this is not the answer that I want right the answer that I actually want here is the word like key code colon colon space bar space or something like that um but it's not giving me the correct response because it doesn't know that we're talking about bevy now the second thing I do right and you see like some version notes at the top here is we go and instruct the llm right and we're saying hey now we're adding some things to the prompt you know your goal is to provide Sport and answer questions like to Bevy in the rest program language after you go and do that you'll see the evaluation success increases pretty dramatically you'll see here that you know what's the key code for the spacebar button Devi you can use key code space that's a successful email that's exactly what I want to see now what's the latest version as of August 9th it's 0.5.0 and it's 2021. that's not what I wanted to see right I want to be able to see today what is the latest fit version of Debbie and so this is the problem that we want to try and solve is how do we go and ground it and real information not just in this training data before we do that there's one more step that I want to add which is putting up some of those guard rails how do you go and like help make sure that we're on a happy path it's not responding it's like what's two plus two and one strategy for this is using something called like react you might have seen like tool former or function calling this is something an open AI recently highlighted and when their blog posts um there's lots of different strategies for that but I think like the opening iPhone's calling is really simple and so I'd encourage folks to take a look and try it out if they haven't done it already this is how you go and like let the model go and select different actions to take and in my case I want to say hey let's only generate valid answers about bevy and if it's not about Bevy right if it's something off topic you're talking about the capital of Canada then we're going to respond to something else right we can still generate some response maybe it's like hey you know I I don't want to talk about that topic but if you have questions about Bevy something like that right but you're trying to go in and separate it from situations that we expect to handle situations we don't after I do that the valve success decreases a little bit more and you'll see when I say something like I am hungry it says sorry I can only answer questions related right it's not going to go and help me plan out my dinner and that's good right and that's helping set the expectation producer finally right knowledge retrieval this is where things start to get a little bit more exciting and so you want to go and take your system and wire it up to like round it somewhere right and you there's probably been like a bunch of other presentations on the other track and this track today talking to me about this concept of you want to have some data you put it somewhere for uh recall um one of the most popular examples this is using embeddings and storing things in some Vector store and being able to go and and run your queries using semantic search I think that's one example I think that you can also just use something like elasticsearch for this um it's I would just go for this talk what I'm using in my little chatbot example is an embedding based strategy where you're going I'm like using semantic search on them but I think that the the thing that I want to highlight is it doesn't necessarily matter what kind of system like how it's built what does matter is you put in some semantic query and or any query really you put in some query and you go and get knowledge that's going to be relevant to the user's query and that's what's required to go and build and ground these systems once you get the data you take it and you put it in the response generation context and you say here are some documents or some knowledge that we go and gathered use this knowledge when generating your response right and you want to highlight it and say only use the knowledge that I'm giving you right don't use the knowledge from your training anyway to use the knowledge that's in like this set of data and if it's not there then then say you don't know and you see here our email has gone way up right we're able to go and return oh bevy's 0.1.0 right or 0.10 this is fantastic it's not responding the right data a couple more improvements we can make to this kind of system are tool-based knowledge retrieval and so this is taking that similar approach we just used right react where you're going to go and plan and you're going to say hey given this question where do I want to go and look for the data do I want to go to the docs that are stored in this document store or do I want to go and look at the GitHub FAQs and that just happens to be another source for our knowledge base like another source that we can query right there's some great papers I think gorilla is like a really interesting one um but um that does a really good job and you'll see that there's about like 10 percent two of our evals who are actually using data that was only retrievable via the GitHub FAQs and so our success rate increased here last thing that I think is really excited is knowledge evaluation which is once you go and get data from the knowledge retrieval step you have something which looks at all those results and decides can I answer this question or not right if no you'll see it might be a little bit hard to see but you can respond with unable to answer right I I don't know right they'll say oh you know I checked my facts but I'm not really sure how to answer that maybe it provides like some recommendations to go check GitHub this is what I would recommend if you actually want to go and find out the answer here but the other thing you can do is it can actually go and highlight uh oh you know these three pieces of knowledge are useful for generating the results and you should use them and cite them and what the school looks like uh as an implementation is that now when it goes and finds that one document that was mentioning bevy's version 0.10 it goes and grabs it and we'll go and return that um so if you take a look here right the knowledge evaluation step will turn around to the response generation step and say hey there's this specific file use it in your generated prompt put it in your citations and then you can see like system here again the uis are beautiful by The Ghost and says Source One came from this file right our eval rates are up again um another case here this is when it's saying hey I didn't find any information you can try looking elsewhere right that that was that red path where it said I don't know it's unable to answer the question now even with all those improvements that we've done and put in place um it's still not entirely comprehensive right you can't solve every situation in this case it doesn't really understand temporal queries of oh you know what was the notable feature from 2022 that's why I read already it's not 100 and I think like the percentages here again don't really matter that much um it's really just meant to be an indicator of are you moving in the right direction right over time I'll be adding more e-files to this the eval percentage is going to go down I have more capabilities it'll go up right and so it's really just meant to be as a marker for are you improving are you getting better at the use cases that you want the user to cure so nearly done two less things um food improvements there's a bunch of potential ways you could take this next right I think the ones that are most exciting are introducing some kind of planning or task Loops right if you have multi-hop queries where you need to go get data from here and here and here and combine it that's something where task group comes in place in handy if you want to go and um enhance the quality of retrieval there's some really interesting things where you can pre-process the documents that you're storing the system right for you know those examples where you're storing the code files uh temporal querying that was the example we looked at and then one that's really challenging resolving conflicting data so if you have different things from multiple sources how do you handle that that one's really tricky um and then improving observability and interpretability right like when you're looking at the bot that I was showing you can't really understand what it's thinking what decisions it's making um I think some things like the tragedy plug-in system is trying to do that and go and like highlight a few things but it's not perfect right it feels like there's better um some better ux out there and there's more exploration to do there it's a quick plug for them if any of these are interesting to you I think every single one of these everything that we work through those are the kinds of challenges that I'm thinking about every day working with the team on so if you're interested in joining I would recommend checking out our careers page so last thing right the two lovers two things that are really important when you're building these kind of systems providing access to the knowledge base right a bunch of ways to do that but that's the most important thing and it should be using that data in its responses and it should only be using that data in its responses and the second thing is the guard rails and that's just to help bring the user to the spots where you have knowledge so they're not asking all these questions that you're just not going to be able to answer and there's a bunch of stuff we're a little bit over time um but I have a link here the bevybot.chat is where I'm going to go and share some of this stuff after allergic to GitHub that's just an Easy Link um I don't know if anyone has some uh questions I'd be happy to answer but I know we're a little bit over awesome thank you so much Scott um you said there was a link you were gonna share did you wanna uh yeah sorry so uh in in this here you can see https slash Bevy Dash bot.chat that's where it's going to be shared it'll read ranked I haven't uploaded the code there yet got to clean up just a tiny bit before it's ready for public but um over the next couple days we'll go and share it there and I encourage people to go and check it out okay awesome awesome um I think one question I'm seeing in the chat from apurva who is uh one of our fearless Emma locks Community leaders in Toronto she's asking how do we add in evals is it mostly through prompt engineering that's a really good question and so I think there's two ways to think about it let me jump back here for a quick sec so um the simplest way to like create evals is to actually write a test Suite that is integrating with some live version of your system so that might be a staging or a production equivalent you're actually running it live right if you run any kind of smoke test on your system before this is the kind of thing that it would do um and this chatbot module.process message would actually make the API call to your agent process it get the response and then you could do like in this example this is some typescript code which goes and checks did the response text include XYZ I think in the future there's lots of really interesting um folks that are working on how do we build llms which might be fine-tuned or just like uh specialized in evaluating the outputs of other L alums so you can actually build your evals using llms and then you wouldn't have to do this yourself you would just say oh here's the response right and ask the system is this a good response and it would be able to go and grade it maybe give you some score between like zero and ten and then they can use that to go and reinforce or improve the system but for now I would definitely like recommend by starting but just keeping it simple see do some simple stream matching I think what's really good about the IR style systems information retrieval is that for a lot of queries there is a right answer right like you have a grounding in some specific document what version is that every right that should have always produce the same answer and so for these kinds of systems it's pretty easy to build evals if you have a system where it's like a poetry generator that would be much harder to generate effective emails for great thank you so much hopefully that answered your question of horva um and another question that we got um thoughts on struct GPT paper um I'm not sure uh if I recall I struck GPD paper I don't know if the the person who's shared that would be able to maybe give a little bit more information about it but I'd be happy to go and and read it and share some more information after yeah drove uh I hope you heard that send us a little bit more information for that question another question that came through um from Ben um which of these pipeline steps do you see having the most room for improvement slash growth in the short to medium term the router planning step or or the knowledge retrieval and query planning that's a really good question I think the one that I found that I always come back to when I'm like whenever there's there's parts of the system where we're not retrieving the right data it's it's this knowledge retrieval step and I think what makes it challenging is there's so many different ways to do retrieval one way like you can think about retrieval and I think there's some good paper in this I think it's like SQL llm or something where it actually goes we'll write the SQL query that will be executed against your database and you provided the schema and it goes and can go and do it and fetch the data live I think that kind of thing is moving in the right direction of how are we grounding the data well we're actually able to go and live interact with certain parts of the system and it feels like there's so many interesting opportunities there on like introducing new kinds of uh retrieval but then also synthesis right and so I talked a little bit about like how hybrid systems are really common um where's that slide so that's when you're you have like elastics or in something like Pine count and you're combining your results after you want to make the query right some kind of re-ranking um I think that what is really hard is when you might have like 15 different sources that you want to query right you have all these different apis that the system you can interface with how does it know which one to look for to get the data um one way you can solve it if it depends on your use case but some of these agents will go and they'll try Source One oh I didn't find it there try Source two I didn't find it there try Source three that's hard because the user ends up waiting a long time but I think there's some interesting things you could do with the ux and you can say like hey I'll get back to you in 10 minutes let me go and I'm like check my sources and so um I think this is where there's a lot of really interesting work to be done but once you actually get the knowledge that uh like grounding it with citations is really important and I think that's that's a step that I wouldn't want like you know if you could it's hard to go and discard any one of these pieces and and keep the user trust really high in the system I think you need everything but I think that's the part where there's like the biggest amount of room for improvement yeah that's great and Drew I know I'm pronouncing your name wrong droops I'm I apologize um but Drew followed up on his drug club uh struck GPD question uh by saying um by saying knowledge grabs being integrated into llms through triplet mining I don't know if that gives you more interesting I've read a couple similar papers I don't know I it's like graph hop is one and there might be one or two others but um I I like some of the concepts I have seen are when you have the llm and you will give it essentially some schema of you know what attributes in the system what objects in like you know in in knowledge graphs you'll have the subject predicate the last part of it but it's a triplet rate and you can go and feed it a list of like different you know nodes and edges essentially and say hey what kind of query would you like to go and fetch this data and I think it's similar to the sequel um llm style systems you're actually like empowering the um knowledge retrieval to specifically said like oh I want to go and get all of the people who live in the city right and then count them up or something like that and I think it's really fascinating I think the really hard part about using knowledge graphs is getting the data into that format and if you don't already have it there so like in this case the knowledge base it's hard to go and extract that all into a Knowledge Graph because that process you're either doing it manually which is a ton of time and you have to keep up to date or you are um using an llm or something else to go and generate triplets so you're an insert into the system and at that point in my hallucinate or it might you know Miss data or include extra data and I think that's where you definitely don't want to end up with where you have bad data in the system you can't trust and so I think that's where it's really tricky there might be a future where that just becomes like good enough like human level quality and a lot of systems end up being built by you know you you run all of your data through some pre-processing stuff and I think like here what I was trying to get at was um this second point right pre-processing here where you're extracting all the enemies right these are all the people that are mentioned in the knowledge base these are all the apis that are mentioned in the large base and then when you query it it's able to go and actually instead of you know performing a search on Pinecone to go and get like oh these like 10 entities it's actually able to go to postgres and a specific table that has all the people and query for anyone that has like a specific name or something like that so um I think there's lots of interesting lots of interesting things in the pre-processing stage and I think the hardest part of it is still um just just getting it into a format that's really high quality um in the knowledge base so I I guess that question's probably saying essentially like what if the knowledge base is not doesn't have the right data is that um like like if there's some piece of information right like a better use version 0.7 and it's incorrect um I think that's extremely challenging right and I think that's part of this like the fourth Point here on resolving conflicting data you might have two documents right imagine you're running like an e-commerce store or a physical store and you have some store hours right like 9 A.M to 5 p.m and then you have another document which says you know like on holidays we're like 9 A.M to 3 P.M and helping the system understand the difference between the two is really challenging and and so the approach that I found best is you can imagine something like this part of the system the knowledge evaluation where it it has it doesn't just have unable to answer but it has another one where it says like conflicting sources and it actually responds to the user it says hey I found two different sources here's Source One here Source two look at them yourself right it says I don't really know but I'm just gonna like try and let you decide that's what you like I'd encourage I think um the wiki chat paper is really interesting they don't use this specific approach what they do is if they find conflicting data or data that they can't um uh what's the word like they can't uh prove essentially they're like they you know the the system has made some statement that I don't have any proof or citation about it'll just remove it from the output altogether um just because it wants to make sure the output is only ever referencing things that it can say are true so not really a great answer but it's you I think just like helping the user understand why it's saying certain things so that it's really easy for the user to do the fact checking yeah that makes sense uh Petros I hope that answered your question a bit and feel free to follow up if you want more information cool well thank you so much Scott I think you're closing out the day um and this was awesome and it looks like there might be a few more questions but I'm going to send you over to the chat to answer those if you don't mind that would be great I actually do apologize they do have to hop off um I have a work thing I need to run to but if anyone has any other questions please please send me an email you can either reach my work email at Scott mem.ai or my personal ads got that mackie.live and so I think my mem.ai should be in my profile but I'm happy to answer any questions over email or add me unlimited or something like that so thank you thank you so much thanks for having me as well thanks so much so long foreign