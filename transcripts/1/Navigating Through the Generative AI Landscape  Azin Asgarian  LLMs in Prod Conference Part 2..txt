all right so I'm so excited to introduce our next guest Zine um her topic I got sort of not that linguistic one was awesome um I'm so glad we had that angle on the conversation oh but this one is so timely as well um navigating through the generative AI landscape I mean who doesn't need help in that direction so thank you Zine for for joining us hello hi thanks for having me Lily yeah so excited for this uh let me pull up your slides and take it away thank you so much um actually so just a quick question can I uh go to the next slide or perfect [Music] um okay sorry just give me one sec while I'm moving this okay uh yeah so hello everybody my name is azin and I'm super excited to be here today and yeah thanks Lily and the team for the opportunity so I will be talking about um basically the generality bi landscape it's a super fast evolving film and I'm just gonna share some thoughts with no means sorry it doesn't mean that this is perfect so feel free to chime in and ask your questions at any point um just do just a bit of um sort of background about myself my name is azim I um you know once once upon a time I was a graduate student at University of Toronto where I did my masteries um in the AI group I graduated I was planning and trying to start my own company it was called pain yard and um yeah and then I decided to do in Georgia because this is you know a perfect place for people who are interested in technology and business and you know like have some sort of entrepreneurial spirit um and so perfect thank you and so um talking about the AI and ml opportunities and challenges I'm pretty sure that you've heard uh llm's probably 100 times just today and you're hearing that probably 100 times every day probably you know for the last six months or last couple of years um so just for for the sake of this thought this talk I'm just planning to you know walk you through some of these opportunities challenges and basically uh share how we at Georgian look at these opportunities and you know the framework we use for adopting this new technologies is basically like the internet era is transforming a lot of different fields and um you know working with a lot of companies and having the opportunity to to work with all of our portfolio companies we just wanted to so the purpose is just to share some of our learnings with you today so again directive AI I'm pretty sure you all have seen a lot of these things we saw the release of chat repeat um a lot of things has been going on co-pilot you know demo of co-pilot by Microsoft Sarah Bros open sourcing their large models anthropic raising gigantic rounds of funding Google Paul was released and just a few days ago that you know a new AIS startup focusing off on building large language models uh raised the biggest speed round and the whole history of alternative area for 113 million I believe so China is clearly getting a lot of attention I mean it's transforming the world so it's sort of you know it's not surprising there's getting a lot of attention from investors from uh technical folks from all sorts of different personals and different groups and in our suicide so yeah the the field is moving so fast and there are a lot of models that are being released every day this is just a view you know uh of some of these models based on their category and class um so we have the Transformer models you see the GPT type models and so on so forth so these models I would say the differences mainly come in terms of the model size we had bird which was 340 million and now we have gpt3 uh and four which are based on these 170 billion parametery models we have architecture you know differences in architectures we have differences in training data there are differences in their pre-training objective and some of them are task agnostics some of them are task specific and then there are also differences in the ethical Parts um some models like models from astrophy are trained being really focused on you know the Triple H harm harmless honest and helpful whereas the other models are maybe trained not you know that accurately on or not being the focused that much on the ethical aspects so I think a couple of questions that we have faced uh and we've you know our companies basically are asking themselves like which of these models is appropriate for your own use case in terms of data cost ethics and the performance and how can these models be tailored for specific use cases because using off-the-shelf models is um pretty easy but uh I mean easy things don't easy tasks or easy problems don't give you Competitive Edge so as a company if you wanted to keep your company with advantage and in this ever evolving field basically how can you do that and so I need to answer the first question there are a lot of benchmarks and leaderboards so this is by the Stafford University is pretty popular now Helm leaderboard it's it evaluates the model across 42 different tasks 36 models and 57 metrics uh so it gives you a pretty good idea and then there are also new leaderboards coming up every day so like hiking face um this is relatively more recent so they have this leaderboard that sort of evaluates um you know automatically evaluates different models that are available on the hugging phase Hub and they have llm benchmarks they also have human and GPT evaluations basically evaluating chatbots and the most recent models based on human responses and GPT evaluation Matrix and so you know you can sort of get a sense of Which models you would like to use or where you wanted to start um and in terms of the second question customizing your solution there are a lot of different approaches that are being discussed in the research community and Industry now yes they start from fine tuning you know as sort of an approach that's been around for many years you can either find you an input output the whole you know your whole model or do instruction tuning which is relatively more recent um since the release of gpc3 I would say probably even before the g32 gpt3 a lot of people realize that GPT type models are great Fusion Learners and I think there was a paper by openai in 2022 that um sort of shares a lot of interesting insight and results that basically showed that gpt3 can get to a great performance we're just having a few examples and so after that um this new era of prompt engineering and prompt optimization has started um you know initially people were just manually designing prompts and coming up with handcrafted prompts but over time uh like any other researchers sort of evolved into this um prompt optimization field uh where the idea is basically that instead of manually designing prompt you can um you know we can come up with algorithms and approaches that automatically design those prompts so those prompts can either we can either limit them and constrain them to the vocabulary to the basically words in our vocabulary and the language so that you know there are sort of interpretable by humans or you can take them to the next level and through them as tunable parameters uh so in that case which is basically continuous or soft prompt optimization methods we may end up with prompts that are totally you know not interpretable by humans and are just like basically a random string of anything uh but they are shown to be very effective in terms of performance and or sort of you know an alternative for fine tuning for extremely large models and then the last approach which came more or less you know which uh became really popular recently after the release of Taj GPT I would say is reinforcedure learning with human feedback um it's a popular approach and very effective approach for fine-tuning chatbot agents you can basically collect a lot of feedback from your customers and end users and use that feedback um to basically fine-tune your base model with to sort of you know align it make it more aligned with human values and human feedback that you and uh it got a lot you know it's it's getting a lot of attention and um yeah it's a very effective approach basically so the next question is that having access being aware of these customization method appropriate approach to address your problem thinking into consideration Factor like cost business requirements data volume and your basically privacy and ethical concerns and there are a lot of platforms that help you to sort of um Implement these um most of the main players like open air Nvidia have fine tuning for example capabilities available under playground so the next question is that which one of these platforms you should really use and um which one are basically suitable for your problem which depends a lot on again you know your problem the requirement you have and the constraints and so the other um the other part is that you know like over time we're just seeing the size of these models increasing and the models are just becoming larger and larger which is creating new sets of problems so you know if you are planning to production as a bird model you're potentially talking about a model with like a couple of hundred million parameters so uh you can you know it's not so hard these days to just create a version of that model fine tune it save a copy on your local machine or you know your server and sort of serve it but if you're if you're talking about a model with potentially you know a few like 100 um like in a few hundred million parameters or even sometimes truly inflammatories um literally thought like basically touching the model in terms of adjusting the way it's serving it creating a copy like that's not something really feasible just because we're talking about a huge memory footprint and the cost doesn't make sense in terms of the cost to do that so um that's why a lot of you know we're sort of hearing a new term called llam ops which is basically analogs for large language models it's not very different from ml apps a lot of people say that and I agree with that but um it's sort of basically you know adjusting or extending some of these platforms to work well with these extremely large models and so there are code there are platforms um that are no code and local platforms that sort of allow different types of users to play around with these models that are code first platforms and there are other tools and Frameworks to um you know a lot that would allow people to uh automate different part of the process like for example Line train uh it's pretty famous these days I believe like you can use it for training for creating agents and all sorts of things again a lot of tools in your at your hand which ones to use and which ones not use really depends again on the problem you have and uh your requirement the business requirement and you know other types of things um other types of criteria and yeah the other part that I wanted to highlight is the responsive responsible AI acquired like um I think like a lot of companies are now more aware and more careful about the ethical aspects of using large language models especially the ones that um directly work with end users and maybe more b2c companies um so this is uh plot by anthropic that basically shows you know how you can make chat Bots more helpful and honest and help and and basically harmless by to by fine-tuning them on human feedback and certain types of data so so I guess like one question that is important for companies and different you know basically stakeholders and this is based to answer is that what is the broader societal impact of your solution are these are there potential negative consequences and if so what guidelines can be established to mitigate them um and we're seeing a lot of activities going on in the in the field from you know popular figures like I don't differences and to all the other uh figures and all you know literally everyone and I think this is also quite important um to sort of you know think about the societal impact of whatever basically your work and how you can mitigate all those issues and that can give you a big competitive Advantage I think a good example of that is the case of anthropic like um there they are basically having a good Comfort event they're keeping their competitive Advantage by keeping a focus on the responsible side and the ethical side which again is very important and so the other the other area that I wanted to focus on is multimodal AI versus Unit Model AI um gpt4 was released that and the the vision modality is not accessible publicly publicly yet but um I think once it becomes accessible it's going to bring new capabilities and it's going to basically start a new wave of transformation because you know you can do all sorts of visual language tasks easily like vqa um analyze images or generate things from generate generating textual confirm which is any basically a lot of new capabilities would come to the surface and that's going to be a sort of a I would say a new era again so the question is understanding the current state and the limitations of multimodal what new applications can be unlocked by multimodal and can any of these impact your work or your business basically and if so I think it's pretty important to stay on top of it and think um a sort of you know try to be sort of think ahead of time and uh moving to the last piece again local Norco platforms we're seeing a lot of them they're a lot of you know a lot of these platforms have been around for years like teapot uh Auto blue on and there are new platforms that are coming and an emerging like search AI mosaicanal um I would say it's really important to sort of know which one of these platforms can give you a boost and sort of make your work more efficient more effective uh so yes I guess the the other aspect to this is that your competitors probably are using some of these platforms and if they are getting it with you probably wanted to keep up with the work they're doing and so I think the two important question here to ask is which of these platforms are suitable for use case and which ones you know aren't good enough or mature enough for you to use and so having said all of that um I think um the the way to sort of adapt and Leverage The potentials of generative AI at the end really depends on the opportunities you have um and so when you think about the opportunities you can think about them in two different groups pain relievers and Cane creators so pain relievers basically the question is how can we solve problems reduce risk or reduce negative emotions for our customers or our team um and a good example of this example that I really like is you know this product is so overwhelming and there is too much documentation I don't understand how to use it and can't find the time to learn so for example if your customers are being overwhelmed with the amount of information they have to um sort of Juggle to find the answer for their question then a potential during solution can be creating an interface or documentation you know an interface a genie agent that helps with the um basically finding the right info and so the other the other category gain Creator is basically how can we enhance our values surprise or Delight or increase happiness for our customers and a good example for this is um you know if I find it so hard to be creative on the spot so basically you can use generative AI uh to um you know increase the creativity and create a great marketing code for example so there are definitely a lot of different categories but these are the two buckets that you can think in high level and coming to my last slide this is what I wanted to recommend basically at the end when you think about these types of opportunities especially more specific generative AI we really recommend going with this you know framework of crawl walk run do not try to add Everything at Once try to have many fast iterations fail quickly learn quickly and then what we basically recommend to all of our companies and this is you know based on working with many of them is to is to basically start very simple and if impactful like to start by just crawling you fuchsia learning prompt engineering prompt tuning do not try to go after like playing through me at that first um once you figure it out or three points you could create a baseline simple Baseline with just the basic uh you know these basic approaches which can probably give you some results um then try to go after walking and then running so walking can be you know using anything from chaining Asians fine tuning models and then taking it to the next level you can try to you know once you really uh plus you have a really solid like Foundation you can try to go after training Foundation model for yourself based on your own property data or distilling models for efficiency and techniques like that um yeah and this is basically our approach when it comes to adopting um and yeah last point we have open positions we also have a technical group called transfer learning if you are interested to stay close to what to our work and what we do feel free to apply for any of these things and yeah thank you awesome thank you so much all right we got a speedy uh get to our next speaker but thank you so much for joining us make sure to check in the chat as well sure sure thanks for having me [Music]