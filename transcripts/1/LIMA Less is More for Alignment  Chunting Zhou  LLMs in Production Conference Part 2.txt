all right so next up we have chanting Zhao um from research at meta AI um very excited for this talk we will put her on stage hello how are you hi thank you yep here are your slides take it away okay cool also I'll just get started uh okay also thanks everyone for coming to the talk I'm Trenton from Maita Ai and I'm very excited to share what we have learned from Lima with you um so in this talk I will try to answer three research questions so first do we need large amount of annotated data to turn a comp patent chatbot the second question is if so what are the critical access when we create uh the annotated data set so the third question is how well can model Trend with a small number of annotated data generalized to new tasks uh as we know large language models are featured on trillions of tokens and we propose a super superficial alignment hypothesis such that a Model A model's knowledge and capabilities are learned almost entirely during pre-training while alignment teacher said which support distribution format should be used when interacting with the others so in the alignment stage we should fit filter model with the right format of fun tuning data that teaches the model to act as an AI assistant so where this hypothesis one conjecture that one could sufficiently tune operation language model with a rather small set of examples um so what are the critical access when creating the annotated data we found that ensuring high quality and high diversity in the training data are the keys to success Lima is turned on 1000 carefully accurated examples always no model distillation data from existing chatbot models and with minor human annotations of 200 examples so let's take a look at what composers this 1000 examples we have 200 examples from the stem stack exchange sets and 200 from the other size of Stack Exchange and we have 200 wikihog examples um we have 150 push push shift separated uh data set of the writing prompts and we have 50 uh NLP examples from natural instructions and we have 200 alternate examples from our co-authors so to control quality for the public data set listed above we remove the artifacts in the community data for example instructions um the user might refer to uh the answers from other posts and we eliminate search answers because we don't want them to be to appear in the in the training data in the chat boss response and we selected data with higher user ratings if uh the upwards if any for the in-house author data we set a uniformed home and our coursers follow the same format of a helpful assistant when writing the examples so many examples start with an acknowledgment of the question and then the actual answer and finally a short conclusion of the answer so to control diversity for the public data set we use also the public Community websites Theory contains a variety of topics and domains and we sample data with a repeated distribution to rebalance of different domains to increase the domain diversity and for our in-house other data we pay actual attention to the task diversity to cover more other scenarios for example creating a trip or creating a trip plan or conjecture on alternative history so we create a test set with 300 prompts with that word topics and tasks so Lima performs pretty well compared to some top chatbot models so one observation that is very interesting is in control setting when we scale up the number of examples from stack exchange data um by ensuring the same quality we don't see any improvements in the generation quality um because more section data don't bring more tasks that we see and improved quality in the training data um and this generation quality is mattered by a openline model with our uh with a Liker score so finally uh how well can model Trend with the small number of annotated data generalized to new tasks I want to share some uh a fascinating generalization ability of fun tuning with a handful of examples first by adding just Theory curated dialogue examples we found Lima has been greatly improved in the dialogue conversations um and feel free to check our examples in the in the article paper um second but I think just the sixth uh formatted a formatic constraint examples we find that the model can generalize to test examples from other domains um and can generate a long from highly structured response following other interactions uh following user inter instructions so one example in our in this out of this six training examples is review a paper from the following four aspects uh summary students weaknesses and potentials and for the for for on testing is for Test example uh here is a prompt creating a create a marketing plan with the following elements um marketing goals and objectives different target audience research marketing tactics uh plan marketing tactics and the web your timeline budget and here is the example the the output from Lima for the prompt we we just we just saw um so it can create a very good marketing plan um that including all of the elements the user specified so uh to summarize those three research questions in the beginning so do I need large amounts of annotated data to train a competent um competent chatbot the answer is no um from the observations of Lima and the second question is what are the critical access when creating the annotated data what we found is the quality and diversity including the domain and the task diversity of the annotated data um so the third question is how well can model Trend with a small number of uh annotated data generalized to new tasks we observe that after seeing a field annotated examples the model can generates pretty well to relevant tasks so in the end I'd like to point some limitations and open questions when we develop Lima uh first we see that Lima is still weak in coding and mass as with money uh other recent tradables one reason is that we are not building upon a very strong Foundation model that has seen sufficient coding and mice um uh pre-training examples and the other reason is that Lima data doesn't have money while aligned coding and mass examples so one open question here is what is the most effective data format of learning code and mass and some other reasoning in intensive tasks so second most of the training examples in Lima are from the public data size and this is definitely not the best ones on examples so one question was investigating is that how do we automatically and systematically discover new and diverse scenarios and create a better version of fun tuning data set um no matter even even in in a lifelong continual learning setting when the model has been deployed in the world so it's interesting it's also interesting to do a hyperbole comparison between PPO and sft in terms of the sample and The annotation efficiency uh so last but not least evaluation is hard especially assessing the truthfulness and the truthfulness of domain specific questions without expert annotators and this will be a constant issue as large language models become more and more stronger um okay so this is the end of my talk uh thank you everyone awesome thank you so much that was uh so insightful and definitely surprised me in a couple directions especially about the um needing fewer annotated pieces of data than I think people would expect I thought that was really interesting awesome all right well please drop in the chat um any links you think would be helpful for our attendees to have and thank you so much this is really wonderful thank you okay I'll just delete it okay yeah yeah talk to you later bye