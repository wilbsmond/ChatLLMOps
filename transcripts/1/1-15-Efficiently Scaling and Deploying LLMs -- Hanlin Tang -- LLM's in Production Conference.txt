foreign [Music] okay great yeah thanks a lot for having me really excited to be here my name is Hamlin Tang I'm the CTO and co-founder at a mosaic ML and today I'll be talking through what it takes to efficiently scale and deploy these large Anglers models at a sort of uh taken the World by storm you know in the last couple of months right and we've seen all the headlines on this entire amazing virtual conference that's been that's been put together has been built specifically for this topic what we've observed early on is that people used to think that okay llms are here and you need one giant AGI model uh for every use case um that's very centrally controlled by a few individual companies I think over the last month or two that thinking has really evolved inside the ecosystem to saying hey you know what uh you don't the world doesn't actually look like one you know AGI model it looks like many small specialized models that are used to solve very specific use cases owned by many companies and I'll provide some examples of what we're seeing in the ecosystem today uh with um with this type of thinking and it's not just us uh you know you can see here um uh articles from uh both illuminaries in the field as well as Venture capitalists that are saying that you know what we're going to be in a much more decentralized world where the power of llms will be put into every individual company uh or startups uh a world and you'll see these very distinct General AI models start to come into place and on the right you can see you know an article from uh folks in Venture Capital that companies with unique data stores will see clear advantages from training their own models as modes so we're really you know seeing this future world where companies will do both they'll use these amazing external apis that have come onto the scene uh to build some of their applications but they've also will undertake the effort to build their own custom large language models and what I'll do today is talk through exactly what that second bullet point means um is it too expensive is it too hard when should you do it when should you do it and what tooling is out there to help you really be able to train and deploy your own custom language models trained on your own data so why build your own models one of the key reasons that we see out there is you can see these headlines here a lot of kind of data privacy concerns where you don't want to be spending all of your time Outsourcing and sending your private data your core IP uh to an external service but I think if we dig deeper there it actually comes um a lot more um than that we see many reasons that companies are now citing that they want to be able to train their own models we already talked a little about data ownership but the other piece is really understanding where that model data is coming from if you want to be controlling the bias and the outputs of these models that many people you know so far have already talked about as a big problem for large language models part of that is understanding well what data went in if you're building a financial model for Enterprise do you really want to be using a model that was say trained on you know reddit's a Wall Street bets channel right or if you're building a healthcare specific model you want to make sure to be excluding certain data sources from your model itself part of the challenge that we have in controlling the model output is that we're applying all these Downstream hacks or modifications to get the models to align when many of the problems actually just come from where the source data came from so controlling what data went into training the model um can play a huge role in this data provenance problem the other piece is really controlling the content fillers that make sense for your business right some businesses need a very long sequence length or have very particular filters that they want to apply and you want to be able to apply that control and the third piece that we see is model ownership companies want to be able to own their weights either for portability so that you don't have to be beholden to a particular service to run the deployment side but also for better introspection and explainability we see even more reasons why customers want to be training their own models inside this ecosystem that's growing very quickly um of course I mentioned the business Advantage where kind of your data is your remote but the other under appreciated piece is inference economics um originally I think the field when they came onto the scenes okay we need to train these 100 billion parameter models 175 billion parameter models you know 500 billion parameter models and playing that kind of scaling game but what really emerge is that for many individual use case that you may be solving um you don't need a 175 billion parameter model that can do a lot of magic and AGI you have a very specific ml problem or NLP problem that you want to solve and for that training smarter smaller models um becomes much more interesting also in many applications that are very domain specific we see a lot of folks starting to train their own language models as well so in genomics for example where now you're dealing with sequences of proteins and dnas instead of natural text or electronic health records or medical or or in vehicle and then lastly I already mentioned kind of the need for data and model ownership from a privacy and from a regulatory standpoint we've heard from insurance companies where hey if you're in a highly regulated environment model and data ownership is critical to building more explainable and and better models also you don't want to be relying on external services that may for example you know discontinue a model or obsolete them all that you've been relying on for your particular application so we're really seeing this world where customers and and you all may want to start training our models and deploying your models and I think when we first say that a lot of what we hear from folks is hey it's that sounds hard right you need to find the right number of gpus you need to figure out what the software thing is to be able to run these things to figure out how to deploy them um thankfully and as I'll walk through during today's talk um there are many amazing tools out in the open source and in the community today to make training and deploying your models a lot easier than you may think it it would be from from first principles and I'll share some examples of of how these are being done today so this is an example is biomed LM it is a domain specific large language model that was trained just on PubMed so just on a large corporates of biomedical literature and I'll make a few interesting points here first this was trained by Stanford University joining with us but primarily by Stanford um and by just a team of uh two or three ml engineers um so despite like the size and scale of these models the tooling has gotten to a point where even small teams are able to train very interesting and Powerful language models and so this is a very simple example of a three billion parameter fairly small in terms of large language model world but we've we've seen that models like these really punch above their weight um this model is able to hit state of the art accuracy at the time of the release on the U.S medical licensing exam um and uh so that's this med QA USMLE example on the lower left here where the model gets this very long prompt about a history of a patient and the symptoms that's being presented um and it has to do a multiple choice about what the right test to order for this particular patient is uh and on the right is a different Benchmark that we use that Stanford used to measure this model which is PubMed QA where you're given a question you're given some context and you're supposed to answer you know some a particular medical problem and what's interesting here is that if you look on the chart on the right is that this biometer actually it was originally called PubMed GPT but we renamed it to PubMed LM model this first row here we can hit state-of-the-art accuracy at the time um on this med QA Benchmark and what's interesting is that this three billion parameter model can reach a similar performance as Galactica which was a model there's about 40 times larger but was trained on much less specific data so it really drives on the point where we're seeing growing evidence out there that training domain specific large language models in the medical space and the legal space in genomics and Healthcare and insurance you can actually build models that are economical uh to deploy at scale in inference across a large set of of customers the other point I'll make here is that um this is actually pretty accessible there's a lot of data that's already exists out there for particular domains out in the web for you to take in and and and and use uh in order to train these models so smaller three billion to 7 billion parameter models that are fairly specialized uh we've seen in the ecosystem can actually have very very strong business value um and we've seen applications everywhere from in the financial space where folks want to classify or summarize loan documents um to co-generation and helping with the programming tasks or these small models bring a lot of value because in most cases you don't need the power of that large you know AGI system that's been trained on a lot of data and it's very expensive to serve the other example that just actually came out last week was Bloomberg who trained a 50 billion parameter large language model on a combination of web data and also uh internal Bloomberg data and uh this uh is also fairly interesting because traditionally we thought of building large language models as requiring either the training from scratch piece or the fine-tuning piece but what's Happening Here Also is this continue to pre-train piece where you take a combination of web data that's already out there and internal Bloomberg data that's what Bloomberg did um and they found out that outperformed existing open source models on a large set of financial tasks and this really drives on the point that hey your internal proprietary proprietary data matters and can be used to solve better tasks for for your business now I think you know when we first say this there are a few I think myths that start coming out and the first one is oh my gosh Hanlon that's great I want to build my own models uh they give me data and privacy I get control over where my IP goes but it's too darn expensive um if you read the press out there gpt3 took somewhere from 10 million to 12 million dollars uh to train this model that's nowhere near feasible for kind of a prototype system the other I think myth that we've seen out there is that oh it's just too difficult um you have to figure out all these different individual components in order to train your large language models how do I get everything to connect together how do I figure out uh the right how many gpus I should use how did I get multi-node orchestration to work how do I deal with node failures how do I get the data streamed in how do I fit all these models into memory what type of model should I train and so these are two very common myths that I wanted to sort of bust in this talk to show you where the tooling is today uh to make training and building your own models uh very accessible the first one is you know we put out a Twitter poll I think this is somewhere in September uh asking folks how much do you think it actually cost to train a gpt3 quality model from scratch um and just like it's being reflected in in a lot of these articles that I just showed about 60 believe that a gpt3 quality model um costs you know between anywhere every one to five million plus or per rough and you know you do have to train these models a few times in order to get it just right um but the reality is that training large item is actually fairly accessible with the tooling that's available from us and other people in the in the community uh here is a actually a chart of different model sizes um how long they take to train on about 128 gpus and the approximate cost and suddenly if you combine kind of the tooling that's available now with the idea that hey a 1 billion to 7 billion parameter model actually is starts becoming very attractable uh for for business use cases uh you can see that training these models is no longer that expensive you can train a gpd3 quality model for about half a million dollars um and uh for many business use cases a thirty thousand dollar model can already go pretty far uh in being deployed into into production and how is this being done so there's a lot of great work happening right now on good Tooling in order to scale these models really efficiency efficiently uh and additionally a lot of work in the open source and from us on ways to efficiently and stably train these models so to efficiently scale these large language models for training one of the challenges that these models are so large they can't fit into the memory of a single GPU pytorch has released a fully sharded data parallel which is a pretty powerful and very simple strategy that essentially splits the model across many gpus that's very flexible and and easy to use and it's native to pytorch and so integrated with everybody who's using pie charts these days uh to train these models and um fully sharded and fully sharded data parallel essentially what happens is you split the model and the optimizer across all the different gpus and essentially fetch them just in time with training this saves a ton of memory but it's also very flexible because you don't have to deal with the more exotic you know parallelism strategies uh in order to train your models and so we found coupling fully sharded data parallel with our own composer Library uh and all the optimizations that will be baked in uh will eventually we'll make a trainees in large language models uh fairly fairly efficient and uh and easy to to use the other thing that's kind of involved in the research space in the last couple of months is that uh you don't actually need to train a large language model for it to be efficient um you can see here a plot from the metas a llama model so this is training loss on the y-axis and how many tokens of data is being crunched through on the x-axis and you can see here in blue is the Llama 7 billion parameter model and in red is a llama 65 billion parameter model what's interesting is that you can see for the 7 billion in the smaller model the loss continues to go down as you train more and more and so interestingly you won this ball when the set of models was released the seven billion per model was the one that got everybody's attention uh because hey it's small you can run it on your laptop sometimes for inference it's very cheap to deploy and if you continue training it and if you use it it actually can solve many of the business problems that that your your that you need to deploy these large language models so internally you know we have this Mantra you know train longer not larger and this has really changed the accessibility of these large anguish models uh from the bra for for everyone to be able to use foreign that we've seen out there is uh hey uh training and models is just too hard um I need to deal with uh challenges or finding the right kernels how do I do my parallelism how do I stream my data in I'm monitoring these runs becomes challenging because nodes can fail um in our experience nodes can fail almost uh every other day or every few days how do you recover from those very well you have to deal with challenges such as lost spikes High my training more efficiently how do I orchestrate all these multiple nodes and get them to talk to each other in the right way all these different challenges at first blush you know get in the way between the model and the data set and your your underlying Hardware and uh there is some evidence to substantiate this when you're training models at very large scales these are the training logs from one meta train their opt model and you can see nodes fail every so often uh when you resume from training you know it takes about 50 minutes when all the cluster is Idle uh waiting for the model to be reloaded and for the data loader to fast forward or you know sometimes your provider may accidentally delete your entire cluster when trying to reprovision the nodes and so all of these combined do make the sense or the the sentiment that hey maybe training these models is just too hard uh fortunately that's not actually the case with tooling that we've built and other folks in the community um we built an llm stat that sort of just works uh where we have provide optimized configurations across many model scales to be able to realize kind of the the cost and and the model training that I I spoke about previously um that is very fast and scalable and essentially you know provide your data and just go Um so if you're out there and you have some interesting internal data that you want to train or fine-tune these models uh to deploy for yourself using you know a lot of the models that are out there in the open source Us and other folks have built a great stack a great set of stacks many in the open source that make training these models uh very easy and sort of adjust working right right out of the box and so what we observe in Enterprise is that many folks may say hey I've trained a Bert model Bert base burnt large or deployed into production that's great um now I want to scale up and so using these tools you can now break this multi-node barrier um and start training smaller you know one billion parameter models and deploying those in your production seeing if that brings you a business Roi and then continuing to stack up uh from there uh to continue to to derive more value from training these larger models are maybe more accurate and um I spoke previously on many of other unique infrastructure challenge that come with training large models and large systems to some extent many of these are now starting to be solved like like that many platforms that are out there so um the ability to detect auto-memory errors that occur when you have a very large model and dynamically adjust the usage on the fly to prevent these ability to resume instantly uh or near instantly from uh from training so that if there is a node failure it automatically catches it and it restarts the ability to kind of gracefully resume from node failures and lost spikes such that you don't actually have to be monitoring these runs uh on a 24 7 right under the hood um they'll uh fill um all right one second um be able to resume gracefully from node failures and and lost spikes so that when things happen you don't have to be monitoring them 24 7. uh we you people have built systems that are able to automatically find the bad node and restart so from your perspective you just provide the data and training for it just happens and of course many of the efficiency work that's happening in the ecosystem from flash attention uh from uh from the the Stanford folks to various efficiency algorithms that we're developing uh to continue to bring down the cost of of training these these large language models and so that really ends up we end up with this ecosystem for the large language model training stack uh where uh there's this full stack that's now developing uh to allow you to easily train large language models on your data in your secure environment everything from experiment tracking tools to tooling from ours and others like web data set to be able to stream the data in to various distributed training Frameworks the underlying deep learning libraries deployment and orchestration and also various device device drivers and and toolkits and so this is literally leading to a world where you know for what we build like the Mosaic ml platform and others it is very straightforward to start training these one billion and seven billion primary large Anglers models for your particular use cases and we really see this as positive for the ecosystem right we want to be in the position and you know what this community actually this this ml Ops committee has shown is we want to be decentralizing on these capabilities um so that we're not beholden to just very particular API providers uh to be able to train these models I know I'm kind of running uh close on time here so I'll close by saying there are many reasons to build your own models training you know seven billion private language animals and and lower on your own data now is very cost effective and straightforward um the communities continue to push out many great open source models out there for you to build off of uh and we've sort of busted uh two myths here the first myth is hey it's just too expensive um which is not actually true it's now fairly cost effective to train these models and the second myth is too hard not true at all uh there are a lot of great open source tooling and full Stacks out there including ones that we've built uh to make the very easy to train these models and so I would really encourage everyone to don't be too scared by the large part in a large language model you know if you've trained or fine-tuned burnt models in the past or computer vision models the tooling is there now to start your large Irish model model in Journey and start scaling up efficiently and deploying these models into production of course we as Mosaic ml offer some of these platforms as well and so you can work with us or many others uh to to get started so very excited to see you know over the next six to 12 months the plethora of different models dedicated for legal or medicine or for your particular business that's going to emerge because of all the great work that's happening in the community and and in the in the open source um so with that um I'll close and thanks again to the animal Ops Community for inviting me to share what we're seeing out here [Music]